"""
Frontend Builder Custom Resource
Deploys pre-built React application to S3 with CloudFormation configuration injection
"""

import json
import os
import shutil
import tempfile

import boto3
from crhelper import CfnResource

s3 = boto3.client('s3')
cloudfront = boto3.client('cloudfront')
helper = CfnResource()


def use_prebuilt_dist(frontend_dir):
    """Use pre-built dist/ folder from Lambda package (no npm required)"""
    print("Using pre-built dist folder from Lambda package...")
    dist_dir = os.path.join(frontend_dir, 'dist')
    
    if not os.path.exists(dist_dir):
        raise Exception(f"Pre-built dist directory not found at {dist_dir}. "
                       f"Lambda package must include pre-built frontend/dist/ folder.")
    
    # Count files in dist
    file_count = sum(1 for root, dirs, files in os.walk(dist_dir) for f in files)
    print(f"Found pre-built dist directory with {file_count} files")
    
    return dist_dir


def inject_aws_config_into_dist(dist_dir, properties):
    """Generate aws-config.js, aws-config.json, and inject script tag into index.html"""
    print("Injecting AWS configuration into pre-built dist...")
    region = properties.get('Region', os.environ.get('AWS_REGION', 'us-west-2'))
    
    # Create configuration object
    config_obj = {
        'region': region,
        'userPoolId': properties.get('UserPoolId', ''),
        'userPoolClientId': properties.get('UserPoolClientId', ''),
        'identityPoolId': properties.get('IdentityPoolId', ''),
        'apiEndpoint': properties.get('ApiEndpoint', '')
    }
    
    # 1. Create aws-config.json at ROOT level (for fetch() in index.html)
    config_json_path = os.path.join(dist_dir, 'aws-config.json')
    with open(config_json_path, 'w') as f:
        json.dump(config_obj, f, indent=2)
    
    print(f"‚úÖ Generated aws-config.json at ROOT level")
    print(f"  Region: {region}")
    print(f"  User Pool ID: {properties.get('UserPoolId', '')}")
    print(f"  API Endpoint: {properties.get('ApiEndpoint', '')}")
    
    # 2. Create aws-config.js in assets/ (for backwards compatibility)
    config_js_content = f"""// AWS Configuration - Auto-generated by CloudFormation Custom Resource
// DO NOT EDIT - This file is automatically generated during CloudFormation deployment

window.AWS_CONFIG = {{
  Auth: {{
    Cognito: {{
      region: '{region}',
      userPoolId: '{properties.get('UserPoolId', '')}',
      userPoolClientId: '{properties.get('UserPoolClientId', '')}',
      identityPoolId: '{properties.get('IdentityPoolId', '')}',
      loginWith: {{
        email: true
      }}
    }}
  }},
  API: {{
    REST: {{
      DRSOrchestration: {{
        endpoint: '{properties.get('ApiEndpoint', '')}',
        region: '{region}'
      }}
    }}
  }}
}};
"""
    
    # Create assets directory if it doesn't exist
    assets_dir = os.path.join(dist_dir, 'assets')
    os.makedirs(assets_dir, exist_ok=True)
    
    config_js_path = os.path.join(assets_dir, 'aws-config.js')
    with open(config_js_path, 'w') as f:
        f.write(config_js_content)
    
    print(f"‚úÖ Generated aws-config.js in dist/assets/ (backwards compatibility)")
    
    # 3. Inject script tag into index.html to load aws-config.js before React app
    index_html_path = os.path.join(dist_dir, 'index.html')
    if os.path.exists(index_html_path):
        with open(index_html_path, 'r') as f:
            html_content = f.read()
        
        # Add script tag BEFORE the first script tag (React bundle)
        # This ensures aws-config.js loads and executes BEFORE React starts
        # Find the first <script tag and insert our config script before it
        import re
        script_pattern = r'(<script[^>]*>)'
        match = re.search(script_pattern, html_content)
        
        if match:
            # Insert config script before first script tag
            insert_pos = match.start()
            config_script = '    <script src="/assets/aws-config.js"></script>\n    '
            html_content = html_content[:insert_pos] + config_script + html_content[insert_pos:]
            print("‚úÖ Injected aws-config.js script tag BEFORE React bundle")
        else:
            # Fallback: insert before </head> if no script tags found
            script_tag = '    <script src="/assets/aws-config.js"></script>\n  </head>'
            html_content = html_content.replace('</head>', script_tag)
            print("‚úÖ Injected aws-config.js script tag before </head> (no script tags found)")
        
        with open(index_html_path, 'w') as f:
            f.write(html_content)
    else:
        print(f"‚ö†Ô∏è  WARNING: index.html not found at {index_html_path}")


@helper.create
@helper.update
def create_or_update(event, context):
    """Deploy pre-built frontend"""
    properties = event['ResourceProperties']
    bucket_name = properties['BucketName']
    distribution_id = properties['DistributionId']
    
    print(f"Frontend Builder: Deploying pre-built frontend to bucket: {bucket_name}")
    
    try:
        # Get frontend source from Lambda package
        lambda_frontend_path = '/var/task/frontend'
        if not os.path.exists(lambda_frontend_path):
            raise Exception(f"Frontend source not found in Lambda package at {lambda_frontend_path}")
        
        print(f"Found frontend source in Lambda package at {lambda_frontend_path}")
        
        # Use pre-built dist/ folder (no npm build required)
        dist_dir = use_prebuilt_dist(lambda_frontend_path)
        
        # Create temporary copy of dist to inject config
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_dist = os.path.join(temp_dir, 'dist')
            shutil.copytree(dist_dir, temp_dist)
            
            # Inject AWS configuration into pre-built dist
            inject_aws_config_into_dist(temp_dist, properties)
            
            # Upload dist to S3
            print("Uploading build artifacts to S3...")
            uploaded_files = upload_to_s3(temp_dist, bucket_name)
            
            print(f"‚úÖ Upload complete. Total files: {len(uploaded_files)}")
        
        # Invalidate CloudFront cache
        print("Creating CloudFront invalidation...")
        invalidation_response = cloudfront.create_invalidation(
            DistributionId=distribution_id,
            InvalidationBatch={
                'Paths': {
                    'Quantity': 1,
                    'Items': ['/*']
                },
                'CallerReference': str(context.aws_request_id)
            }
        )
        
        invalidation_id = invalidation_response['Invalidation']['Id']
        print(f"‚úÖ CloudFront invalidation created: {invalidation_id}")
        
        print("üéâ Frontend deployment complete!")
        
        return {
            'BucketName': bucket_name,
            'FilesDeployed': len(uploaded_files),
            'InvalidationId': invalidation_id,
            'BuildType': 'pre-built-react',
            'ConfigFiles': 'aws-config.json + aws-config.js'
        }
            
    except Exception as e:
        error_msg = f"Error deploying frontend: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        raise Exception(error_msg)


def upload_to_s3(dist_dir, bucket_name):
    """Upload all files from dist directory to S3 with proper cache headers"""
    uploaded_files = []
    
    for root, dirs, files in os.walk(dist_dir):
        for file in files:
            local_path = os.path.join(root, file)
            relative_path = os.path.relpath(local_path, dist_dir)
            s3_key = relative_path.replace('\\', '/')
            
            # Determine content type
            content_type = get_content_type(file)
            
            # Set cache control based on file type
            # index.html & aws-config.json: no cache (always fetch fresh)
            # Static assets: long-term cache (immutable with hashed filenames)
            if file in ['index.html', 'aws-config.json']:
                cache_control = 'no-cache, no-store, must-revalidate'
            else:
                cache_control = 'public, max-age=31536000, immutable'
            
            s3.upload_file(
                local_path,
                bucket_name,
                s3_key,
                ExtraArgs={
                    'ContentType': content_type,
                    'CacheControl': cache_control
                }
            )
            
            uploaded_files.append(s3_key)
            print(f"  Uploaded: {s3_key} ({content_type}, {cache_control})")
    
    return uploaded_files


def get_content_type(filename):
    """Determine content type from file extension"""
    ext = os.path.splitext(filename)[1].lower()
    
    content_types = {
        '.html': 'text/html',
        '.css': 'text/css',
        '.js': 'application/javascript',
        '.json': 'application/json',
        '.png': 'image/png',
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.gif': 'image/gif',
        '.svg': 'image/svg+xml',
        '.ico': 'image/x-icon',
        '.woff': 'font/woff',
        '.woff2': 'font/woff2',
        '.ttf': 'font/ttf',
        '.eot': 'application/vnd.ms-fontobject',
        '.txt': 'text/plain',
        '.xml': 'application/xml',
        '.pdf': 'application/pdf'
    }
    
    return content_types.get(ext, 'application/octet-stream')


@helper.delete
def delete(event, context):
    """Empty S3 bucket before CloudFormation deletes it"""
    properties = event['ResourceProperties']
    bucket_name = properties['BucketName']
    
    print(f"Frontend Builder: Emptying bucket {bucket_name} before deletion...")
    
    try:
        # Delete all objects (including versions if versioning enabled)
        paginator = s3.get_paginator('list_object_versions')
        
        delete_count = 0
        for page in paginator.paginate(Bucket=bucket_name):
            # Collect all objects and delete markers
            objects_to_delete = []
            
            # Add regular versions
            if 'Versions' in page:
                for version in page['Versions']:
                    objects_to_delete.append({
                        'Key': version['Key'],
                        'VersionId': version['VersionId']
                    })
            
            # Add delete markers
            if 'DeleteMarkers' in page:
                for marker in page['DeleteMarkers']:
                    objects_to_delete.append({
                        'Key': marker['Key'],
                        'VersionId': marker['VersionId']
                    })
            
            # Delete objects in batches of 1000 (AWS limit)
            if objects_to_delete:
                s3.delete_objects(
                    Bucket=bucket_name,
                    Delete={'Objects': objects_to_delete}
                )
                delete_count += len(objects_to_delete)
                print(f"  Deleted {len(objects_to_delete)} objects/versions")
        
        print(f"‚úÖ Bucket emptied successfully. Total objects deleted: {delete_count}")
        return None
        
    except s3.exceptions.NoSuchBucket:
        print(f"Bucket {bucket_name} doesn't exist - skipping cleanup")
        return None
        
    except Exception as e:
        error_msg = f"Error emptying bucket {bucket_name}: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        # Don't raise - allow stack deletion to continue even if cleanup fails
        print("‚ö†Ô∏è  Continuing with stack deletion despite cleanup error")
        return None


def lambda_handler(event, context):
    """Main handler for CloudFormation custom resource"""
    print(f"Frontend Builder: Received event: {json.dumps(event, default=str)}")
    helper(event, context)
