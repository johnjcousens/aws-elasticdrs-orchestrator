#!/bin/bash
#
# Local CI/CD Quality Checks
# Runs all validation, security scans, and tests from GitHub Actions locally
# Based on: .github/workflows/deploy.yml and security-checks.yml
#
# Usage:
#   ./scripts/local-ci-checks.sh [--skip-tests] [--skip-security]
#
# Options:
#   --skip-tests      Skip unit tests (faster for quick validation)
#   --skip-security   Skip security scans (faster for quick validation)
#   --quick           Skip both tests and security (fastest)

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
GRAY='\033[0;90m'
NC='\033[0m' # No Color

# ============================================================================
# PROGRESS INDICATOR FUNCTIONS
# ============================================================================

# Spinner characters
SPINNER_CHARS='â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â '
SPINNER_PID=""

# Start a background spinner with a message
start_spinner() {
    local msg="$1"
    local i=0
    local len=${#SPINNER_CHARS}
    
    # Run spinner in background
    (
        while true; do
            printf "\r${GRAY}  %s ${msg}...${NC}" "${SPINNER_CHARS:$i:1}"
            i=$(( (i + 1) % len ))
            sleep 0.1
        done
    ) &
    SPINNER_PID=$!
    
    # Ensure spinner is killed on script exit
    trap "kill $SPINNER_PID 2>/dev/null" EXIT
}

# Stop the spinner and show result
stop_spinner() {
    local result="$1"  # "success", "warning", "error", or "skip"
    local msg="$2"
    
    # Kill spinner if running
    if [ -n "$SPINNER_PID" ]; then
        kill $SPINNER_PID 2>/dev/null || true
        wait $SPINNER_PID 2>/dev/null || true
        SPINNER_PID=""
    fi
    
    # Clear the line and show result
    printf "\r\033[K"  # Clear line
    
    case "$result" in
        success)
            echo -e "${GREEN}  âœ“ ${msg}${NC}"
            ;;
        warning)
            echo -e "${YELLOW}  âš  ${msg}${NC}"
            ;;
        error)
            echo -e "${RED}  âœ— ${msg}${NC}"
            ;;
        skip)
            echo -e "${GRAY}  â—‹ ${msg}${NC}"
            ;;
        *)
            echo -e "  ${msg}"
            ;;
    esac
}

# Run a command with spinner and capture output
run_with_spinner() {
    local msg="$1"
    local log_file="$2"
    shift 2
    local cmd="$@"
    
    start_spinner "$msg"
    
    local start_time=$(date +%s)
    local exit_code=0
    
    # Run command and capture output
    eval "$cmd" > "$log_file" 2>&1 || exit_code=$?
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    # Stop spinner
    if [ -n "$SPINNER_PID" ]; then
        kill $SPINNER_PID 2>/dev/null || true
        wait $SPINNER_PID 2>/dev/null || true
        SPINNER_PID=""
    fi
    printf "\r\033[K"  # Clear line
    
    return $exit_code
}

# Show elapsed time
show_elapsed() {
    local start=$1
    local end=$(date +%s)
    local elapsed=$((end - start))
    echo -e "${GRAY}  (${elapsed}s elapsed)${NC}"
}

# Parse arguments
SKIP_TESTS=false
SKIP_SECURITY=false

for arg in "$@"; do
    case $arg in
        --skip-tests)
            SKIP_TESTS=true
            ;;
        --skip-security)
            SKIP_SECURITY=true
            ;;
        --quick)
            SKIP_TESTS=true
            SKIP_SECURITY=true
            ;;
        *)
            echo -e "${RED}Unknown option: $arg${NC}"
            exit 1
            ;;
    esac
done

# Track failures
VALIDATION_FAILED=false
SECURITY_FAILED=false
TEST_FAILED=false

echo -e "${BLUE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${BLUE}â•‘  AWS DRS Orchestration - Local CI/CD Quality Checks       â•‘${NC}"
echo -e "${BLUE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# Create logs directory structure
LOGS_DIR="docs/logs"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
RUN_LOG_DIR="$LOGS_DIR/runs/$TIMESTAMP"

# Clean up logs older than 30 days
if [ -d "$LOGS_DIR/runs" ]; then
    echo "ğŸ§¹ Cleaning up logs older than 30 days..."
    find "$LOGS_DIR/runs" -type d -mindepth 1 -maxdepth 1 -mtime +30 -exec rm -rf {} + 2>/dev/null || true
fi

mkdir -p "$RUN_LOG_DIR/validation"
mkdir -p "$RUN_LOG_DIR/security/raw"
mkdir -p "$RUN_LOG_DIR/security/formatted"
mkdir -p "$RUN_LOG_DIR/tests"
mkdir -p "$RUN_LOG_DIR/build"
mkdir -p "$RUN_LOG_DIR/deploy"

# Create symlink to latest run
rm -f "$LOGS_DIR/latest"
ln -sf "runs/$TIMESTAMP" "$LOGS_DIR/latest"

# Log run metadata
cat > "$RUN_LOG_DIR/run-metadata.txt" << EOF
Pipeline Run Metadata
=====================
Timestamp: $(date)
Run ID: $TIMESTAMP
Skip Tests: $SKIP_TESTS
Skip Security: $SKIP_SECURITY
Git Branch: $(git branch --show-current 2>/dev/null || echo "unknown")
Git Commit: $(git rev-parse --short HEAD 2>/dev/null || echo "unknown")
User: $(whoami)
Host: $(hostname)
EOF

echo "ğŸ“Š Logs will be saved to: $RUN_LOG_DIR"
echo ""

# Track overall start time
PIPELINE_START_TIME=$(date +%s)

# ============================================================================
# STAGE 1: VALIDATION
# ============================================================================
echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${CYAN}  STAGE 1: VALIDATION${NC}"
echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""
echo -e "${GRAY}  Checking CloudFormation, Python, Frontend, CloudScape...${NC}"
echo ""

VALIDATION_START_TIME=$(date +%s)

# 1.1 CloudFormation Validation
echo -e "${BLUE}[1.1] CloudFormation Template Validation${NC}"
echo ""

# cfn-lint validation
if command -v cfn-lint &> /dev/null; then
    start_spinner "Running cfn-lint"
    cfn-lint cfn/*.yaml --format json > $RUN_LOG_DIR/validation/cfn-lint.json 2>&1 || true
    cfn-lint cfn/*.yaml > $RUN_LOG_DIR/validation/cfn-lint.txt 2>&1 || true
    
    # Check for errors (E codes) vs warnings (W codes)
    ERROR_COUNT=$(grep -o '"Rule":.*"E[0-9]' $RUN_LOG_DIR/validation/cfn-lint.json 2>/dev/null | wc -l | tr -d ' ')
    WARNING_COUNT=$(grep -o '"Rule":.*"W[0-9]' $RUN_LOG_DIR/validation/cfn-lint.json 2>/dev/null | wc -l | tr -d ' ')
    ERROR_COUNT=${ERROR_COUNT:-0}
    WARNING_COUNT=${WARNING_COUNT:-0}
    
    if [ "$ERROR_COUNT" -gt 0 ] 2>/dev/null; then
        stop_spinner "error" "cfn-lint: Found $ERROR_COUNT error(s)"
        VALIDATION_FAILED=true
    elif [ "$WARNING_COUNT" -gt 0 ] 2>/dev/null; then
        stop_spinner "warning" "cfn-lint: Found $WARNING_COUNT warning(s) - acceptable"
    else
        stop_spinner "success" "cfn-lint: All templates valid"
    fi
else
    stop_spinner "skip" "cfn-lint not installed - skipping"
fi

echo ""

# AWS CloudFormation native validation
echo -e "${BLUE}  AWS CloudFormation native validation:${NC}"
VALIDATION_SUCCESS=true
TEMPLATE_COUNT=$(ls -1 cfn/*.yaml 2>/dev/null | wc -l | tr -d ' ')
CURRENT_TEMPLATE=0

# Check if timeout command exists (GNU coreutils), use gtimeout on macOS
if command -v timeout &> /dev/null; then
    TIMEOUT_CMD="timeout"
elif command -v gtimeout &> /dev/null; then
    TIMEOUT_CMD="gtimeout"
else
    # No timeout available - run without timeout
    TIMEOUT_CMD=""
fi

for template in cfn/*.yaml; do
    TEMPLATE_NAME=$(basename "$template")
    CURRENT_TEMPLATE=$((CURRENT_TEMPLATE + 1))
    
    # Check file size
    FILE_SIZE=$(stat -f%z "$template" 2>/dev/null || stat -c%s "$template")
    
    if [ "$FILE_SIZE" -gt 51200 ]; then
        # Large template - skip for local validation (would need S3)
        echo -e "${GRAY}    [$CURRENT_TEMPLATE/$TEMPLATE_COUNT] $TEMPLATE_NAME: ${YELLOW}SKIPPED${GRAY} (>51KB)${NC}"
    else
        # Small template - use inline validation
        printf "${GRAY}    [$CURRENT_TEMPLATE/$TEMPLATE_COUNT] $TEMPLATE_NAME: validating...${NC}"
        
        # Run validation with or without timeout
        if [ -n "$TIMEOUT_CMD" ]; then
            VALIDATE_RESULT=$($TIMEOUT_CMD 10 aws cloudformation validate-template --template-body file://$template 2>&1)
            VALIDATE_EXIT=$?
        else
            VALIDATE_RESULT=$(aws cloudformation validate-template --template-body file://$template 2>&1)
            VALIDATE_EXIT=$?
        fi
        
        if [ $VALIDATE_EXIT -eq 0 ]; then
            printf "\r\033[K${GRAY}    [$CURRENT_TEMPLATE/$TEMPLATE_COUNT] $TEMPLATE_NAME: ${GREEN}VALID${NC}\n"
        else
            printf "\r\033[K${GRAY}    [$CURRENT_TEMPLATE/$TEMPLATE_COUNT] $TEMPLATE_NAME: ${RED}INVALID${NC}\n"
            VALIDATION_SUCCESS=false
            VALIDATION_FAILED=true
        fi
    fi
done

if [ "$VALIDATION_SUCCESS" = true ]; then
    echo -e "${GREEN}  âœ“ AWS CloudFormation: All templates valid${NC}"
else
    echo -e "${RED}  âœ— AWS CloudFormation: Some templates invalid${NC}"
fi

echo ""

# 1.2 Python Code Quality
echo -e "${BLUE}[1.2] Python Code Quality${NC}"

# flake8
if command -v flake8 &> /dev/null; then
    start_spinner "Running flake8"
    if flake8 lambda/ scripts/ --config .flake8 --count --statistics > $RUN_LOG_DIR/validation/flake8.txt 2>&1; then
        stop_spinner "success" "flake8: No issues found"
    else
        stop_spinner "warning" "flake8: Found issues (see logs)"
        VALIDATION_FAILED=true
    fi
else
    stop_spinner "skip" "flake8 not installed"
fi

# black
if command -v black &> /dev/null; then
    start_spinner "Running black formatting check"
    if black --check --line-length 79 lambda/ scripts/ > $RUN_LOG_DIR/validation/black.txt 2>&1; then
        stop_spinner "success" "black: Code is formatted correctly"
    else
        stop_spinner "error" "black: Code needs formatting"
        echo -e "${GRAY}    Run: black --line-length 79 lambda/ scripts/${NC}"
        VALIDATION_FAILED=true
    fi
else
    stop_spinner "skip" "black not installed"
fi

# isort
if command -v isort &> /dev/null; then
    start_spinner "Running isort import check"
    if isort --check-only --profile black lambda/ scripts/ > $RUN_LOG_DIR/validation/isort.txt 2>&1; then
        stop_spinner "success" "isort: Imports are sorted correctly"
    else
        stop_spinner "error" "isort: Imports need sorting"
        echo -e "${GRAY}    Run: isort --profile black lambda/ scripts/${NC}"
        VALIDATION_FAILED=true
    fi
else
    stop_spinner "skip" "isort not installed"
fi

# 1.3 Frontend Validation
echo -e "${BLUE}[1.3] Frontend Code Quality${NC}"

if [ -d "frontend" ]; then
    cd frontend
    
    # Install dependencies if needed
    if [ ! -d "node_modules" ]; then
        start_spinner "Installing frontend dependencies"
        npm ci --silent > /dev/null 2>&1
        stop_spinner "success" "Dependencies installed"
    fi
    
    # TypeScript type check
    start_spinner "Running TypeScript type check"
    if npm run type-check > ../$RUN_LOG_DIR/validation/typescript.txt 2>&1; then
        stop_spinner "success" "TypeScript: No type errors"
    else
        stop_spinner "warning" "TypeScript: Found type errors (see logs)"
        VALIDATION_FAILED=true
    fi
    
    # ESLint
    start_spinner "Running ESLint"
    if npm run lint -- --max-warnings 200 > ../$RUN_LOG_DIR/validation/eslint.txt 2>&1; then
        stop_spinner "success" "ESLint: No critical issues"
    else
        stop_spinner "warning" "ESLint: Found issues (see logs)"
        VALIDATION_FAILED=true
    fi
    
    cd ..
else
    stop_spinner "skip" "Frontend directory not found"
fi

# 1.4 CloudScape Design System Compliance
echo -e "${BLUE}[1.4] CloudScape Design System Compliance${NC}"

if [ -f "scripts/check-cloudscape-compliance.sh" ]; then
    chmod +x scripts/check-cloudscape-compliance.sh
    start_spinner "Checking CloudScape compliance"
    if ./scripts/check-cloudscape-compliance.sh frontend/src > $RUN_LOG_DIR/validation/cloudscape.txt 2>&1; then
        stop_spinner "success" "CloudScape: Compliant"
    else
        stop_spinner "warning" "CloudScape: Found issues (see logs)"
        VALIDATION_FAILED=true
    fi
else
    stop_spinner "skip" "CloudScape compliance script not found"
fi

# 1.5 CamelCase Consistency
echo -e "${BLUE}[1.5] CamelCase Consistency Validation${NC}"

if [ -f "scripts/validate-camelcase-consistency.sh" ]; then
    chmod +x scripts/validate-camelcase-consistency.sh
    start_spinner "Checking CamelCase consistency"
    if ./scripts/validate-camelcase-consistency.sh > $RUN_LOG_DIR/validation/camelcase.txt 2>&1; then
        stop_spinner "success" "CamelCase: Consistent"
    else
        stop_spinner "warning" "CamelCase: Found inconsistencies (see logs)"
        VALIDATION_FAILED=true
    fi
else
    stop_spinner "skip" "CamelCase validation script not found"
fi

# 1.6 API Gateway Architecture
echo -e "${BLUE}[1.6] API Gateway Architecture Validation${NC}"

if [ -f "scripts/validate-api-architecture.sh" ]; then
    chmod +x scripts/validate-api-architecture.sh
    start_spinner "Checking API architecture"
    if ./scripts/validate-api-architecture.sh > $RUN_LOG_DIR/validation/api-architecture.txt 2>&1; then
        stop_spinner "success" "API Architecture: Valid"
    else
        stop_spinner "warning" "API Architecture: Found issues (see logs)"
        VALIDATION_FAILED=true
    fi
else
    stop_spinner "skip" "API architecture validation script not found"
fi

echo ""

VALIDATION_END_TIME=$(date +%s)
VALIDATION_DURATION=$((VALIDATION_END_TIME - VALIDATION_START_TIME))
echo -e "${GRAY}  Validation stage completed in ${VALIDATION_DURATION}s${NC}"
echo ""

# ============================================================================
# STAGE 2: SECURITY SCANS
# ============================================================================
if [ "$SKIP_SECURITY" = false ]; then
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${CYAN}  STAGE 2: SECURITY SCANS${NC}"
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    echo -e "${GRAY}  Running Bandit, Semgrep, Safety, NPM Audit...${NC}"
    echo ""
    
    SECURITY_START_TIME=$(date +%s)
    
    # 2.1 Python Security - Bandit
    echo -e "${BLUE}[2.1] Python Security Scanning (Bandit)${NC}"
    
    if command -v bandit &> /dev/null; then
        start_spinner "Running Bandit security scan"
        bandit -r lambda/ scripts/ -f json -o $RUN_LOG_DIR/security/raw/bandit-report.json -ll 2>&1 || true
        bandit -r lambda/ scripts/ -ll > $RUN_LOG_DIR/security/formatted/bandit-report.txt 2>&1 || true
        
        # Check for critical issues
        CRITICAL_COUNT=$(grep -o '"issue_severity": "HIGH"' $RUN_LOG_DIR/security/raw/bandit-report.json 2>/dev/null | wc -l | tr -d ' ')
        CRITICAL_COUNT=${CRITICAL_COUNT:-0}
        if [ "$CRITICAL_COUNT" -gt 0 ] 2>/dev/null; then
            stop_spinner "error" "Bandit: Found $CRITICAL_COUNT high severity issues"
            SECURITY_FAILED=true
        else
            stop_spinner "success" "Bandit: No high severity issues"
        fi
    else
        stop_spinner "skip" "Bandit not installed"
    fi
    
    # 2.2 Python Security - Semgrep
    echo -e "${BLUE}[2.2] Python Security Scanning (Semgrep)${NC}"
    
    if command -v semgrep &> /dev/null; then
        start_spinner "Running Semgrep security scan"
        semgrep --config=python.lang.security lambda/ scripts/ \
            --json -o $RUN_LOG_DIR/security/raw/semgrep-python.json \
            --severity ERROR --severity WARNING 2>&1 || true
        semgrep --config=python.lang.security lambda/ scripts/ \
            --severity ERROR --severity WARNING > $RUN_LOG_DIR/security/formatted/semgrep-python.txt 2>&1 || true
        stop_spinner "success" "Semgrep: Scan complete"
    else
        stop_spinner "skip" "Semgrep not installed"
    fi
    
    # 2.3 Dependency Vulnerability Scan - Safety
    echo -e "${BLUE}[2.3] Python Dependency Vulnerability Scan (Safety)${NC}"
    
    if command -v safety &> /dev/null; then
        start_spinner "Running Safety dependency scan"
        safety check --json > $RUN_LOG_DIR/security/raw/safety-report.json 2>&1 || true
        safety check > $RUN_LOG_DIR/security/formatted/safety-report.txt 2>&1 || true
        stop_spinner "success" "Safety: Scan complete"
    else
        stop_spinner "skip" "Safety not installed"
    fi
    
    # 2.4 Frontend Security - NPM Audit
    echo -e "${BLUE}[2.4] Frontend Security Scanning (NPM Audit)${NC}"
    
    if [ -d "frontend" ]; then
        cd frontend
        
        start_spinner "Running NPM audit"
        npm audit --audit-level moderate --json > ../$RUN_LOG_DIR/security/raw/npm-audit.json 2>&1 || true
        npm audit --audit-level moderate > ../$RUN_LOG_DIR/security/formatted/npm-audit.txt 2>&1 || true
        
        # Check for critical vulnerabilities
        CRITICAL_VULNS=$(grep -o '"severity": "critical"' ../$RUN_LOG_DIR/security/raw/npm-audit.json 2>/dev/null | wc -l | tr -d ' ')
        CRITICAL_VULNS=${CRITICAL_VULNS:-0}
        if [ "$CRITICAL_VULNS" -gt 0 ] 2>/dev/null; then
            stop_spinner "error" "NPM Audit: Found $CRITICAL_VULNS critical vulnerabilities"
            SECURITY_FAILED=true
        else
            stop_spinner "success" "NPM Audit: No critical vulnerabilities"
        fi
        
        cd ..
    else
        stop_spinner "skip" "Frontend directory not found"
    fi
    
    # 2.5 Infrastructure Security - CloudFormation
    echo -e "${BLUE}[2.5] Infrastructure Security Scanning${NC}"
    
    if command -v semgrep &> /dev/null; then
        start_spinner "Running Semgrep on CloudFormation"
        semgrep --config=yaml.lang.security cfn/ \
            --json -o $RUN_LOG_DIR/security/raw/semgrep-cfn.json \
            --severity ERROR --severity WARNING 2>&1 || true
        semgrep --config=yaml.lang.security cfn/ \
            --severity ERROR --severity WARNING > $RUN_LOG_DIR/security/formatted/semgrep-cfn.txt 2>&1 || true
        stop_spinner "success" "Semgrep CFN: Scan complete"
    else
        stop_spinner "skip" "Semgrep not installed"
    fi
    
    # 2.6 Generate Security Summary
    echo -e "${BLUE}[2.6] Security Summary${NC}"
    
    if [ -f "scripts/generate-security-summary.py" ]; then
        start_spinner "Generating security summary"
        python3 scripts/generate-security-summary.py > $RUN_LOG_DIR/security/summary.txt 2>&1 || true
        stop_spinner "success" "Security summary generated"
    else
        stop_spinner "skip" "Security summary script not found"
    fi
    
    # 2.7 Check Security Thresholds
    if [ -f "scripts/check-security-thresholds.py" ]; then
        start_spinner "Checking security thresholds"
        if python3 scripts/check-security-thresholds.py > $RUN_LOG_DIR/security/thresholds.txt 2>&1; then
            stop_spinner "success" "Security thresholds: PASSED"
        else
            stop_spinner "error" "Security thresholds: EXCEEDED"
            cat $RUN_LOG_DIR/security/thresholds.txt
            SECURITY_FAILED=true
        fi
    else
        stop_spinner "skip" "Security threshold script not found"
    fi
    
    SECURITY_END_TIME=$(date +%s)
    SECURITY_DURATION=$((SECURITY_END_TIME - SECURITY_START_TIME))
    echo ""
    echo -e "${GRAY}  Security stage completed in ${SECURITY_DURATION}s${NC}"
    echo ""
else
    echo -e "${YELLOW}âš  Security scans skipped (--skip-security)${NC}"
    echo ""
fi

# ============================================================================
# STAGE 3: TESTS
# ============================================================================
if [ "$SKIP_TESTS" = false ]; then
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${CYAN}  STAGE 3: TESTS${NC}"
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    echo -e "${GRAY}  Running Python unit tests, Frontend tests...${NC}"
    echo ""
    
    TEST_START_TIME=$(date +%s)
    
    # 3.1 Python Unit Tests
    echo -e "${BLUE}[3.1] Python Unit Tests${NC}"
    
    if command -v pytest &> /dev/null; then
        if [ -d "tests/python" ]; then
            cd tests/python
            
            start_spinner "Running Python unit tests"
            # Run tests excluding problematic ones
            if pytest unit/ -v --tb=short \
                --ignore=unit/test_api_handler.py \
                --ignore=unit/test_drs_service_limits.py \
                > ../../$RUN_LOG_DIR/tests/python-unit.txt 2>&1; then
                stop_spinner "success" "Python unit tests: PASSED"
            else
                stop_spinner "error" "Python unit tests: FAILED"
                echo -e "${GRAY}    See logs for details${NC}"
                TEST_FAILED=true
            fi
            
            cd ../..
        else
            stop_spinner "skip" "No Python tests found"
        fi
    else
        stop_spinner "skip" "pytest not installed"
    fi
    
    # 3.2 Frontend Tests
    echo -e "${BLUE}[3.2] Frontend Tests${NC}"
    
    if [ -d "frontend" ]; then
        cd frontend
        
        # Check if tests are configured
        if grep -q '"test"' package.json; then
            start_spinner "Running frontend tests"
            if npm test -- --run > ../$RUN_LOG_DIR/tests/frontend.txt 2>&1; then
                stop_spinner "success" "Frontend tests: PASSED"
            else
                stop_spinner "warning" "Frontend tests: Some failures (see logs)"
                TEST_FAILED=true
            fi
        else
            stop_spinner "skip" "No frontend tests configured"
        fi
        
        cd ..
    else
        stop_spinner "skip" "Frontend directory not found"
    fi
    
    TEST_END_TIME=$(date +%s)
    TEST_DURATION=$((TEST_END_TIME - TEST_START_TIME))
    echo ""
    echo -e "${GRAY}  Test stage completed in ${TEST_DURATION}s${NC}"
    echo ""
else
    echo -e "${YELLOW}âš  Tests skipped (--skip-tests)${NC}"
    echo ""
fi

# ============================================================================
# SUMMARY
# ============================================================================
PIPELINE_END_TIME=$(date +%s)
PIPELINE_DURATION=$((PIPELINE_END_TIME - PIPELINE_START_TIME))

echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${CYAN}  SUMMARY (completed in ${PIPELINE_DURATION}s)${NC}"
echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# Validation Summary
if [ "$VALIDATION_FAILED" = true ]; then
    echo -e "${RED}âœ— VALIDATION: FAILED${NC}"
    echo "  See $RUN_LOG_DIR/validation/ for details"
else
    echo -e "${GREEN}âœ“ VALIDATION: PASSED${NC}"
fi

# Security Summary
if [ "$SKIP_SECURITY" = false ]; then
    if [ "$SECURITY_FAILED" = true ]; then
        echo -e "${RED}âœ— SECURITY: FAILED${NC}"
        echo "  See $RUN_LOG_DIR/security/ for details"
    else
        echo -e "${GREEN}âœ“ SECURITY: PASSED${NC}"
    fi
else
    echo -e "${YELLOW}âš  SECURITY: SKIPPED${NC}"
fi

# Test Summary
if [ "$SKIP_TESTS" = false ]; then
    if [ "$TEST_FAILED" = true ]; then
        echo -e "${RED}âœ— TESTS: FAILED${NC}"
        echo "  See $RUN_LOG_DIR/tests/ for details"
    else
        echo -e "${GREEN}âœ“ TESTS: PASSED${NC}"
    fi
else
    echo -e "${YELLOW}âš  TESTS: SKIPPED${NC}"
fi

echo ""
echo "Reports saved to: $RUN_LOG_DIR/"
echo ""

# Exit with error if any stage failed
if [ "$VALIDATION_FAILED" = true ] || [ "$SECURITY_FAILED" = true ] || [ "$TEST_FAILED" = true ]; then
    echo -e "${RED}âŒ CI checks failed - fix issues before deploying${NC}"
    exit 1
else
    echo -e "${GREEN}âœ… All CI checks passed - ready to deploy${NC}"
    exit 0
fi
