"""
Frontend Builder Custom Resource
Deploys pre-built React application to S3 with CloudFormation configuration injection
"""

import json
import os
import shutil
import tempfile

import boto3
from crhelper import CfnResource

# Import security utilities (mandatory - no fallback)
from shared.security_utils import (
    log_security_event,
    safe_aws_client_call,
    sanitize_string_input,
    validate_file_path,
)

s3 = boto3.client("s3")
cloudfront = boto3.client("cloudfront")
helper = CfnResource()


def use_prebuilt_dist(frontend_dir):
    """Use pre-built dist/ folder from Lambda package (no npm required)"""
    print("Using pre-built dist folder from Lambda package...")

    # Security validation for file paths
    validate_file_path(frontend_dir)
    frontend_dir = sanitize_string_input(frontend_dir)
    log_security_event(
        "using_prebuilt_dist", {"frontend_dir": frontend_dir}
    )

    dist_dir = os.path.join(frontend_dir, "dist")

    if not os.path.exists(dist_dir):
        error_msg = (
            f"Pre-built dist directory not found at {dist_dir}. "
            f"Lambda package must include pre-built frontend/dist/ folder."
        )
        log_security_event(
            "dist_directory_not_found",
            {"dist_dir": dist_dir, "error": error_msg},
        )
        raise FileNotFoundError(error_msg)

    # Count files in dist
    file_count = sum(
        1 for root, dirs, files in os.walk(dist_dir) for f in files
    )
    print(f"Found pre-built dist directory with {file_count} files")

    return dist_dir


def inject_aws_config_into_dist(dist_dir, properties):
    """
    Generate aws-config.js, aws-config.json, and inject script tag into
    index.html
    """
    print("Injecting AWS configuration into pre-built dist...")

    # Security validation for inputs
    validate_file_path(dist_dir)
    dist_dir = sanitize_string_input(dist_dir)
    region = sanitize_string_input(
        properties.get("Region", os.environ.get("AWS_REGION", "us-west-2"))
    )
    log_security_event(
        "injecting_aws_config", {"dist_dir": dist_dir, "region": region}
    )

    # Create configuration object with sanitized values
    config_obj = {
        "region": region,
        "userPoolId": sanitize_string_input(
            properties.get("UserPoolId", "")
        ),
        "userPoolClientId": sanitize_string_input(
            properties.get("UserPoolClientId", "")
        ),
        "identityPoolId": sanitize_string_input(
            properties.get("IdentityPoolId", "")
        ),
        "apiEndpoint": sanitize_string_input(
            properties.get("ApiEndpoint", "")
        ),
    }

    # 1. Create aws-config.json at ROOT level (for fetch() in index.html)
    config_json_path = os.path.join(dist_dir, "aws-config.json")
    with open(config_json_path, "w") as f:
        json.dump(config_obj, f, indent=2)

    print("‚úÖ Generated aws-config.json at ROOT level")
    print(f"  Region: {region}")
    print(f"  User Pool ID: {properties.get('UserPoolId', '')}")
    print(f"  API Endpoint: {properties.get('ApiEndpoint', '')}")

    # 2. Create aws-config.js in assets/ (for backwards compatibility)
    config_js_content = f"""// AWS Configuration - Auto-generated by CloudFormation Custom Resource
// DO NOT EDIT - This file is automatically generated during CloudFormation deployment

window.AWS_CONFIG = {{
  Auth: {{
    Cognito: {{
      region: '{region}',
      userPoolId: '{properties.get('UserPoolId', '')}',
      userPoolClientId: '{properties.get('UserPoolClientId', '')}',
      identityPoolId: '{properties.get('IdentityPoolId', '')}',
      loginWith: {{
        email: true
      }}
    }}
  }},
  API: {{
    REST: {{
      DRSOrchestration: {{
        endpoint: '{properties.get('ApiEndpoint', '')}',
        region: '{region}'
      }}
    }}
  }}
}};
"""  # noqa: E231,E241,E202,E702

    # Create assets directory if it doesn't exist
    assets_dir = os.path.join(dist_dir, "assets")
    os.makedirs(assets_dir, exist_ok=True)

    config_js_path = os.path.join(assets_dir, "aws-config.js")
    with open(config_js_path, "w") as f:
        f.write(config_js_content)

    print(
        "‚úÖ Generated aws-config.js in dist/assets/ (backwards compatibility)"
    )

    # 3. Inject script tag into index.html to load aws-config.js before React app
    index_html_path = os.path.join(dist_dir, "index.html")
    if os.path.exists(index_html_path):
        with open(index_html_path, "r") as f:
            html_content = f.read()

        # Add script tag BEFORE the first script tag (React bundle)
        # This ensures aws-config.js loads and executes BEFORE React starts
        # Find the first <script tag and insert our config script before it
        import re

        script_pattern = r"(<script[^>]*>)"
        match = re.search(script_pattern, html_content, re.IGNORECASE)

        if match:
            # Insert config script before first script tag
            insert_pos = match.start()
            config_script = (
                '    <script src="/assets/aws-config.js"></script>\n    '
            )
            html_content = (
                html_content[:insert_pos]
                + config_script
                + html_content[insert_pos:]
            )
            print("‚úÖ Injected aws-config.js script tag BEFORE React bundle")
        else:
            # Fallback: insert before </head> if no script tags found
            script_tag = (
                '    <script src="/assets/aws-config.js"></script>\n  </head>'
            )
            html_content = html_content.replace("</head>", script_tag)
            print(
                "‚úÖ Injected aws-config.js script tag before </head> "
                "(no script tags found)"
            )

        with open(index_html_path, "w") as f:
            f.write(html_content)
    else:
        print(f"‚ö†Ô∏è  WARNING: index.html not found at {index_html_path}")


@helper.create
@helper.update
def create_or_update(event, context):
    """Deploy pre-built frontend"""
    properties = event["ResourceProperties"]

    # Security validation for CloudFormation inputs
    bucket_name = sanitize_string_input(properties["BucketName"])
    distribution_id = sanitize_string_input(properties["DistributionId"])
    log_security_event(
        "frontend_deployment_started",
        {
            "bucket_name": bucket_name,
            "distribution_id": distribution_id,
            "request_id": context.aws_request_id,
        },
    )

    print(
        f"Frontend Builder: Deploying pre-built frontend to bucket: "
        f"{bucket_name}"
    )

    try:
        # Get frontend source from Lambda package
        lambda_frontend_path = "/var/task/frontend"
        if not os.path.exists(lambda_frontend_path):
            error_msg = (
                f"Frontend source not found in Lambda package at "
                f"{lambda_frontend_path}"
            )
            log_security_event(
                "frontend_source_not_found",
                {"path": lambda_frontend_path, "error": error_msg},
            )
            raise FileNotFoundError(error_msg)

        print(
            f"Found frontend source in Lambda package at "
            f"{lambda_frontend_path}"
        )

        # Use pre-built dist/ folder (no npm build required)
        dist_dir = use_prebuilt_dist(lambda_frontend_path)

        # Create temporary copy of dist to inject config
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_dist = os.path.join(temp_dir, "dist")
            shutil.copytree(dist_dir, temp_dist)

            # Inject AWS configuration into pre-built dist
            inject_aws_config_into_dist(temp_dist, properties)

            # Upload dist to S3
            print("Uploading build artifacts to S3...")
            uploaded_files = upload_to_s3(temp_dist, bucket_name)

            print(f"‚úÖ Upload complete. Total files: {len(uploaded_files)}")

        # Invalidate CloudFront cache
        print("Creating CloudFront invalidation...")

        def invalidation_call():
            return cloudfront.create_invalidation(
                DistributionId=distribution_id,
                InvalidationBatch={
                    "Paths": {"Quantity": 1, "Items": ["/*"]},
                    "CallerReference": str(context.aws_request_id),
                },
            )

        invalidation_response = safe_aws_client_call(invalidation_call)

        invalidation_id = invalidation_response["Invalidation"]["Id"]
        print(f"‚úÖ CloudFront invalidation created: {invalidation_id}")

        print("üéâ Frontend deployment complete!")

        log_security_event(
            "frontend_deployment_completed",
            {
                "bucket_name": bucket_name,
                "files_deployed": len(uploaded_files),
                "invalidation_id": invalidation_id,
            },
        )

        return {
            "BucketName": bucket_name,
            "FilesDeployed": len(uploaded_files),
            "InvalidationId": invalidation_id,
            "BuildType": "pre-built-react",
            "ConfigFiles": "aws-config.json + aws-config.js",
        }

    except Exception as e:
        error_msg = f"Error deploying frontend: {str(e)}"
        print(error_msg)
        log_security_event(
            "frontend_deployment_error",
            {"error": str(e), "bucket_name": bucket_name},
        )
        import traceback

        traceback.print_exc()
        raise RuntimeError(error_msg)


def upload_to_s3(dist_dir, bucket_name):
    """Upload all files from dist directory to S3 with proper cache headers"""
    uploaded_files = []

    # Security validation for S3 inputs
    validate_file_path(dist_dir)
    bucket_name = sanitize_string_input(bucket_name)

    for root, dirs, files in os.walk(dist_dir):
        for file in files:
            local_path = os.path.join(root, file)
            relative_path = os.path.relpath(local_path, dist_dir)
            s3_key = relative_path.replace("\\", "/")

            # Security validation for file paths
            validate_file_path(local_path)
            s3_key = sanitize_string_input(s3_key)

            # Determine content type
            content_type = get_content_type(file)

            # Set cache control based on file type
            # index.html & aws-config.json: no cache (always fetch fresh)
            # Static assets: long-term cache (immutable with hashed filenames)
            if file in ["index.html", "aws-config.json"]:
                cache_control = "no-cache, no-store, must-revalidate"
            else:
                cache_control = "public, max-age=31536000, immutable"

            def upload_call():
                return s3.upload_file(
                    local_path,
                    bucket_name,
                    s3_key,
                    ExtraArgs={
                        "ContentType": content_type,
                        "CacheControl": cache_control,
                    },
                )

            safe_aws_client_call(upload_call)

            uploaded_files.append(s3_key)
            print(f"  Uploaded: {s3_key} ({content_type}, {cache_control})")

    return uploaded_files


def get_content_type(filename):
    """Determine content type from file extension"""
    ext = os.path.splitext(filename)[1].lower()

    content_types = {
        ".html": "text/html",
        ".css": "text/css",
        ".js": "application/javascript",
        ".json": "application/json",
        ".png": "image/png",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".gif": "image/gif",
        ".svg": "image/svg+xml",
        ".ico": "image/x-icon",
        ".woff": "font/woff",
        ".woff2": "font/woff2",
        ".ttf": "font/ttf",
        ".eot": "application/vnd.ms-fontobject",
        ".txt": "text/plain",
        ".xml": "application/xml",
        ".pdf": "application/pdf",
    }

    return content_types.get(ext, "application/octet-stream")


@helper.delete
def delete(event, context):
    """Empty S3 bucket before CloudFormation deletes it"""
    properties = event["ResourceProperties"]
    bucket_name = properties["BucketName"]

    print(
        f"Frontend Builder: Emptying bucket {bucket_name} before deletion..."
    )

    try:
        # Delete all objects (including versions if versioning enabled)
        paginator = s3.get_paginator("list_object_versions")

        delete_count = 0
        for page in paginator.paginate(Bucket=bucket_name):
            # Collect all objects and delete markers
            objects_to_delete = []

            # Add regular versions
            if "Versions" in page:
                for version in page["Versions"]:
                    objects_to_delete.append(
                        {
                            "Key": version["Key"],
                            "VersionId": version["VersionId"],
                        }
                    )

            # Add delete markers
            if "DeleteMarkers" in page:
                for marker in page["DeleteMarkers"]:
                    objects_to_delete.append(
                        {
                            "Key": marker["Key"],
                            "VersionId": marker["VersionId"],
                        }
                    )

            # Delete objects in batches of 1000 (AWS limit)
            if objects_to_delete:
                s3.delete_objects(
                    Bucket=bucket_name, Delete={"Objects": objects_to_delete}
                )
                delete_count += len(objects_to_delete)
                print(f"  Deleted {len(objects_to_delete)} objects/versions")

        print(
            f"‚úÖ Bucket emptied successfully. Total objects deleted: "
            f"{delete_count}"
        )
        return None

    except s3.exceptions.NoSuchBucket:
        print(f"Bucket {bucket_name} doesn't exist - skipping cleanup")
        return None

    except Exception as e:
        error_msg = f"Error emptying bucket {bucket_name}: {str(e)}"
        print(error_msg)
        import traceback

        traceback.print_exc()
        # Don't raise - allow stack deletion to continue even if cleanup fails
        print("‚ö†Ô∏è  Continuing with stack deletion despite cleanup error")
        return None


def lambda_handler(event, context):
    """Main handler for CloudFormation custom resource"""
    print(
        f"Frontend Builder: Received event: {json.dumps(event, default=str)}"
    )
    helper(event, context)
