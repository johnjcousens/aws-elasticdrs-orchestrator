name: Deploy AWS DRS Orchestration

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - test
          - prod

env:
  AWS_REGION: us-east-1
  PROJECT_NAME: aws-elasticdrs-orchestrator

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  # Stage 0: Detect changes to determine what needs to be deployed
  detect-changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      docs-only: ${{ steps.changes.outputs.docs-only }}
      frontend-only: ${{ steps.changes.outputs.frontend-only }}
      infrastructure: ${{ steps.changes.outputs.infrastructure }}
      lambda: ${{ steps.changes.outputs.lambda }}
      frontend: ${{ steps.changes.outputs.frontend }}
      docs: ${{ steps.changes.outputs.docs }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect changed files
        id: changes
        run: |
          # Get list of changed files
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }})
          else
            # For push events, compare with previous commit
            CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
          fi
          
          echo "Changed files:"
          echo "$CHANGED_FILES"
          
          # Categorize changes
          INFRASTRUCTURE_CHANGED=false
          LAMBDA_CHANGED=false
          FRONTEND_CHANGED=false
          DOCS_CHANGED=false
          
          while IFS= read -r file; do
            case "$file" in
              cfn/*|buildspecs/*|scripts/sync-to-deployment-bucket.sh)
                INFRASTRUCTURE_CHANGED=true
                ;;
              lambda/*|tests/python/*)
                LAMBDA_CHANGED=true
                ;;
              frontend/*)
                FRONTEND_CHANGED=true
                ;;
              docs/*|README.md|CHANGELOG.md|*.md)
                DOCS_CHANGED=true
                ;;
              .github/workflows/*)
                # Workflow changes should trigger full pipeline
                INFRASTRUCTURE_CHANGED=true
                ;;
            esac
          done <<< "$CHANGED_FILES"
          
          # Determine deployment strategy
          DOCS_ONLY=false
          FRONTEND_ONLY=false
          
          if [ "$DOCS_CHANGED" = "true" ] && [ "$INFRASTRUCTURE_CHANGED" = "false" ] && [ "$LAMBDA_CHANGED" = "false" ] && [ "$FRONTEND_CHANGED" = "false" ]; then
            DOCS_ONLY=true
          elif [ "$FRONTEND_CHANGED" = "true" ] && [ "$INFRASTRUCTURE_CHANGED" = "false" ] && [ "$LAMBDA_CHANGED" = "false" ]; then
            FRONTEND_ONLY=true
          fi
          
          echo "docs-only=$DOCS_ONLY" >> $GITHUB_OUTPUT
          echo "frontend-only=$FRONTEND_ONLY" >> $GITHUB_OUTPUT
          echo "infrastructure=$INFRASTRUCTURE_CHANGED" >> $GITHUB_OUTPUT
          echo "lambda=$LAMBDA_CHANGED" >> $GITHUB_OUTPUT
          echo "frontend=$FRONTEND_CHANGED" >> $GITHUB_OUTPUT
          echo "docs=$DOCS_CHANGED" >> $GITHUB_OUTPUT
          
          echo "=== Change Detection Results ==="
          echo "Documentation only: $DOCS_ONLY"
          echo "Frontend only: $FRONTEND_ONLY"
          echo "Infrastructure changed: $INFRASTRUCTURE_CHANGED"
          echo "Lambda changed: $LAMBDA_CHANGED"
          echo "Frontend changed: $FRONTEND_CHANGED"
          echo "Documentation changed: $DOCS_CHANGED"

  # Stage 1: Validate CloudFormation templates and code quality
  validate:
    name: Validate
    runs-on: ubuntu-latest
    needs: [detect-changes]
    if: needs.detect-changes.outputs.docs-only != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install validation tools
        run: |
          pip install cfn-lint flake8 black isort

      - name: Validate CloudFormation templates
        run: |
          echo "=== CloudFormation Lint Validation ==="
          for template in cfn/*.yaml; do
            echo "Validating $template with cfn-lint..."
            cfn-lint "$template" || true
          done

      - name: Configure AWS credentials for validation
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: AWS CloudFormation native validation
        run: |
          echo "=== AWS CloudFormation Native Validation ==="
          BUCKET="${{ secrets.DEPLOYMENT_BUCKET }}"
          
          for template in cfn/*.yaml; do
            echo "Validating $template with AWS..."
            
            # Check file size (51200 bytes = 50KB limit for inline validation)
            FILE_SIZE=$(stat -c%s "$template" 2>/dev/null || stat -f%z "$template")
            
            if [ "$FILE_SIZE" -gt 51200 ]; then
              # Large template - upload to S3 and validate via URL
              echo "  Template is ${FILE_SIZE} bytes (>51KB), using S3 validation..."
              TEMPLATE_NAME=$(basename "$template")
              aws s3 cp "$template" "s3://${BUCKET}/cfn-validation/${TEMPLATE_NAME}" --quiet
              aws cloudformation validate-template \
                --template-url "https://${BUCKET}.s3.amazonaws.com/cfn-validation/${TEMPLATE_NAME}" > /dev/null
              aws s3 rm "s3://${BUCKET}/cfn-validation/${TEMPLATE_NAME}" --quiet
            else
              # Small template - use inline validation
              aws cloudformation validate-template --template-body file://$template > /dev/null
            fi
            
            echo "âœ“ $template is valid"
          done

      - name: Python code quality
        run: |
          echo "=== Python Code Quality ==="
          flake8 lambda/ --config .flake8 --count --show-source --statistics || true
          black --check --line-length 79 lambda/ || true
          isort --check-only --profile black lambda/ || true

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Frontend type check
        working-directory: frontend
        run: |
          npm ci
          npm run type-check || true

      - name: Frontend ESLint
        working-directory: frontend
        run: |
          echo "=== ESLint Validation ==="
          npm run lint -- --max-warnings 200 || true

      - name: CloudScape Design System Compliance
        run: |
          echo "=== CloudScape Design System Compliance Check ==="
          chmod +x scripts/check-cloudscape-compliance.sh
          ./scripts/check-cloudscape-compliance.sh frontend/src

  # Stage 2: Security scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: [detect-changes]
    if: needs.detect-changes.outputs.docs-only != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install security tools
        run: |
          pip install bandit==1.9.2 safety==2.3.4 semgrep==1.146.0 cfn-lint==0.83.8

      - name: Create security reports directory
        run: |
          mkdir -p reports/security/raw
          mkdir -p reports/security/formatted

      - name: Python security scanning
        run: |
          echo "=== Python Security Scanning ==="
          
          # Bandit security scan
          echo "Running Bandit security scan..."
          bandit -r lambda/ scripts/ -f json -o reports/security/raw/bandit-report.json -ll || true
          bandit -r lambda/ scripts/ -ll > reports/security/formatted/bandit-report.txt || true
          
          # Semgrep security scan for Python
          echo "Running Semgrep security scan on Python code..."
          semgrep --config=python.lang.security lambda/ scripts/ --json -o reports/security/raw/semgrep-python.json --severity ERROR --severity WARNING || true
          semgrep --config=python.lang.security lambda/ scripts/ --severity ERROR --severity WARNING > reports/security/formatted/semgrep-python.txt || true
          
          # Safety dependency vulnerability scan
          echo "Running Safety dependency vulnerability scan..."
          safety check --json > reports/security/raw/safety-report.json || true
          safety check > reports/security/formatted/safety-report.txt || true

      - name: Frontend security scanning
        working-directory: frontend
        run: |
          echo "=== Frontend Security Scanning ==="
          npm ci
          
          # NPM audit security scan
          echo "Running NPM audit security scan..."
          npm audit --audit-level moderate --json > ../reports/security/raw/npm-audit.json || true
          npm audit --audit-level moderate > ../reports/security/formatted/npm-audit.txt || true
          
          # ESLint security scan
          echo "Running ESLint security scan..."
          npx eslint src/ --ext .ts,.tsx --format json -o ../reports/security/raw/eslint-security.json || true
          npx eslint src/ --ext .ts,.tsx --format compact > ../reports/security/formatted/eslint-security.txt || true

      - name: Infrastructure security scanning
        run: |
          echo "=== Infrastructure Security Scanning ==="
          
          # CloudFormation security linting
          echo "Running CloudFormation security linting..."
          cfn-lint cfn/*.yaml --format json > reports/security/raw/cfn-lint.json || true
          cfn-lint cfn/*.yaml > reports/security/formatted/cfn-lint.txt || true
          
          # Semgrep security scan for CloudFormation
          echo "Running Semgrep security scan on CloudFormation templates..."
          semgrep --config=yaml.lang.security cfn/ --json -o reports/security/raw/semgrep-cfn.json --severity ERROR --severity WARNING || true
          semgrep --config=yaml.lang.security cfn/ --severity ERROR --severity WARNING > reports/security/formatted/semgrep-cfn.txt || true

      - name: Generate security summary
        env:
          SECURITY_THRESHOLD_CRITICAL: "0"
          SECURITY_THRESHOLD_HIGH: "10"
          SECURITY_THRESHOLD_TOTAL: "50"
        run: |
          echo "=== Generating Security Summary ==="
          python scripts/generate-security-summary.py

      - name: Check security thresholds
        env:
          SECURITY_THRESHOLD_CRITICAL: "0"
          SECURITY_THRESHOLD_HIGH: "10"
          SECURITY_THRESHOLD_TOTAL: "50"
        run: |
          echo "=== Checking Security Thresholds ==="
          python scripts/check-security-thresholds.py

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            reports/security/
          retention-days: 30

  # Stage 3: Build Lambda packages and frontend
  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [detect-changes, validate, security-scan]
    if: needs.detect-changes.outputs.docs-only != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Build Lambda packages
        run: |
          echo "=== Building Lambda Packages ==="
          mkdir -p build/lambda
          
          # Install shared dependencies
          pip install boto3 urllib3 crhelper -t /tmp/lambda-deps/ --quiet
          
          # Build each Lambda function from its subdirectory
          # Structure: lambda/<function-name>/index.py + shared modules
          
          FUNCTIONS="api-handler orchestration-stepfunctions frontend-builder bucket-cleaner execution-finder execution-poller notification-formatter"
          
          for func in $FUNCTIONS; do
            echo "Building ${func}.zip..."
            
            # Start with the function's index.py
            cd lambda/${func}
            zip -q ../../build/lambda/${func}.zip index.py
            cd ../..
            
            # Add shared modules (rbac_middleware.py, security_utils.py)
            cd lambda/shared
            zip -qg ../../build/lambda/${func}.zip *.py 2>/dev/null || true
            cd ../..
            
            # Add dependencies
            cd /tmp/lambda-deps
            zip -qr $GITHUB_WORKSPACE/build/lambda/${func}.zip .
            cd $GITHUB_WORKSPACE
          done
          
          echo "Lambda packages built:"
          ls -la build/lambda/

      - name: Build frontend
        working-directory: frontend
        run: |
          echo "=== Building Frontend ==="
          npm ci
          npm run build
          
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            build/
            frontend/dist/
          retention-days: 7

  # Stage 4: Run tests
  test:
    name: Test
    runs-on: ubuntu-latest
    needs: [detect-changes, build]
    if: needs.detect-changes.outputs.docs-only != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install test dependencies
        run: |
          pip install pytest pytest-cov moto boto3

      - name: Run unit tests
        run: |
          echo "=== Running Unit Tests ==="
          cd tests/python
          pytest unit/ -v --tb=short || true

  # Stage 5: Deploy infrastructure (only on main branch) - Multi-Stack Matrix Strategy
  deploy-infrastructure:
    name: Deploy Infrastructure (${{ matrix.stack.name }})
    runs-on: ubuntu-latest
    needs: [detect-changes, test]
    if: |
      github.ref == 'refs/heads/main' && 
      github.event_name == 'push' && 
      needs.detect-changes.outputs.docs-only != 'true' && 
      (needs.detect-changes.outputs.infrastructure == 'true' || needs.detect-changes.outputs.lambda == 'true')
    strategy:
      matrix:
        stack:
          - name: "aws-elasticdrs-orchestrator-dev"
            display_name: "Current Stack (Primary)"
            bucket_secret: "DEPLOYMENT_BUCKET"
            stack_secret: "STACK_NAME"
            admin_email_secret: "ADMIN_EMAIL"
            role_arn_secret: "AWS_ROLE_ARN"
            project_name: "aws-elasticdrs-orchestrator"
          - name: "aws-drs-orchestrator-archive-test"
            display_name: "Archive Test Stack"
            bucket_secret: "ARCHIVE_DEPLOYMENT_BUCKET"
            stack_secret: "ARCHIVE_STACK_NAME"
            admin_email_secret: "ARCHIVE_ADMIN_EMAIL"
            role_arn_secret: "ARCHIVE_AWS_ROLE_ARN"
            project_name: "aws-drs-orchestrator"
      max-parallel: 1  # CRITICAL: Sequential deployment to avoid S3 conflicts
    environment: 
      name: ${{ github.event.inputs.environment || 'dev' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials for ${{ matrix.stack.display_name }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets[matrix.stack.role_arn_secret] }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS access for ${{ matrix.stack.display_name }}
        run: |
          echo "=== AWS Identity for ${{ matrix.stack.display_name }} ==="
          aws sts get-caller-identity
          echo "Stack: ${{ matrix.stack.name }}"
          echo "Project: ${{ matrix.stack.project_name }}"

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts

      - name: Sync to deployment bucket (${{ matrix.stack.display_name }})
        run: |
          echo "=== Syncing to S3 for ${{ matrix.stack.display_name }} ==="
          BUCKET="${{ secrets[matrix.stack.bucket_secret] }}"
          
          # Sync CloudFormation templates
          aws s3 sync cfn/ "s3://${BUCKET}/cfn/" --delete
          
          # Sync Lambda packages
          aws s3 sync build/lambda/ "s3://${BUCKET}/lambda/" --delete
          
          echo "Deployment artifacts synced to s3://${BUCKET}/ for ${{ matrix.stack.display_name }}"

      - name: Deploy CloudFormation stack (${{ matrix.stack.display_name }})
        run: |
          echo "=== Deploying CloudFormation Stack: ${{ matrix.stack.display_name }} ==="
          STACK_NAME="${{ secrets[matrix.stack.stack_secret] }}"
          BUCKET="${{ secrets[matrix.stack.bucket_secret] }}"
          ADMIN_EMAIL="${{ secrets[matrix.stack.admin_email_secret] }}"
          PROJECT_NAME="${{ matrix.stack.project_name }}"
          ENV="${{ github.event.inputs.environment || 'dev' }}"
          
          echo "ðŸš€ MULTI-STACK DEPLOYMENT"
          echo "   Stack: $STACK_NAME"
          echo "   Display Name: ${{ matrix.stack.display_name }}"
          echo "   Project: $PROJECT_NAME"
          echo "   Environment: $ENV"
          echo "   Bucket: $BUCKET"
          
          # PRODUCTION SAFETY CHECK
          if [[ "$ENV" == "prod" ]]; then
            echo "ðŸš¨ PRODUCTION DEPLOYMENT DETECTED ðŸš¨"
            echo "Stack: $STACK_NAME"
            echo "Environment: $ENV"
            echo "Commit: ${{ github.sha }}"
            echo "This deployment will affect PRODUCTION resources"
            echo "Termination protection will be enabled automatically"
          fi
          
          # ENTERPRISE SAFETY: Pre-deployment validation
          echo "ðŸ”’ PIPELINE SAFETY POLICY:"
          echo "   - Pipeline will NEVER delete stacks automatically"
          echo "   - Only deploys/updates stacks, never deletes"
          echo "   - Manual deletion available when needed for development"
          echo "   - Stack: $STACK_NAME"
          echo "   - Environment: $ENV"
          
          # Check stack status
          STACK_STATUS=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].StackStatus' --output text 2>/dev/null || echo "DOES_NOT_EXIST")
          
          echo "Current stack status: $STACK_STATUS"
          
          # ENTERPRISE SAFETY: Check for in-progress operations before deployment
          if [[ "$STACK_STATUS" == *"IN_PROGRESS"* ]]; then
            echo "âŒ Stack is currently in progress: $STACK_STATUS"
            echo "ðŸ›‘ STOPPING DEPLOYMENT - Cannot update stack during active operation"
            echo "ðŸ“‹ MANUAL ACTION: Wait for current operation to complete, then retry"
            echo ""
            echo "To monitor progress:"
            echo "  aws cloudformation describe-stack-events --stack-name $STACK_NAME --region ${{ env.AWS_REGION }} --query 'StackEvents[0:5].[Timestamp,ResourceStatus,ResourceType,LogicalResourceId]' --output table"
            echo ""
            echo "To check status:"
            echo "  aws cloudformation describe-stacks --stack-name $STACK_NAME --query 'Stacks[0].StackStatus' --output text --region ${{ env.AWS_REGION }}"
            echo ""
            echo "If stuck for >30 minutes, consider canceling:"
            echo "  aws cloudformation cancel-update-stack --stack-name $STACK_NAME --region ${{ env.AWS_REGION }}"
            exit 1
          fi
          
          # Handle failed states - NEVER auto-delete production stacks
          if [[ "$STACK_STATUS" == *"ROLLBACK_COMPLETE"* ]]; then
            echo "âš ï¸  Stack is in ROLLBACK_COMPLETE state - requires manual intervention"
            echo "Stack can be updated again, but will not be auto-deleted for safety"
            echo "Current status: $STACK_STATUS"
            echo "âœ… SAFE: No auto-deletion will occur"
            echo "ðŸ“‹ MANUAL ACTION: If stack cleanup is needed, delete manually outside of pipeline"
          elif [[ "$STACK_STATUS" == *"DELETE_FAILED"* ]]; then
            echo "âŒ Stack is in DELETE_FAILED state - manual cleanup required"
            echo "This requires manual investigation and resolution"
            echo "ðŸ›‘ STOPPING DEPLOYMENT - Manual intervention needed"
            echo "ðŸ“‹ MANUAL ACTION: Investigate DELETE_FAILED state and resolve manually"
            exit 1
          elif [[ "$STACK_STATUS" == *"DELETE_IN_PROGRESS"* ]]; then
            echo "âŒ Stack is currently being deleted"
            echo "ðŸ›‘ STOPPING DEPLOYMENT - Wait for deletion to complete"
            echo "ðŸ“‹ MANUAL ACTION: Wait for deletion to complete, then redeploy"
            exit 1
          fi
          
          # ENTERPRISE SAFETY: Explicit no-deletion policy
          echo "ðŸ›¡ï¸  PIPELINE SAFETY: This pipeline will NEVER delete stacks automatically"
          echo "ðŸ›¡ï¸  All stack deletions must be performed manually when needed"
          echo "ðŸ”§  Development flexibility: Manual deletion available without restrictions"
          
          # Deploy stack WITHOUT termination protection for development flexibility
          DEPLOY_TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          aws cloudformation deploy \
            --template-file cfn/master-template.yaml \
            --stack-name "$STACK_NAME" \
            --parameter-overrides \
              ProjectName="$PROJECT_NAME" \
              Environment="$ENV" \
              SourceBucket="$BUCKET" \
              AdminEmail="$ADMIN_EMAIL" \
              ApiDeploymentTimestamp="$DEPLOY_TIMESTAMP" \
              EnableTerminationProtection="false" \
            --capabilities CAPABILITY_NAMED_IAM \
            --tags \
              Project="$PROJECT_NAME" \
              Environment="$ENV" \
              DeployedBy=GitHubActions \
              CommitSha="${{ github.sha }}" \
              StackType="${{ matrix.stack.display_name }}" \
            --no-fail-on-empty-changeset
          
          echo "âœ… ${{ matrix.stack.display_name }} deployed successfully"
          echo "ðŸ”§ Manual deletion available when needed for development"
          
          echo "=== Stack Outputs for ${{ matrix.stack.display_name }} ==="
          aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[].{Key:OutputKey,Value:OutputValue}' --output table

      - name: Save deployment info for ${{ matrix.stack.display_name }}
        run: |
          STACK_NAME="${{ secrets[matrix.stack.stack_secret] }}"
          
          API_ENDPOINT=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' --output text)
          CLOUDFRONT_URL=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`CloudFrontUrl`].OutputValue' --output text)
          
          echo "API_ENDPOINT_${{ matrix.stack.name }}=$API_ENDPOINT" >> $GITHUB_ENV
          echo "CLOUDFRONT_URL_${{ matrix.stack.name }}=$CLOUDFRONT_URL" >> $GITHUB_ENV
          
          echo "### ${{ matrix.stack.display_name }} Deployment Complete :rocket:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Resource | URL |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-----|" >> $GITHUB_STEP_SUMMARY
          echo "| API Endpoint | $API_ENDPOINT |" >> $GITHUB_STEP_SUMMARY
          echo "| CloudFront URL | $CLOUDFRONT_URL |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

  # Stage 6: Deploy frontend (frontend-only changes) - Multi-Stack Matrix Strategy
  deploy-frontend:
    name: Deploy Frontend (${{ matrix.stack.name }})
    runs-on: ubuntu-latest
    needs: [detect-changes, test]
    if: |
      github.ref == 'refs/heads/main' && 
      github.event_name == 'push' && 
      needs.detect-changes.outputs.docs-only != 'true' && 
      needs.detect-changes.outputs.frontend == 'true'
    strategy:
      matrix:
        stack:
          - name: "aws-elasticdrs-orchestrator-dev"
            display_name: "Current Stack (Primary)"
            bucket_secret: "DEPLOYMENT_BUCKET"
            stack_secret: "STACK_NAME"
            admin_email_secret: "ADMIN_EMAIL"
            role_arn_secret: "AWS_ROLE_ARN"
          - name: "aws-drs-orchestrator-archive-test"
            display_name: "Archive Test Stack"
            bucket_secret: "ARCHIVE_DEPLOYMENT_BUCKET"
            stack_secret: "ARCHIVE_STACK_NAME"
            admin_email_secret: "ARCHIVE_ADMIN_EMAIL"
            role_arn_secret: "ARCHIVE_AWS_ROLE_ARN"
      max-parallel: 1  # Sequential deployment
    # Deploy frontend when frontend files change
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials for ${{ matrix.stack.display_name }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets[matrix.stack.role_arn_secret] }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts

      - name: Get stack outputs for ${{ matrix.stack.display_name }}
        id: stack
        run: |
          STACK_NAME="${{ secrets[matrix.stack.stack_secret] }}"
          
          FRONTEND_BUCKET=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue' --output text)
          CLOUDFRONT_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue' --output text)
          API_ENDPOINT=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' --output text)
          USER_POOL_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`UserPoolId`].OutputValue' --output text)
          USER_POOL_CLIENT_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`UserPoolClientId`].OutputValue' --output text)
          IDENTITY_POOL_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`IdentityPoolId`].OutputValue' --output text)
          
          echo "frontend_bucket=$FRONTEND_BUCKET" >> $GITHUB_OUTPUT
          echo "cloudfront_id=$CLOUDFRONT_ID" >> $GITHUB_OUTPUT
          echo "api_endpoint=$API_ENDPOINT" >> $GITHUB_OUTPUT
          echo "user_pool_id=$USER_POOL_ID" >> $GITHUB_OUTPUT
          echo "user_pool_client_id=$USER_POOL_CLIENT_ID" >> $GITHUB_OUTPUT
          echo "identity_pool_id=$IDENTITY_POOL_ID" >> $GITHUB_OUTPUT
            --query 'Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue' --output text)
          CLOUDFRONT_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue' --output text)
          API_ENDPOINT=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' --output text)
          USER_POOL_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`UserPoolId`].OutputValue' --output text)
          USER_POOL_CLIENT_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`UserPoolClientId`].OutputValue' --output text)
          IDENTITY_POOL_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`IdentityPoolId`].OutputValue' --output text)
          
          echo "frontend_bucket=$FRONTEND_BUCKET" >> $GITHUB_OUTPUT
          echo "cloudfront_id=$CLOUDFRONT_ID" >> $GITHUB_OUTPUT
          echo "api_endpoint=$API_ENDPOINT" >> $GITHUB_OUTPUT
          echo "user_pool_id=$USER_POOL_ID" >> $GITHUB_OUTPUT
          echo "user_pool_client_id=$USER_POOL_CLIENT_ID" >> $GITHUB_OUTPUT
          echo "identity_pool_id=$IDENTITY_POOL_ID" >> $GITHUB_OUTPUT

      - name: Generate frontend config
        run: |
          cat > frontend/dist/aws-config.json << EOF
          {
            "region": "${{ env.AWS_REGION }}",
            "userPoolId": "${{ steps.stack.outputs.user_pool_id }}",
            "userPoolClientId": "${{ steps.stack.outputs.user_pool_client_id }}",
            "identityPoolId": "${{ steps.stack.outputs.identity_pool_id }}",
            "apiEndpoint": "${{ steps.stack.outputs.api_endpoint }}"
          }
          EOF
          
          echo "Generated aws-config.json:"
          cat frontend/dist/aws-config.json

      - name: Deploy to S3
        run: |
          echo "=== Deploying Frontend to S3 ==="
          aws s3 sync frontend/dist/ "s3://${{ steps.stack.outputs.frontend_bucket }}/" \
            --delete \
            --cache-control "max-age=31536000" \
            --exclude "index.html" \
            --exclude "aws-config.json"
          
          # Deploy index.html and config with no-cache
          aws s3 cp frontend/dist/index.html "s3://${{ steps.stack.outputs.frontend_bucket }}/index.html" \
            --cache-control "no-cache, no-store, must-revalidate"
          aws s3 cp frontend/dist/aws-config.json "s3://${{ steps.stack.outputs.frontend_bucket }}/aws-config.json" \
            --cache-control "no-cache, no-store, must-revalidate"

      - name: Invalidate CloudFront cache
        run: |
          echo "=== Invalidating CloudFront Cache ==="
          aws cloudfront create-invalidation \
            --distribution-id "${{ steps.stack.outputs.cloudfront_id }}" \
            --paths "/*"

      - name: Deployment summary for ${{ matrix.stack.display_name }}
        run: |
          CLOUDFRONT_URL=$(aws cloudformation describe-stacks --stack-name "${{ secrets[matrix.stack.stack_secret] }}" \
            --query 'Stacks[0].Outputs[?OutputKey==`CloudFrontUrl`].OutputValue' --output text)
          
          echo "### ${{ matrix.stack.display_name }} Frontend Deployed :white_check_mark:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Application URL:** $CLOUDFRONT_URL" >> $GITHUB_STEP_SUMMARY

  # Stage 6b: Deploy frontend after infrastructure changes - Multi-Stack Matrix Strategy
  deploy-frontend-after-infra:
    name: Deploy Frontend Post-Infrastructure (${{ matrix.stack.name }})
    runs-on: ubuntu-latest
    needs: [detect-changes, deploy-infrastructure]
    if: |
      github.ref == 'refs/heads/main' && 
      github.event_name == 'push' && 
      needs.deploy-infrastructure.result == 'success'
    strategy:
      matrix:
        stack:
          - name: "aws-elasticdrs-orchestrator-dev"
            display_name: "Current Stack (Primary)"
            bucket_secret: "DEPLOYMENT_BUCKET"
            stack_secret: "STACK_NAME"
            admin_email_secret: "ADMIN_EMAIL"
            role_arn_secret: "AWS_ROLE_ARN"
          - name: "aws-drs-orchestrator-archive-test"
            display_name: "Archive Test Stack"
            bucket_secret: "ARCHIVE_DEPLOYMENT_BUCKET"
            stack_secret: "ARCHIVE_STACK_NAME"
            admin_email_secret: "ARCHIVE_ADMIN_EMAIL"
            role_arn_secret: "ARCHIVE_AWS_ROLE_ARN"
      max-parallel: 1  # Sequential deployment
    # Deploy frontend after infrastructure deployment (config may have changed)
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials for ${{ matrix.stack.display_name }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets[matrix.stack.role_arn_secret] }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts

      - name: Get stack outputs for frontend deployment (${{ matrix.stack.display_name }})
        run: |
          STACK_NAME="${{ secrets[matrix.stack.stack_secret] }}"
          
          CLOUDFRONT_URL=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`CloudFrontUrl`].OutputValue' --output text)
          API_ENDPOINT=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' --output text)
          USER_POOL_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`UserPoolId`].OutputValue' --output text)
          USER_POOL_CLIENT_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`UserPoolClientId`].OutputValue' --output text)
          
          echo "CLOUDFRONT_URL=$CLOUDFRONT_URL" >> $GITHUB_ENV
          echo "API_ENDPOINT=$API_ENDPOINT" >> $GITHUB_ENV
          echo "USER_POOL_ID=$USER_POOL_ID" >> $GITHUB_ENV
          echo "USER_POOL_CLIENT_ID=$USER_POOL_CLIENT_ID" >> $GITHUB_ENV

      - name: Get stack outputs for frontend deployment (${{ matrix.stack.display_name }})
        id: stack
        run: |
          STACK_NAME="${{ secrets[matrix.stack.stack_secret] }}"
          
          FRONTEND_BUCKET=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue' --output text)
          CLOUDFRONT_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue' --output text)
          IDENTITY_POOL_ID=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" \
            --query 'Stacks[0].Outputs[?OutputKey==`IdentityPoolId`].OutputValue' --output text)
          
          echo "frontend_bucket=$FRONTEND_BUCKET" >> $GITHUB_OUTPUT
          echo "cloudfront_id=$CLOUDFRONT_ID" >> $GITHUB_OUTPUT
          echo "identity_pool_id=$IDENTITY_POOL_ID" >> $GITHUB_OUTPUT

      - name: Generate frontend config
        run: |
          cat > frontend/dist/aws-config.json << EOF
          {
            "region": "${{ env.AWS_REGION }}",
            "userPoolId": "$USER_POOL_ID",
            "userPoolClientId": "$USER_POOL_CLIENT_ID",
            "identityPoolId": "${{ steps.stack.outputs.identity_pool_id }}",
            "apiEndpoint": "$API_ENDPOINT"
          }
          EOF
          
          echo "Generated aws-config.json:"
          cat frontend/dist/aws-config.json

      - name: Deploy to S3
        run: |
          echo "=== Deploying Frontend to S3 ==="
          aws s3 sync frontend/dist/ "s3://${{ steps.stack.outputs.frontend_bucket }}/" \
            --delete \
            --cache-control "max-age=31536000" \
            --exclude "index.html" \
            --exclude "aws-config.json"
          
          # Deploy index.html and config with no-cache
          aws s3 cp frontend/dist/index.html "s3://${{ steps.stack.outputs.frontend_bucket }}/index.html" \
            --cache-control "no-cache, no-store, must-revalidate"
          aws s3 cp frontend/dist/aws-config.json "s3://${{ steps.stack.outputs.frontend_bucket }}/aws-config.json" \
            --cache-control "no-cache, no-store, must-revalidate"

      - name: Invalidate CloudFront cache
        run: |
          echo "=== Invalidating CloudFront Cache ==="
          aws cloudfront create-invalidation \
            --distribution-id "${{ steps.stack.outputs.cloudfront_id }}" \
            --paths "/*"
      - name: Deployment summary for ${{ matrix.stack.display_name }}
        run: |
          echo "### ${{ matrix.stack.display_name }} Frontend Deployed (Post-Infrastructure) :white_check_mark:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Application URL:** $CLOUDFRONT_URL" >> $GITHUB_STEP_SUMMARY

  # Documentation-only deployment summary
  docs-summary:
    name: Documentation Summary
    runs-on: ubuntu-latest
    needs: [detect-changes]
    if: needs.detect-changes.outputs.docs-only == 'true'
    steps:
      - name: Documentation update summary
        run: |
          echo "### Documentation Update :memo:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Only documentation files were changed." >> $GITHUB_STEP_SUMMARY
          echo "Skipped infrastructure and frontend deployment." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Time saved:** ~18 minutes" >> $GITHUB_STEP_SUMMARY
